{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_Single_Trial_Classification_PatientData_Binary_NSL",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/EEG_Deep/blob/master/main_Single_Trial_Classification_PatientData_Binary_NSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X110PE9MjrlE",
        "colab_type": "code",
        "outputId": "1055f9c1-cbce-452d-b02f-66ab6d1aaca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "!git clone https://github.com/sagihaider/EEG_Deep.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEG_Deep'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 207 (delta 28), reused 13 (delta 5), pack-reused 153\u001b[K\n",
            "Receiving objects: 100% (207/207), 858.77 MiB | 38.70 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "Checking out files: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLzMoiS60Qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c4a3c2b8-f68f-4406-e371-9a7519d846cf"
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "from importlib.machinery import SourceFileLoader\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEG_Deep.EEGModels import EEGNet, ShallowConvNet, DeepConvNet, EEGNet_Patient\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "!pip install neural_structured_learning\n",
        "import tensorflow as tf\n",
        "import neural_structured_learning as nsl"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: neural_structured_learning in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from neural_structured_learning) (19.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from neural_structured_learning) (1.12.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from neural_structured_learning) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from neural_structured_learning) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->neural_structured_learning) (1.17.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo80Jg_Pn5lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Band-pass Filter\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjtnE_6RSpum",
        "colab_type": "code",
        "outputId": "2623da2d-2799-4a17-a2a4-b3a52e4d4d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import zeros\n",
        "K.clear_session()\n",
        "cols = 1\n",
        "rows = 10\n",
        "acc_all = zeros([rows, cols])\n",
        "loss_all = zeros([rows, cols])\n",
        "X_tr_c12 = np.empty([80, 12, 4096])\n",
        "X_ts_c12 = np.empty([80, 12, 4096])\n",
        "result=[]\n",
        "\n",
        "from itertools import combinations \n",
        "comb = combinations([1, 2], 2) \n",
        "  # Print the obtained combinations \n",
        "bincomb=[]\n",
        "for i in list(comb): \n",
        "    bincomb.append(i)\n",
        "\n",
        "for x in range(1,11):\n",
        "  fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'T.mat'  # Load Data\n",
        "  print(fName)\n",
        "  mat = spio.loadmat(fName)\n",
        "  r_X_tr = mat['RawEEGData']\n",
        "  r_y_tr = mat['Labels']\n",
        "\n",
        "  ### Filter Data ###\n",
        "  for t in range(r_X_tr.shape[0]):\n",
        "    tril = r_X_tr[t,:,:]\n",
        "    # tril = tril.transpose()\n",
        "    tril_filtered = butter_bandpass_filter(tril, \n",
        "                                              lowcut=8, \n",
        "                                              highcut=24, \n",
        "                                              fs=512,\n",
        "                                              order=4)\n",
        "    # tril_filtered = tril_filtered.transpose()\n",
        "    X_tr_c12[t,:,:] = tril_filtered\n",
        "\n",
        "  print(\"Filtering of Training Data Finished\")\n",
        "  ## Test Data Load \n",
        "\n",
        "  fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'E.mat'  # Load Data\n",
        "  print(fName)\n",
        "  mat = spio.loadmat(fName)\n",
        "  r_X_ts = mat['RawEEGData']\n",
        "  r_y_ts = mat['Labels']\n",
        "  for t in range(r_X_ts.shape[0]):\n",
        "    tril = r_X_ts[t,:,:]\n",
        "    # tril = tril.transpose()\n",
        "    tril_filtered = butter_bandpass_filter(tril, \n",
        "                                              lowcut=8, \n",
        "                                              highcut=24, \n",
        "                                              fs=512,\n",
        "                                              order=4)\n",
        "    # tril_filtered = tril_filtered.transpose()\n",
        "    X_ts_c12[t,:,:] = tril_filtered\n",
        "  \n",
        "  print(\"Filtering of Testing Data Finished\")    \n",
        "\n",
        "  for k, com in enumerate(bincomb):\n",
        "      print(com)\n",
        "      # # Find labels to specific class\n",
        "      print(\"Finding labels in training data\")\n",
        "      class1indx = list(np.where(r_y_tr == com[0]))\n",
        "      class2indx = list(np.where(r_y_tr == com[1]))\n",
        "      c1=list(class1indx[0])\n",
        "      c2=list(class2indx[0])\n",
        "      y_tr_c12 = c1 + c2\n",
        "      y_tr_c12.sort()\n",
        "      # print(y_tr_c12)\n",
        "      x_tr_12 = X_tr_c12[y_tr_c12,:,:]\n",
        "      y_tr_12 = r_y_tr[y_tr_c12]\n",
        "      # print(np.shape(x_tr_12))\n",
        "      # print(np.shape(y_tr_12))\n",
        "      # # Find labels to specific class\n",
        "      print(\"Finding labels in testing data\")\n",
        "      class1indx = list(np.where(r_y_ts == com[0]))\n",
        "      class2indx = list(np.where(r_y_ts == com[1]))\n",
        "      c1=list(class1indx[0])\n",
        "      c2=list(class2indx[0])\n",
        "      y_ts_c12 = c1 + c2\n",
        "      y_ts_c12.sort()\n",
        "      # print(y_ts_c12)\n",
        "      x_ts_12 = X_ts_c12[y_ts_c12,:,:]\n",
        "      y_ts_12 = r_y_ts[y_ts_c12]\n",
        "      # print(np.shape(x_ts_12))\n",
        "      # print(np.shape(y_ts_12))\n",
        "      del class1indx, class2indx, c1, c2\n",
        "\n",
        "      # shuffle the training data\n",
        "      indices = np.arange(x_tr_12.shape[0])\n",
        "      np.random.shuffle(indices)\n",
        "      x_tr_12 = x_tr_12[indices]\n",
        "      y_tr_12 = y_tr_12[indices]\n",
        "\n",
        "      # split data of each subject in training and validation\n",
        "      X_train = x_tr_12[0:60,:,2560:4096]\n",
        "      Y_train = y_tr_12[0:60].ravel()\n",
        "      X_val   = x_tr_12[60:,:,2560:4096]\n",
        "      Y_val   = y_tr_12[60:].ravel()\n",
        "      print(Y_val)\n",
        "      print(np.shape(X_train))\n",
        "      print(np.shape(Y_train))\n",
        "      print(np.shape(X_val))\n",
        "      print(np.shape(Y_val))\n",
        "  \n",
        "      # convert labels to one-hot encodings.\n",
        "      Y_train      = np_utils.to_categorical(Y_train-1, num_classes=4)\n",
        "      Y_val       = np_utils.to_categorical(Y_val-1, num_classes=4)\n",
        "      print(Y_val)\n",
        "\n",
        "      kernels, chans, samples = 1, 12, 1536\n",
        "      # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "      # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "      X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "      X_val   = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "   \n",
        "      print('X_train shape:', X_train.shape)\n",
        "      print(X_train.shape[0], 'train samples')\n",
        "      print(X_val.shape[0], 'val samples')\n",
        "\n",
        "      X_test      = x_ts_12[:,:,2560:4096]\n",
        "      Y_test      = y_ts_12[:]\n",
        "      print(np.shape(X_test))\n",
        "      print(np.shape(Y_test))\n",
        "\n",
        "      #convert labels to one-hot encodings.\n",
        "      Y_test      = np_utils.to_categorical(Y_test-1, num_classes=4)\n",
        "\n",
        "      # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "      # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "      X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "      print('X_train shape:', X_test.shape)\n",
        "      print(X_test.shape[0], 'train samples')\n",
        "\n",
        "\n",
        "      ##### Learning without NSL ###########################################\n",
        "      \n",
        "      # # Create a base model -- sequential, functional, or subclass.\n",
        "      # model = tf.keras.Sequential([\n",
        "      #                              tf.keras.Input((1, 12, 1536), name='feature'),\n",
        "      #                              tf.keras.layers.Flatten(),\n",
        "      #                              tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "      #                              tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
        "      #                              ])\n",
        "      # model.summary()\n",
        "      \n",
        "      # # Compile, train, and evaluate.\n",
        "      # model.compile(optimizer='adam',\n",
        "      #                   loss='categorical_crossentropy',\n",
        "      #                   metrics=['accuracy'])\n",
        "      \n",
        "      # history = model.fit(X_train, Y_train, batch_size = 32, epochs = 500, \n",
        "      #                     verbose = 2, validation_data=(X_val, Y_val)\n",
        "      #                     )\n",
        "\n",
        "      # configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "      # model configurations may do better, but this is a good starting point)\n",
        "\n",
        "      ##### Learning without NSL ################################################\n",
        "    #   model = EEGNet(nb_classes = 4, Chans = 12, Samples = 1536,\n",
        "    #                  dropoutRate = 0.5, kernLength = 25, F1 = 8, \n",
        "    #                  D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "\n",
        "    #  # Compile, train, and evaluate.\n",
        "    #   model.compile(optimizer='adam',\n",
        "    #                     loss='categorical_crossentropy',\n",
        "    #                     metrics=['accuracy'])\n",
        "      \n",
        "    #   history = model.fit(X_train, Y_train, batch_size = 32, epochs = 500, \n",
        "    #                           validation_data=(X_val, Y_val)\n",
        "    #                           )\n",
        "\n",
        "\n",
        "      ##### Learning with NSL ################################################\n",
        "      # Wrap the model with adversarial regularization.\n",
        "\n",
        "      model = EEGNet(nb_classes = 4, Chans = 12, Samples = 1536,\n",
        "                     dropoutRate = 0.5, kernLength = 25, F1 = 8,\n",
        "                     D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "            \n",
        "      adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
        "      adv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\n",
        "      \n",
        "      # Compile, train, and evaluate.\n",
        "      model.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "      \n",
        "      history = model.fit(X_train, Y_train, batch_size = 32,\n",
        "                          epochs = 500,\n",
        "                          validation_data=(X_val, Y_val)\n",
        "                          )\n",
        "      \n",
        "\n",
        "      ##### Plot with NSL ################################################\n",
        "\n",
        "      # Plot training & validation accuracy values\n",
        "      plt.plot(history.history['acc'])\n",
        "      plt.plot(history.history['val_acc'])\n",
        "      plt.title('Model accuracy')\n",
        "      plt.ylabel('Accuracy')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.legend(['Train', 'Test'], loc='upper left')\n",
        "      plt.show()\n",
        "      figName = 'Accuracy_A0' + str(x) + '.png'  \n",
        "      plt.savefig(figName)\n",
        "\n",
        "      print('\\n# Evaluate on test data')\n",
        "      results = model.evaluate(X_test, Y_test, batch_size=1)\n",
        "      print('test loss, test acc:', results)\n",
        "\n",
        "      loss_all[x - 1, k-1] = results[0]\n",
        "      acc_all[x - 1, k-1] = results[1]\n",
        "\n",
        "      from keras import backend as K \n",
        "      # Do some code, e.g. train and save model\n",
        "      K.clear_session()\n",
        "\n",
        "print(loss_all)\n",
        "print(acc_all)   \n",
        "\n",
        "     \n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P01E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[2 1 1 2 2 2 1 2 2 1 2 2 2 1 2 2 1 1 1 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.4656 - acc: 0.2333 - val_loss: 1.3892 - val_acc: 0.2000\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 1.2502 - acc: 0.5833 - val_loss: 1.3735 - val_acc: 0.4500\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 1.1207 - acc: 0.5833 - val_loss: 1.3595 - val_acc: 0.4500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 1.0311 - acc: 0.5667 - val_loss: 1.3456 - val_acc: 0.3500\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.9601 - acc: 0.5333 - val_loss: 1.3333 - val_acc: 0.3500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.9310 - acc: 0.5833 - val_loss: 1.3220 - val_acc: 0.3500\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.8889 - acc: 0.5833 - val_loss: 1.3112 - val_acc: 0.3000\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.8575 - acc: 0.6167 - val_loss: 1.3009 - val_acc: 0.3000\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.8268 - acc: 0.6833 - val_loss: 1.2908 - val_acc: 0.3000\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.8223 - acc: 0.7000 - val_loss: 1.2810 - val_acc: 0.3000\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.7896 - acc: 0.7333 - val_loss: 1.2710 - val_acc: 0.4000\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.7818 - acc: 0.7333 - val_loss: 1.2618 - val_acc: 0.4500\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 747us/sample - loss: 0.7871 - acc: 0.7167 - val_loss: 1.2527 - val_acc: 0.4500\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.7844 - acc: 0.6667 - val_loss: 1.2432 - val_acc: 0.5500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.7650 - acc: 0.7167 - val_loss: 1.2337 - val_acc: 0.5500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.7531 - acc: 0.7333 - val_loss: 1.2245 - val_acc: 0.5500\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.7502 - acc: 0.8167 - val_loss: 1.2151 - val_acc: 0.6000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.7327 - acc: 0.7500 - val_loss: 1.2061 - val_acc: 0.6000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.7371 - acc: 0.7667 - val_loss: 1.1968 - val_acc: 0.5500\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.7346 - acc: 0.7833 - val_loss: 1.1876 - val_acc: 0.5000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.7164 - acc: 0.8500 - val_loss: 1.1786 - val_acc: 0.5500\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.7152 - acc: 0.7500 - val_loss: 1.1699 - val_acc: 0.5500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.7264 - acc: 0.7333 - val_loss: 1.1611 - val_acc: 0.5500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.7068 - acc: 0.7833 - val_loss: 1.1522 - val_acc: 0.6000\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.7014 - acc: 0.7833 - val_loss: 1.1434 - val_acc: 0.6000\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.6999 - acc: 0.7500 - val_loss: 1.1346 - val_acc: 0.5500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.6983 - acc: 0.8500 - val_loss: 1.1259 - val_acc: 0.5500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.6888 - acc: 0.8500 - val_loss: 1.1172 - val_acc: 0.5000\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.6836 - acc: 0.8167 - val_loss: 1.1085 - val_acc: 0.5000\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.6835 - acc: 0.7833 - val_loss: 1.0999 - val_acc: 0.4500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.6651 - acc: 0.8500 - val_loss: 1.0915 - val_acc: 0.4500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.6596 - acc: 0.8833 - val_loss: 1.0834 - val_acc: 0.4500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.6704 - acc: 0.7833 - val_loss: 1.0752 - val_acc: 0.4500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.6412 - acc: 0.8667 - val_loss: 1.0674 - val_acc: 0.5500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.6449 - acc: 0.8333 - val_loss: 1.0602 - val_acc: 0.5500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.6464 - acc: 0.8667 - val_loss: 1.0530 - val_acc: 0.5500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.6479 - acc: 0.9000 - val_loss: 1.0453 - val_acc: 0.6000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.6325 - acc: 0.8667 - val_loss: 1.0380 - val_acc: 0.6000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.6081 - acc: 0.9500 - val_loss: 1.0311 - val_acc: 0.6000\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.6182 - acc: 0.8833 - val_loss: 1.0240 - val_acc: 0.6000\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.6151 - acc: 0.9167 - val_loss: 1.0166 - val_acc: 0.6000\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.6214 - acc: 0.8333 - val_loss: 1.0088 - val_acc: 0.6000\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.6201 - acc: 0.8333 - val_loss: 1.0004 - val_acc: 0.6000\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.5747 - acc: 0.9167 - val_loss: 0.9917 - val_acc: 0.6000\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.5820 - acc: 0.9000 - val_loss: 0.9823 - val_acc: 0.6000\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5823 - acc: 0.9167 - val_loss: 0.9731 - val_acc: 0.6000\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.5790 - acc: 0.9000 - val_loss: 0.9643 - val_acc: 0.6000\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.5716 - acc: 0.8833 - val_loss: 0.9550 - val_acc: 0.6000\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.5471 - acc: 0.9333 - val_loss: 0.9455 - val_acc: 0.6000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.5668 - acc: 0.8500 - val_loss: 0.9352 - val_acc: 0.6000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.5353 - acc: 0.8833 - val_loss: 0.9250 - val_acc: 0.5500\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.5260 - acc: 0.9000 - val_loss: 0.9154 - val_acc: 0.5500\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.5180 - acc: 0.8833 - val_loss: 0.9057 - val_acc: 0.5500\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.5141 - acc: 0.9000 - val_loss: 0.8962 - val_acc: 0.5500\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.5237 - acc: 0.8833 - val_loss: 0.8872 - val_acc: 0.5500\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 763us/sample - loss: 0.5329 - acc: 0.8333 - val_loss: 0.8788 - val_acc: 0.5500\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 722us/sample - loss: 0.5112 - acc: 0.8500 - val_loss: 0.8700 - val_acc: 0.5500\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.5103 - acc: 0.9000 - val_loss: 0.8622 - val_acc: 0.5500\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5130 - acc: 0.8833 - val_loss: 0.8540 - val_acc: 0.5500\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.4879 - acc: 0.8833 - val_loss: 0.8461 - val_acc: 0.5500\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.4766 - acc: 0.8833 - val_loss: 0.8404 - val_acc: 0.5500\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4686 - acc: 0.9000 - val_loss: 0.8345 - val_acc: 0.5500\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.4181 - acc: 0.9333 - val_loss: 0.8290 - val_acc: 0.5500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.5094 - acc: 0.8333 - val_loss: 0.8223 - val_acc: 0.5500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.4648 - acc: 0.8667 - val_loss: 0.8163 - val_acc: 0.5500\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.4634 - acc: 0.8833 - val_loss: 0.8098 - val_acc: 0.5500\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.4822 - acc: 0.8333 - val_loss: 0.8043 - val_acc: 0.5500\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.4290 - acc: 0.9333 - val_loss: 0.7979 - val_acc: 0.5500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.4224 - acc: 0.9333 - val_loss: 0.7902 - val_acc: 0.5500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.4551 - acc: 0.8333 - val_loss: 0.7821 - val_acc: 0.5500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.4196 - acc: 0.9333 - val_loss: 0.7772 - val_acc: 0.5500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.4131 - acc: 0.9333 - val_loss: 0.7701 - val_acc: 0.5500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.4339 - acc: 0.9000 - val_loss: 0.7597 - val_acc: 0.5500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.4387 - acc: 0.8667 - val_loss: 0.7505 - val_acc: 0.6000\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.4345 - acc: 0.9167 - val_loss: 0.7407 - val_acc: 0.6000\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4148 - acc: 0.8667 - val_loss: 0.7322 - val_acc: 0.6000\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.4306 - acc: 0.9167 - val_loss: 0.7272 - val_acc: 0.6000\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.4016 - acc: 0.9000 - val_loss: 0.7230 - val_acc: 0.6000\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.4015 - acc: 0.8833 - val_loss: 0.7189 - val_acc: 0.6000\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.3899 - acc: 0.9333 - val_loss: 0.7137 - val_acc: 0.6000\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.3661 - acc: 0.9000 - val_loss: 0.7039 - val_acc: 0.6000\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.3828 - acc: 0.8667 - val_loss: 0.6909 - val_acc: 0.6000\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.4160 - acc: 0.9000 - val_loss: 0.6748 - val_acc: 0.6000\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.4249 - acc: 0.8500 - val_loss: 0.6609 - val_acc: 0.7000\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.3799 - acc: 0.8833 - val_loss: 0.6529 - val_acc: 0.7000\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.3684 - acc: 0.9167 - val_loss: 0.6481 - val_acc: 0.7000\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.3651 - acc: 0.9000 - val_loss: 0.6448 - val_acc: 0.6500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.4148 - acc: 0.9167 - val_loss: 0.6397 - val_acc: 0.6500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3978 - acc: 0.8833 - val_loss: 0.6340 - val_acc: 0.6500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3465 - acc: 0.9167 - val_loss: 0.6292 - val_acc: 0.6500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.3329 - acc: 0.9167 - val_loss: 0.6215 - val_acc: 0.7500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3412 - acc: 0.9167 - val_loss: 0.6169 - val_acc: 0.7500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.3390 - acc: 0.8833 - val_loss: 0.6111 - val_acc: 0.7500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.3742 - acc: 0.8500 - val_loss: 0.6042 - val_acc: 0.7500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3414 - acc: 0.9167 - val_loss: 0.5978 - val_acc: 0.7500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3130 - acc: 0.9333 - val_loss: 0.5900 - val_acc: 0.7500\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3729 - acc: 0.9333 - val_loss: 0.5853 - val_acc: 0.8000\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3661 - acc: 0.8833 - val_loss: 0.5786 - val_acc: 0.8500\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3151 - acc: 0.9333 - val_loss: 0.5743 - val_acc: 0.8000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.3410 - acc: 0.8667 - val_loss: 0.5724 - val_acc: 0.8000\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.3352 - acc: 0.9333 - val_loss: 0.5707 - val_acc: 0.8500\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.3267 - acc: 0.9333 - val_loss: 0.5712 - val_acc: 0.8000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.3287 - acc: 0.9333 - val_loss: 0.5715 - val_acc: 0.7500\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.3148 - acc: 0.9167 - val_loss: 0.5680 - val_acc: 0.8000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.3031 - acc: 0.9167 - val_loss: 0.5644 - val_acc: 0.8000\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.3153 - acc: 0.9333 - val_loss: 0.5560 - val_acc: 0.8500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2975 - acc: 0.9500 - val_loss: 0.5495 - val_acc: 0.8500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 762us/sample - loss: 0.2841 - acc: 1.0000 - val_loss: 0.5422 - val_acc: 0.8000\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.3103 - acc: 0.9333 - val_loss: 0.5364 - val_acc: 0.8000\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3381 - acc: 0.9167 - val_loss: 0.5312 - val_acc: 0.8500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3111 - acc: 0.9333 - val_loss: 0.5304 - val_acc: 0.8500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3315 - acc: 0.9000 - val_loss: 0.5284 - val_acc: 0.8500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.3168 - acc: 0.9500 - val_loss: 0.5229 - val_acc: 0.8500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2727 - acc: 0.9333 - val_loss: 0.5177 - val_acc: 0.8500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3113 - acc: 0.9167 - val_loss: 0.5139 - val_acc: 0.8000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.3173 - acc: 0.9000 - val_loss: 0.5110 - val_acc: 0.8500\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2887 - acc: 0.9167 - val_loss: 0.5114 - val_acc: 0.8500\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.3146 - acc: 0.9167 - val_loss: 0.5093 - val_acc: 0.8000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2836 - acc: 0.9167 - val_loss: 0.5072 - val_acc: 0.8000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2636 - acc: 0.9667 - val_loss: 0.5037 - val_acc: 0.8500\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.3101 - acc: 0.9167 - val_loss: 0.5010 - val_acc: 0.8500\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.2765 - acc: 0.9667 - val_loss: 0.4979 - val_acc: 0.8500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2663 - acc: 0.9167 - val_loss: 0.4968 - val_acc: 0.8000\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2738 - acc: 0.9333 - val_loss: 0.4987 - val_acc: 0.8000\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2906 - acc: 0.9333 - val_loss: 0.5034 - val_acc: 0.8000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2120 - acc: 1.0000 - val_loss: 0.5080 - val_acc: 0.8000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2997 - acc: 0.9167 - val_loss: 0.5119 - val_acc: 0.8000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2628 - acc: 0.9167 - val_loss: 0.5154 - val_acc: 0.8000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3654 - acc: 0.9333 - val_loss: 0.5202 - val_acc: 0.8000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.2979 - acc: 0.9500 - val_loss: 0.5226 - val_acc: 0.8000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2678 - acc: 0.9333 - val_loss: 0.5122 - val_acc: 0.8000\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.2863 - acc: 0.9500 - val_loss: 0.5030 - val_acc: 0.8000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.2253 - acc: 0.9833 - val_loss: 0.4957 - val_acc: 0.8000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3035 - acc: 0.9000 - val_loss: 0.4903 - val_acc: 0.8000\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.2628 - acc: 0.9333 - val_loss: 0.4862 - val_acc: 0.8500\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2803 - acc: 0.9333 - val_loss: 0.4825 - val_acc: 0.8500\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2836 - acc: 0.9667 - val_loss: 0.4810 - val_acc: 0.8000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.3059 - acc: 0.8833 - val_loss: 0.4824 - val_acc: 0.8000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2823 - acc: 0.9333 - val_loss: 0.4857 - val_acc: 0.8000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2501 - acc: 0.9500 - val_loss: 0.4890 - val_acc: 0.8000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2827 - acc: 0.9667 - val_loss: 0.4908 - val_acc: 0.8000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2645 - acc: 0.9000 - val_loss: 0.4927 - val_acc: 0.8000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.2894 - acc: 0.9167 - val_loss: 0.4941 - val_acc: 0.8000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2812 - acc: 0.9500 - val_loss: 0.4928 - val_acc: 0.8000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2592 - acc: 0.9833 - val_loss: 0.4942 - val_acc: 0.8000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2587 - acc: 0.9167 - val_loss: 0.4948 - val_acc: 0.8000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2750 - acc: 0.9500 - val_loss: 0.4997 - val_acc: 0.8000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.2502 - acc: 0.9333 - val_loss: 0.5109 - val_acc: 0.7500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2545 - acc: 0.9833 - val_loss: 0.5137 - val_acc: 0.7500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.2362 - acc: 0.9833 - val_loss: 0.5206 - val_acc: 0.7500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2417 - acc: 0.9167 - val_loss: 0.5286 - val_acc: 0.7500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.2289 - acc: 0.9667 - val_loss: 0.5312 - val_acc: 0.7500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2692 - acc: 0.9333 - val_loss: 0.5276 - val_acc: 0.7500\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.2771 - acc: 0.9333 - val_loss: 0.5279 - val_acc: 0.7000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2423 - acc: 0.9500 - val_loss: 0.5256 - val_acc: 0.7000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 748us/sample - loss: 0.2487 - acc: 0.9333 - val_loss: 0.5237 - val_acc: 0.7000\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.2206 - acc: 0.9833 - val_loss: 0.5222 - val_acc: 0.7000\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2343 - acc: 0.9167 - val_loss: 0.5155 - val_acc: 0.7000\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.2342 - acc: 0.9500 - val_loss: 0.5145 - val_acc: 0.7500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2159 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.7500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2314 - acc: 0.9667 - val_loss: 0.5195 - val_acc: 0.7500\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.2465 - acc: 0.9500 - val_loss: 0.5241 - val_acc: 0.7500\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2169 - acc: 0.9333 - val_loss: 0.5209 - val_acc: 0.7500\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 734us/sample - loss: 0.1869 - acc: 0.9667 - val_loss: 0.5334 - val_acc: 0.7000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2348 - acc: 0.9333 - val_loss: 0.5558 - val_acc: 0.6500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2493 - acc: 0.9333 - val_loss: 0.5621 - val_acc: 0.6500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1808 - acc: 1.0000 - val_loss: 0.5635 - val_acc: 0.6000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1390 - acc: 1.0000 - val_loss: 0.5640 - val_acc: 0.6000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2196 - acc: 0.9167 - val_loss: 0.5662 - val_acc: 0.6000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2240 - acc: 0.9833 - val_loss: 0.5649 - val_acc: 0.6000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.2129 - acc: 0.9667 - val_loss: 0.5624 - val_acc: 0.6000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2109 - acc: 0.9667 - val_loss: 0.5778 - val_acc: 0.6000\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2782 - acc: 0.9167 - val_loss: 0.6100 - val_acc: 0.6000\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2171 - acc: 0.9667 - val_loss: 0.6095 - val_acc: 0.6000\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1984 - acc: 0.9833 - val_loss: 0.5968 - val_acc: 0.6000\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2135 - acc: 0.9500 - val_loss: 0.5781 - val_acc: 0.6000\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2572 - acc: 0.9333 - val_loss: 0.5644 - val_acc: 0.6000\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2061 - acc: 0.9333 - val_loss: 0.5608 - val_acc: 0.6000\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1978 - acc: 0.9667 - val_loss: 0.5632 - val_acc: 0.6000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1884 - acc: 0.9833 - val_loss: 0.5608 - val_acc: 0.6000\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1914 - acc: 0.9833 - val_loss: 0.5577 - val_acc: 0.6500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2073 - acc: 0.9667 - val_loss: 0.5495 - val_acc: 0.6500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2045 - acc: 0.9500 - val_loss: 0.5474 - val_acc: 0.6500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1817 - acc: 0.9833 - val_loss: 0.5385 - val_acc: 0.6500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2410 - acc: 0.9333 - val_loss: 0.5224 - val_acc: 0.7500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1806 - acc: 0.9833 - val_loss: 0.5174 - val_acc: 0.7500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1685 - acc: 0.9500 - val_loss: 0.5190 - val_acc: 0.7500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1923 - acc: 0.9500 - val_loss: 0.5221 - val_acc: 0.7500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2448 - acc: 0.9333 - val_loss: 0.5283 - val_acc: 0.7500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1818 - acc: 0.9500 - val_loss: 0.5165 - val_acc: 0.7500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.2214 - acc: 0.9333 - val_loss: 0.5076 - val_acc: 0.7500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 782us/sample - loss: 0.2122 - acc: 0.9667 - val_loss: 0.5158 - val_acc: 0.7500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1518 - acc: 0.9833 - val_loss: 0.5190 - val_acc: 0.7500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2096 - acc: 0.9667 - val_loss: 0.5261 - val_acc: 0.7500\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1638 - acc: 0.9833 - val_loss: 0.5306 - val_acc: 0.7500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.2320 - acc: 0.9667 - val_loss: 0.5412 - val_acc: 0.7500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2024 - acc: 0.9333 - val_loss: 0.5323 - val_acc: 0.7500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1880 - acc: 0.9667 - val_loss: 0.5329 - val_acc: 0.7500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2486 - acc: 0.9000 - val_loss: 0.5407 - val_acc: 0.7000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1564 - acc: 0.9833 - val_loss: 0.5467 - val_acc: 0.7000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.2176 - acc: 0.9500 - val_loss: 0.5570 - val_acc: 0.7000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.1965 - acc: 0.9667 - val_loss: 0.5605 - val_acc: 0.7000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1637 - acc: 1.0000 - val_loss: 0.5695 - val_acc: 0.7000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1673 - acc: 0.9833 - val_loss: 0.5495 - val_acc: 0.7000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.1717 - acc: 0.9833 - val_loss: 0.5282 - val_acc: 0.7500\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1773 - acc: 0.9667 - val_loss: 0.5139 - val_acc: 0.7500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.2191 - acc: 0.9167 - val_loss: 0.5004 - val_acc: 0.7500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1735 - acc: 0.9667 - val_loss: 0.4846 - val_acc: 0.7500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.2020 - acc: 0.9333 - val_loss: 0.4751 - val_acc: 0.7500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1810 - acc: 0.9500 - val_loss: 0.4775 - val_acc: 0.7500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1621 - acc: 1.0000 - val_loss: 0.4845 - val_acc: 0.7500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.2105 - acc: 0.9333 - val_loss: 0.5075 - val_acc: 0.7500\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1486 - acc: 0.9667 - val_loss: 0.5317 - val_acc: 0.7000\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1884 - acc: 0.9333 - val_loss: 0.5474 - val_acc: 0.7000\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1400 - acc: 1.0000 - val_loss: 0.5663 - val_acc: 0.7000\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1366 - acc: 0.9833 - val_loss: 0.5860 - val_acc: 0.6500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2002 - acc: 0.9500 - val_loss: 0.5897 - val_acc: 0.6500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1408 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.6500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2070 - acc: 0.9500 - val_loss: 0.5672 - val_acc: 0.6500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1445 - acc: 1.0000 - val_loss: 0.5629 - val_acc: 0.6500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1653 - acc: 0.9667 - val_loss: 0.5649 - val_acc: 0.6500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1925 - acc: 0.9833 - val_loss: 0.5765 - val_acc: 0.6500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1627 - acc: 0.9667 - val_loss: 0.5898 - val_acc: 0.6500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2173 - acc: 0.9333 - val_loss: 0.6037 - val_acc: 0.6500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1645 - acc: 0.9500 - val_loss: 0.6164 - val_acc: 0.6500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.2146 - acc: 0.9500 - val_loss: 0.6222 - val_acc: 0.6500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1493 - acc: 0.9667 - val_loss: 0.6076 - val_acc: 0.6500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2099 - acc: 0.9167 - val_loss: 0.5798 - val_acc: 0.6500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1184 - acc: 0.9833 - val_loss: 0.5527 - val_acc: 0.6500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1826 - acc: 0.9667 - val_loss: 0.5386 - val_acc: 0.6500\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1914 - acc: 0.9500 - val_loss: 0.5266 - val_acc: 0.6500\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.1832 - acc: 0.9833 - val_loss: 0.5038 - val_acc: 0.7500\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1782 - acc: 0.9500 - val_loss: 0.4769 - val_acc: 0.7500\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1731 - acc: 0.9500 - val_loss: 0.4534 - val_acc: 0.7500\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1773 - acc: 0.9833 - val_loss: 0.4368 - val_acc: 0.7500\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1632 - acc: 0.9667 - val_loss: 0.4321 - val_acc: 0.7500\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1466 - acc: 0.9833 - val_loss: 0.4436 - val_acc: 0.7500\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1490 - acc: 0.9833 - val_loss: 0.4526 - val_acc: 0.7500\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1414 - acc: 0.9833 - val_loss: 0.4619 - val_acc: 0.7500\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1475 - acc: 0.9833 - val_loss: 0.4656 - val_acc: 0.7500\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1918 - acc: 0.9667 - val_loss: 0.4595 - val_acc: 0.7500\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1659 - acc: 0.9500 - val_loss: 0.4557 - val_acc: 0.7500\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1795 - acc: 0.9667 - val_loss: 0.4603 - val_acc: 0.7500\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1234 - acc: 0.9667 - val_loss: 0.4614 - val_acc: 0.7500\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1879 - acc: 0.9500 - val_loss: 0.4552 - val_acc: 0.7500\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1906 - acc: 0.9167 - val_loss: 0.4518 - val_acc: 0.7500\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1777 - acc: 0.9667 - val_loss: 0.4402 - val_acc: 0.7500\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1908 - acc: 0.9333 - val_loss: 0.4393 - val_acc: 0.7500\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0928 - acc: 1.0000 - val_loss: 0.4401 - val_acc: 0.7500\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1825 - acc: 0.9333 - val_loss: 0.4431 - val_acc: 0.7500\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1162 - acc: 0.9833 - val_loss: 0.4463 - val_acc: 0.7500\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1823 - acc: 0.9500 - val_loss: 0.4490 - val_acc: 0.7500\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1368 - acc: 0.9833 - val_loss: 0.4507 - val_acc: 0.7500\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1187 - acc: 0.9833 - val_loss: 0.4490 - val_acc: 0.7500\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1768 - acc: 0.9667 - val_loss: 0.4470 - val_acc: 0.7500\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1696 - acc: 1.0000 - val_loss: 0.4416 - val_acc: 0.7500\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1232 - acc: 1.0000 - val_loss: 0.4367 - val_acc: 0.7500\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.1512 - acc: 0.9333 - val_loss: 0.4339 - val_acc: 0.7500\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 0.4267 - val_acc: 0.8000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1501 - acc: 0.9667 - val_loss: 0.4220 - val_acc: 0.8000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1206 - acc: 0.9833 - val_loss: 0.4160 - val_acc: 0.8500\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1812 - acc: 0.9500 - val_loss: 0.4123 - val_acc: 0.8500\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1214 - acc: 1.0000 - val_loss: 0.4101 - val_acc: 0.8500\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0965 - acc: 0.9833 - val_loss: 0.4097 - val_acc: 0.8500\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1429 - acc: 0.9667 - val_loss: 0.4161 - val_acc: 0.8000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 748us/sample - loss: 0.1597 - acc: 0.9333 - val_loss: 0.4267 - val_acc: 0.7500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1506 - acc: 0.9833 - val_loss: 0.4401 - val_acc: 0.7500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1192 - acc: 0.9833 - val_loss: 0.4509 - val_acc: 0.7000\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1078 - acc: 1.0000 - val_loss: 0.4556 - val_acc: 0.7000\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1435 - acc: 0.9500 - val_loss: 0.4590 - val_acc: 0.7000\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1246 - acc: 0.9833 - val_loss: 0.4542 - val_acc: 0.7500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1381 - acc: 0.9833 - val_loss: 0.4480 - val_acc: 0.7500\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1314 - acc: 0.9667 - val_loss: 0.4356 - val_acc: 0.7500\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1314 - acc: 0.9833 - val_loss: 0.4203 - val_acc: 0.7500\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 802us/sample - loss: 0.1639 - acc: 0.9500 - val_loss: 0.4163 - val_acc: 0.7500\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1651 - acc: 0.9500 - val_loss: 0.4112 - val_acc: 0.7500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1305 - acc: 0.9667 - val_loss: 0.4133 - val_acc: 0.8000\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1423 - acc: 0.9500 - val_loss: 0.4212 - val_acc: 0.7500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1632 - acc: 0.9667 - val_loss: 0.4307 - val_acc: 0.7500\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1325 - acc: 0.9667 - val_loss: 0.4444 - val_acc: 0.7500\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1224 - acc: 0.9833 - val_loss: 0.4542 - val_acc: 0.7500\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1191 - acc: 0.9833 - val_loss: 0.4610 - val_acc: 0.7500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1696 - acc: 0.9500 - val_loss: 0.4584 - val_acc: 0.7500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0991 - acc: 1.0000 - val_loss: 0.4611 - val_acc: 0.7500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1332 - acc: 0.9667 - val_loss: 0.4545 - val_acc: 0.7500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1017 - acc: 0.9833 - val_loss: 0.4494 - val_acc: 0.7500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1545 - acc: 0.9833 - val_loss: 0.4374 - val_acc: 0.7500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1282 - acc: 1.0000 - val_loss: 0.4247 - val_acc: 0.7500\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1107 - acc: 0.9833 - val_loss: 0.4179 - val_acc: 0.7500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1008 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.8000\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1145 - acc: 0.9833 - val_loss: 0.4130 - val_acc: 0.8000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1708 - acc: 0.9333 - val_loss: 0.4131 - val_acc: 0.7500\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0915 - acc: 1.0000 - val_loss: 0.4130 - val_acc: 0.7500\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0935 - acc: 1.0000 - val_loss: 0.4148 - val_acc: 0.7500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1112 - acc: 0.9667 - val_loss: 0.4182 - val_acc: 0.7500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1146 - acc: 0.9833 - val_loss: 0.4194 - val_acc: 0.7500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1011 - acc: 1.0000 - val_loss: 0.4167 - val_acc: 0.7500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1025 - acc: 0.9667 - val_loss: 0.4141 - val_acc: 0.8000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 770us/sample - loss: 0.1434 - acc: 0.9333 - val_loss: 0.4144 - val_acc: 0.8000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1610 - acc: 0.9500 - val_loss: 0.4142 - val_acc: 0.8000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 732us/sample - loss: 0.1157 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 0.8000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1076 - acc: 0.9667 - val_loss: 0.4179 - val_acc: 0.8000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1027 - acc: 0.9833 - val_loss: 0.4239 - val_acc: 0.8000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1215 - acc: 0.9667 - val_loss: 0.4294 - val_acc: 0.8000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1645 - acc: 0.9500 - val_loss: 0.4274 - val_acc: 0.8000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1204 - acc: 0.9833 - val_loss: 0.4349 - val_acc: 0.7500\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1509 - acc: 0.9333 - val_loss: 0.4226 - val_acc: 0.8000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0940 - acc: 0.9833 - val_loss: 0.4129 - val_acc: 0.8000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1011 - acc: 0.9833 - val_loss: 0.3973 - val_acc: 0.8000\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0980 - acc: 0.9667 - val_loss: 0.3886 - val_acc: 0.8500\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1098 - acc: 1.0000 - val_loss: 0.3877 - val_acc: 0.9000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.3896 - val_acc: 0.9000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1239 - acc: 0.9667 - val_loss: 0.3938 - val_acc: 0.8500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1474 - acc: 0.9667 - val_loss: 0.3999 - val_acc: 0.8500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1519 - acc: 0.9667 - val_loss: 0.4049 - val_acc: 0.8500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1289 - acc: 0.9667 - val_loss: 0.4099 - val_acc: 0.8000\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.4091 - val_acc: 0.8000\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1158 - acc: 0.9833 - val_loss: 0.4058 - val_acc: 0.8500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.1082 - acc: 1.0000 - val_loss: 0.4042 - val_acc: 0.8500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1534 - acc: 0.9333 - val_loss: 0.4031 - val_acc: 0.8000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1038 - acc: 0.9833 - val_loss: 0.4000 - val_acc: 0.8000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1167 - acc: 0.9667 - val_loss: 0.3967 - val_acc: 0.8000\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1253 - acc: 0.9667 - val_loss: 0.3932 - val_acc: 0.8000\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.8000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1113 - acc: 1.0000 - val_loss: 0.3904 - val_acc: 0.8000\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1484 - acc: 0.9667 - val_loss: 0.3887 - val_acc: 0.8000\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1121 - acc: 0.9833 - val_loss: 0.3872 - val_acc: 0.8000\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0908 - acc: 1.0000 - val_loss: 0.3854 - val_acc: 0.8500\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0826 - acc: 1.0000 - val_loss: 0.3844 - val_acc: 0.8500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1238 - acc: 0.9667 - val_loss: 0.3834 - val_acc: 0.8000\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0874 - acc: 1.0000 - val_loss: 0.3848 - val_acc: 0.8000\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.3926 - val_acc: 0.8000\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0981 - acc: 1.0000 - val_loss: 0.4005 - val_acc: 0.8000\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0931 - acc: 0.9833 - val_loss: 0.4017 - val_acc: 0.8000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1166 - acc: 0.9833 - val_loss: 0.4039 - val_acc: 0.8000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0835 - acc: 1.0000 - val_loss: 0.4040 - val_acc: 0.8000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1056 - acc: 0.9667 - val_loss: 0.4034 - val_acc: 0.8000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0855 - acc: 0.9833 - val_loss: 0.4017 - val_acc: 0.8000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1007 - acc: 1.0000 - val_loss: 0.4032 - val_acc: 0.8000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.1294 - acc: 0.9667 - val_loss: 0.3928 - val_acc: 0.8000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1015 - acc: 0.9833 - val_loss: 0.3808 - val_acc: 0.8000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1212 - acc: 0.9667 - val_loss: 0.3724 - val_acc: 0.8500\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0994 - acc: 0.9833 - val_loss: 0.3687 - val_acc: 0.9000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0900 - acc: 1.0000 - val_loss: 0.3644 - val_acc: 0.9000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1050 - acc: 0.9833 - val_loss: 0.3636 - val_acc: 0.8500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0725 - acc: 1.0000 - val_loss: 0.3650 - val_acc: 0.8500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0867 - acc: 0.9833 - val_loss: 0.3689 - val_acc: 0.8000\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0905 - acc: 1.0000 - val_loss: 0.3742 - val_acc: 0.8000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.3867 - val_acc: 0.8000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1246 - acc: 0.9667 - val_loss: 0.3832 - val_acc: 0.8000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1111 - acc: 0.9833 - val_loss: 0.3841 - val_acc: 0.8000\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.3857 - val_acc: 0.8000\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0810 - acc: 1.0000 - val_loss: 0.3894 - val_acc: 0.8000\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1291 - acc: 0.9667 - val_loss: 0.3815 - val_acc: 0.8000\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0882 - acc: 1.0000 - val_loss: 0.3834 - val_acc: 0.8000\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1568 - acc: 0.9500 - val_loss: 0.3895 - val_acc: 0.8000\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 731us/sample - loss: 0.1178 - acc: 0.9500 - val_loss: 0.3928 - val_acc: 0.8000\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0657 - acc: 1.0000 - val_loss: 0.4006 - val_acc: 0.8000\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0897 - acc: 0.9667 - val_loss: 0.4089 - val_acc: 0.8000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.8000\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.0789 - acc: 1.0000 - val_loss: 0.4371 - val_acc: 0.7500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.4300 - val_acc: 0.8000\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.4245 - val_acc: 0.8000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0816 - acc: 0.9833 - val_loss: 0.4138 - val_acc: 0.8000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0842 - acc: 0.9833 - val_loss: 0.3974 - val_acc: 0.8000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 827us/sample - loss: 0.1050 - acc: 0.9667 - val_loss: 0.3812 - val_acc: 0.8000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1054 - acc: 0.9667 - val_loss: 0.3823 - val_acc: 0.8000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0922 - acc: 0.9833 - val_loss: 0.3865 - val_acc: 0.8000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1130 - acc: 0.9833 - val_loss: 0.3995 - val_acc: 0.8000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0837 - acc: 1.0000 - val_loss: 0.3982 - val_acc: 0.8000\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0875 - acc: 1.0000 - val_loss: 0.3959 - val_acc: 0.8000\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0746 - acc: 0.9833 - val_loss: 0.3904 - val_acc: 0.8000\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0584 - acc: 1.0000 - val_loss: 0.3883 - val_acc: 0.8000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0805 - acc: 1.0000 - val_loss: 0.3849 - val_acc: 0.8000\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0837 - acc: 1.0000 - val_loss: 0.3873 - val_acc: 0.8000\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0934 - acc: 1.0000 - val_loss: 0.3917 - val_acc: 0.8000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0805 - acc: 0.9833 - val_loss: 0.4020 - val_acc: 0.8000\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.4181 - val_acc: 0.8000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1142 - acc: 0.9667 - val_loss: 0.4332 - val_acc: 0.8000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0932 - acc: 0.9667 - val_loss: 0.4469 - val_acc: 0.8000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1007 - acc: 0.9667 - val_loss: 0.4674 - val_acc: 0.7500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.4786 - val_acc: 0.7500\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1036 - acc: 0.9833 - val_loss: 0.4794 - val_acc: 0.7500\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.4752 - val_acc: 0.7500\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0793 - acc: 0.9833 - val_loss: 0.4604 - val_acc: 0.8000\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0908 - acc: 0.9833 - val_loss: 0.4485 - val_acc: 0.8000\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0745 - acc: 0.9833 - val_loss: 0.4443 - val_acc: 0.8000\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1283 - acc: 0.9333 - val_loss: 0.4446 - val_acc: 0.8000\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0821 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.8000\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0699 - acc: 1.0000 - val_loss: 0.4529 - val_acc: 0.8000\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0830 - acc: 0.9667 - val_loss: 0.4434 - val_acc: 0.8000\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0968 - acc: 0.9833 - val_loss: 0.4560 - val_acc: 0.8000\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.0813 - acc: 1.0000 - val_loss: 0.4619 - val_acc: 0.7500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1138 - acc: 0.9500 - val_loss: 0.4762 - val_acc: 0.7000\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 741us/sample - loss: 0.0894 - acc: 1.0000 - val_loss: 0.4939 - val_acc: 0.7000\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 0.5085 - val_acc: 0.7000\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0566 - acc: 1.0000 - val_loss: 0.5033 - val_acc: 0.7000\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0747 - acc: 0.9833 - val_loss: 0.4840 - val_acc: 0.7000\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1019 - acc: 0.9833 - val_loss: 0.4597 - val_acc: 0.7000\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.4399 - val_acc: 0.7000\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0691 - acc: 1.0000 - val_loss: 0.4348 - val_acc: 0.7500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0685 - acc: 0.9833 - val_loss: 0.4277 - val_acc: 0.8000\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1083 - acc: 0.9667 - val_loss: 0.4277 - val_acc: 0.8000\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0880 - acc: 0.9500 - val_loss: 0.4126 - val_acc: 0.8000\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.0963 - acc: 0.9833 - val_loss: 0.4283 - val_acc: 0.8000\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0646 - acc: 0.9833 - val_loss: 0.4584 - val_acc: 0.8000\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0842 - acc: 0.9667 - val_loss: 0.4805 - val_acc: 0.7000\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.4969 - val_acc: 0.7000\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.5083 - val_acc: 0.7000\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1363 - acc: 0.9833 - val_loss: 0.5141 - val_acc: 0.7000\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0692 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.7000\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0763 - acc: 0.9833 - val_loss: 0.4439 - val_acc: 0.8000\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.0719 - acc: 1.0000 - val_loss: 0.4059 - val_acc: 0.8000\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.3826 - val_acc: 0.8000\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1347 - acc: 0.9833 - val_loss: 0.3681 - val_acc: 0.8000\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0750 - acc: 0.9833 - val_loss: 0.3549 - val_acc: 0.8500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1303 - acc: 0.9667 - val_loss: 0.3568 - val_acc: 0.8500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.3592 - val_acc: 0.8500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.1514 - acc: 0.9500 - val_loss: 0.3685 - val_acc: 0.8500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1107 - acc: 0.9667 - val_loss: 0.3681 - val_acc: 0.8500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0980 - acc: 0.9833 - val_loss: 0.3800 - val_acc: 0.8000\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0754 - acc: 0.9833 - val_loss: 0.3893 - val_acc: 0.8000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0923 - acc: 0.9833 - val_loss: 0.3980 - val_acc: 0.8000\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.8000\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.4314 - val_acc: 0.8000\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0906 - acc: 0.9833 - val_loss: 0.4398 - val_acc: 0.8000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0677 - acc: 0.9833 - val_loss: 0.4561 - val_acc: 0.8000\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0706 - acc: 0.9833 - val_loss: 0.4658 - val_acc: 0.7500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0924 - acc: 0.9833 - val_loss: 0.4554 - val_acc: 0.8000\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.4353 - val_acc: 0.8000\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0862 - acc: 0.9667 - val_loss: 0.4170 - val_acc: 0.8000\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0693 - acc: 1.0000 - val_loss: 0.4101 - val_acc: 0.8000\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0685 - acc: 1.0000 - val_loss: 0.4184 - val_acc: 0.8000\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.0972 - acc: 0.9833 - val_loss: 0.4335 - val_acc: 0.8000\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0857 - acc: 0.9667 - val_loss: 0.4280 - val_acc: 0.8000\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0924 - acc: 0.9833 - val_loss: 0.4235 - val_acc: 0.8000\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0685 - acc: 0.9833 - val_loss: 0.4158 - val_acc: 0.8000\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.4041 - val_acc: 0.8000\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0792 - acc: 0.9833 - val_loss: 0.4074 - val_acc: 0.8000\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1120 - acc: 0.9667 - val_loss: 0.4219 - val_acc: 0.8000\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0826 - acc: 1.0000 - val_loss: 0.4308 - val_acc: 0.8000\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0799 - acc: 1.0000 - val_loss: 0.4253 - val_acc: 0.8000\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.4198 - val_acc: 0.8000\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.4154 - val_acc: 0.8000\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0677 - acc: 1.0000 - val_loss: 0.4115 - val_acc: 0.8000\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0725 - acc: 1.0000 - val_loss: 0.3998 - val_acc: 0.8000\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.3986 - val_acc: 0.8000\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0833 - acc: 0.9833 - val_loss: 0.4060 - val_acc: 0.8000\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0702 - acc: 0.9833 - val_loss: 0.4186 - val_acc: 0.8000\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0558 - acc: 1.0000 - val_loss: 0.4074 - val_acc: 0.8000\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0690 - acc: 0.9667 - val_loss: 0.3936 - val_acc: 0.8500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0643 - acc: 0.9833 - val_loss: 0.3862 - val_acc: 0.8500\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0774 - acc: 0.9833 - val_loss: 0.3876 - val_acc: 0.8500\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0822 - acc: 1.0000 - val_loss: 0.3879 - val_acc: 0.8500\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1232 - acc: 0.9500 - val_loss: 0.3854 - val_acc: 0.8500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.3881 - val_acc: 0.8500\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 0.8500\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.3938 - val_acc: 0.8000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0626 - acc: 1.0000 - val_loss: 0.3896 - val_acc: 0.8000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0860 - acc: 0.9667 - val_loss: 0.3919 - val_acc: 0.8000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0759 - acc: 1.0000 - val_loss: 0.4050 - val_acc: 0.7500\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0652 - acc: 1.0000 - val_loss: 0.4247 - val_acc: 0.7500\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0691 - acc: 0.9667 - val_loss: 0.4430 - val_acc: 0.7500\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0770 - acc: 0.9667 - val_loss: 0.4490 - val_acc: 0.7500\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0826 - acc: 0.9833 - val_loss: 0.4371 - val_acc: 0.7500\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0594 - acc: 0.9833 - val_loss: 0.4256 - val_acc: 0.7500\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0894 - acc: 0.9833 - val_loss: 0.4335 - val_acc: 0.7500\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0792 - acc: 0.9833 - val_loss: 0.4631 - val_acc: 0.7500\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0670 - acc: 1.0000 - val_loss: 0.4694 - val_acc: 0.7500\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.4561 - val_acc: 0.7500\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0836 - acc: 0.9667 - val_loss: 0.4256 - val_acc: 0.7500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0690 - acc: 0.9833 - val_loss: 0.4073 - val_acc: 0.7500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0713 - acc: 0.9833 - val_loss: 0.3998 - val_acc: 0.7500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0779 - acc: 0.9667 - val_loss: 0.4012 - val_acc: 0.8000\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0731 - acc: 0.9667 - val_loss: 0.3948 - val_acc: 0.8500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0849 - acc: 0.9833 - val_loss: 0.3930 - val_acc: 0.8000\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.3955 - val_acc: 0.8000\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.4061 - val_acc: 0.8000\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.8000\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0826 - acc: 0.9833 - val_loss: 0.4425 - val_acc: 0.8000\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0884 - acc: 0.9833 - val_loss: 0.4751 - val_acc: 0.7500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 580us/sample - loss: 0.0737 - acc: 1.0000 - val_loss: 0.4928 - val_acc: 0.7500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.0619 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.7500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0705 - acc: 0.9833 - val_loss: 0.4919 - val_acc: 0.7500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0594 - acc: 1.0000 - val_loss: 0.4838 - val_acc: 0.7500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.0604 - acc: 1.0000 - val_loss: 0.4584 - val_acc: 0.7500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0588 - acc: 1.0000 - val_loss: 0.4397 - val_acc: 0.7500\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0598 - acc: 1.0000 - val_loss: 0.4200 - val_acc: 0.8000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.4076 - val_acc: 0.8000\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0909 - acc: 0.9833 - val_loss: 0.4020 - val_acc: 0.8000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0600 - acc: 0.9833 - val_loss: 0.3893 - val_acc: 0.8000\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.8000\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0587 - acc: 1.0000 - val_loss: 0.4001 - val_acc: 0.8000\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0621 - acc: 0.9833 - val_loss: 0.4202 - val_acc: 0.8000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0619 - acc: 1.0000 - val_loss: 0.4461 - val_acc: 0.7500\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0734 - acc: 0.9667 - val_loss: 0.4951 - val_acc: 0.7500\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.7000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0783 - acc: 1.0000 - val_loss: 0.5772 - val_acc: 0.7000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0545 - acc: 1.0000 - val_loss: 0.5791 - val_acc: 0.7000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0892 - acc: 0.9667 - val_loss: 0.5715 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncyIwM8ucE4GZWeacCMzMMvf/An+bWEyhUQkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.5952 - acc: 0.7500\n",
            "test loss, test acc: [0.595165408635512, 0.75]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P02E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[2 1 1 2 1 2 1 2 1 1 1 1 1 2 2 2 1 2 2 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 6ms/sample - loss: 1.5283 - acc: 0.2667 - val_loss: 1.3692 - val_acc: 0.5500\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 1.2480 - acc: 0.5667 - val_loss: 1.3710 - val_acc: 0.6000\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 1.1045 - acc: 0.6000 - val_loss: 1.3697 - val_acc: 0.6500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.9898 - acc: 0.7333 - val_loss: 1.3640 - val_acc: 0.6500\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.9398 - acc: 0.6833 - val_loss: 1.3558 - val_acc: 0.7000\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.8880 - acc: 0.6333 - val_loss: 1.3451 - val_acc: 0.7000\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.8727 - acc: 0.6333 - val_loss: 1.3330 - val_acc: 0.7000\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.8207 - acc: 0.7333 - val_loss: 1.3204 - val_acc: 0.7000\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.8016 - acc: 0.7500 - val_loss: 1.3077 - val_acc: 0.7000\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.7905 - acc: 0.6833 - val_loss: 1.2957 - val_acc: 0.6500\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.7782 - acc: 0.7333 - val_loss: 1.2836 - val_acc: 0.6500\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.7518 - acc: 0.8333 - val_loss: 1.2712 - val_acc: 0.6500\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.7524 - acc: 0.8167 - val_loss: 1.2583 - val_acc: 0.6500\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.7413 - acc: 0.8667 - val_loss: 1.2456 - val_acc: 0.6500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.7382 - acc: 0.7833 - val_loss: 1.2341 - val_acc: 0.6500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.7029 - acc: 0.8667 - val_loss: 1.2226 - val_acc: 0.6500\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.7122 - acc: 0.8500 - val_loss: 1.2110 - val_acc: 0.6500\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.7009 - acc: 0.8500 - val_loss: 1.1998 - val_acc: 0.6500\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.7070 - acc: 0.8000 - val_loss: 1.1888 - val_acc: 0.6500\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 784us/sample - loss: 0.6912 - acc: 0.8667 - val_loss: 1.1787 - val_acc: 0.6500\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.6888 - acc: 0.8667 - val_loss: 1.1687 - val_acc: 0.6500\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.6814 - acc: 0.9167 - val_loss: 1.1585 - val_acc: 0.6500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.6914 - acc: 0.8333 - val_loss: 1.1482 - val_acc: 0.6500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.6567 - acc: 0.8667 - val_loss: 1.1384 - val_acc: 0.6500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.6700 - acc: 0.9000 - val_loss: 1.1282 - val_acc: 0.6500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.6639 - acc: 0.8667 - val_loss: 1.1188 - val_acc: 0.6500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.6557 - acc: 0.8667 - val_loss: 1.1097 - val_acc: 0.6500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.6469 - acc: 0.8500 - val_loss: 1.1010 - val_acc: 0.6500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.6414 - acc: 0.9167 - val_loss: 1.0923 - val_acc: 0.6500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.6455 - acc: 0.9333 - val_loss: 1.0842 - val_acc: 0.6500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.6372 - acc: 0.8667 - val_loss: 1.0763 - val_acc: 0.6500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.6229 - acc: 0.9000 - val_loss: 1.0686 - val_acc: 0.6500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.6335 - acc: 0.8667 - val_loss: 1.0610 - val_acc: 0.6500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.6281 - acc: 0.9000 - val_loss: 1.0529 - val_acc: 0.6500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.6044 - acc: 0.9333 - val_loss: 1.0456 - val_acc: 0.6500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.6119 - acc: 0.9167 - val_loss: 1.0373 - val_acc: 0.6500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.6024 - acc: 0.9667 - val_loss: 1.0292 - val_acc: 0.6500\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.5825 - acc: 0.9333 - val_loss: 1.0207 - val_acc: 0.6500\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5879 - acc: 0.9167 - val_loss: 1.0122 - val_acc: 0.6500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.5650 - acc: 0.9333 - val_loss: 1.0043 - val_acc: 0.6500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.5846 - acc: 0.9500 - val_loss: 0.9958 - val_acc: 0.6500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.5497 - acc: 0.9000 - val_loss: 0.9884 - val_acc: 0.6500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.5762 - acc: 0.9000 - val_loss: 0.9810 - val_acc: 0.6500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.5539 - acc: 0.9667 - val_loss: 0.9743 - val_acc: 0.6500\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.5625 - acc: 0.9333 - val_loss: 0.9684 - val_acc: 0.6500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.5262 - acc: 0.9333 - val_loss: 0.9633 - val_acc: 0.6500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.5421 - acc: 0.9667 - val_loss: 0.9580 - val_acc: 0.6500\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5144 - acc: 0.9000 - val_loss: 0.9514 - val_acc: 0.6500\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.5483 - acc: 0.9333 - val_loss: 0.9450 - val_acc: 0.6500\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5149 - acc: 0.9667 - val_loss: 0.9390 - val_acc: 0.6500\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.5425 - acc: 0.8833 - val_loss: 0.9334 - val_acc: 0.6500\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.5286 - acc: 0.8833 - val_loss: 0.9267 - val_acc: 0.6500\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.5151 - acc: 0.9167 - val_loss: 0.9215 - val_acc: 0.6500\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.5271 - acc: 0.9000 - val_loss: 0.9176 - val_acc: 0.6500\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.4970 - acc: 0.8833 - val_loss: 0.9122 - val_acc: 0.6500\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.4949 - acc: 0.9333 - val_loss: 0.9058 - val_acc: 0.6500\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.4637 - acc: 0.9667 - val_loss: 0.8993 - val_acc: 0.7000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.4792 - acc: 0.9333 - val_loss: 0.8916 - val_acc: 0.7000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.4656 - acc: 0.9500 - val_loss: 0.8835 - val_acc: 0.7000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.4745 - acc: 0.9000 - val_loss: 0.8758 - val_acc: 0.7000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.4478 - acc: 0.9500 - val_loss: 0.8687 - val_acc: 0.7000\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.4606 - acc: 0.9000 - val_loss: 0.8597 - val_acc: 0.7500\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.4336 - acc: 0.9667 - val_loss: 0.8516 - val_acc: 0.7500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.4550 - acc: 0.9000 - val_loss: 0.8454 - val_acc: 0.7500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.4371 - acc: 0.9667 - val_loss: 0.8400 - val_acc: 0.7500\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.4508 - acc: 0.8833 - val_loss: 0.8338 - val_acc: 0.8500\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.4071 - acc: 0.9333 - val_loss: 0.8272 - val_acc: 0.8500\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.4284 - acc: 0.9000 - val_loss: 0.8205 - val_acc: 0.8500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 728us/sample - loss: 0.4389 - acc: 0.8833 - val_loss: 0.8138 - val_acc: 0.8500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.3965 - acc: 0.9333 - val_loss: 0.8082 - val_acc: 0.8500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.4327 - acc: 0.8667 - val_loss: 0.8007 - val_acc: 0.8500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 761us/sample - loss: 0.3706 - acc: 0.9167 - val_loss: 0.7960 - val_acc: 0.8500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.4039 - acc: 0.9000 - val_loss: 0.7943 - val_acc: 0.8000\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.3711 - acc: 0.9333 - val_loss: 0.7936 - val_acc: 0.7500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3650 - acc: 0.9167 - val_loss: 0.7926 - val_acc: 0.7000\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3774 - acc: 0.8833 - val_loss: 0.7923 - val_acc: 0.6500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.3480 - acc: 0.9167 - val_loss: 0.7914 - val_acc: 0.6500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3450 - acc: 0.9500 - val_loss: 0.7891 - val_acc: 0.6500\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.3085 - acc: 0.9667 - val_loss: 0.7847 - val_acc: 0.6500\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.3228 - acc: 0.9167 - val_loss: 0.7800 - val_acc: 0.6500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.3243 - acc: 0.9500 - val_loss: 0.7731 - val_acc: 0.6500\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.3940 - acc: 0.8833 - val_loss: 0.7640 - val_acc: 0.7000\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 736us/sample - loss: 0.3372 - acc: 0.9167 - val_loss: 0.7581 - val_acc: 0.7000\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.3496 - acc: 0.8833 - val_loss: 0.7520 - val_acc: 0.7500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.3263 - acc: 0.9000 - val_loss: 0.7443 - val_acc: 0.7500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2944 - acc: 0.9167 - val_loss: 0.7373 - val_acc: 0.7500\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3342 - acc: 0.9167 - val_loss: 0.7308 - val_acc: 0.8000\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3194 - acc: 0.9333 - val_loss: 0.7199 - val_acc: 0.8000\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2893 - acc: 0.9000 - val_loss: 0.7111 - val_acc: 0.8000\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 836us/sample - loss: 0.3130 - acc: 0.9000 - val_loss: 0.7043 - val_acc: 0.8000\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.3158 - acc: 0.9167 - val_loss: 0.6991 - val_acc: 0.8000\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 727us/sample - loss: 0.2789 - acc: 0.9167 - val_loss: 0.6973 - val_acc: 0.8000\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2799 - acc: 0.9167 - val_loss: 0.6971 - val_acc: 0.7500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2757 - acc: 0.9500 - val_loss: 0.6997 - val_acc: 0.7500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2829 - acc: 0.9167 - val_loss: 0.7003 - val_acc: 0.7000\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2737 - acc: 0.9500 - val_loss: 0.7018 - val_acc: 0.7000\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.2821 - acc: 0.9167 - val_loss: 0.7021 - val_acc: 0.7000\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2650 - acc: 0.9500 - val_loss: 0.7039 - val_acc: 0.7000\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 759us/sample - loss: 0.3151 - acc: 0.9167 - val_loss: 0.7017 - val_acc: 0.7000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.3128 - acc: 0.8833 - val_loss: 0.6992 - val_acc: 0.7000\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.2606 - acc: 0.9167 - val_loss: 0.7010 - val_acc: 0.7000\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.2600 - acc: 0.9333 - val_loss: 0.7040 - val_acc: 0.7000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2511 - acc: 0.9500 - val_loss: 0.7061 - val_acc: 0.7000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.3005 - acc: 0.8833 - val_loss: 0.7059 - val_acc: 0.7000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2534 - acc: 0.9333 - val_loss: 0.6983 - val_acc: 0.7000\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.2580 - acc: 0.9333 - val_loss: 0.6885 - val_acc: 0.7000\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2644 - acc: 0.8833 - val_loss: 0.6808 - val_acc: 0.7000\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3010 - acc: 0.8833 - val_loss: 0.6714 - val_acc: 0.6500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2596 - acc: 0.9500 - val_loss: 0.6654 - val_acc: 0.7000\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2700 - acc: 0.9167 - val_loss: 0.6623 - val_acc: 0.6500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2635 - acc: 0.9500 - val_loss: 0.6575 - val_acc: 0.7000\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2367 - acc: 0.9333 - val_loss: 0.6573 - val_acc: 0.6500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 728us/sample - loss: 0.2697 - acc: 0.9333 - val_loss: 0.6536 - val_acc: 0.6500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.2467 - acc: 0.9333 - val_loss: 0.6472 - val_acc: 0.6500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.2678 - acc: 0.9333 - val_loss: 0.6451 - val_acc: 0.6500\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 748us/sample - loss: 0.2469 - acc: 0.9500 - val_loss: 0.6468 - val_acc: 0.6500\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.3368 - acc: 0.9000 - val_loss: 0.6464 - val_acc: 0.7000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2494 - acc: 0.9500 - val_loss: 0.6574 - val_acc: 0.7000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2274 - acc: 0.9333 - val_loss: 0.6678 - val_acc: 0.7000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.2388 - acc: 0.9333 - val_loss: 0.6782 - val_acc: 0.7000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2101 - acc: 0.9500 - val_loss: 0.6906 - val_acc: 0.7000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2582 - acc: 0.9167 - val_loss: 0.6990 - val_acc: 0.7000\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.2308 - acc: 0.9500 - val_loss: 0.7068 - val_acc: 0.7000\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.2631 - acc: 0.9167 - val_loss: 0.7114 - val_acc: 0.7000\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2213 - acc: 0.9500 - val_loss: 0.7089 - val_acc: 0.7000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.2344 - acc: 0.9333 - val_loss: 0.7081 - val_acc: 0.7000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2325 - acc: 0.9333 - val_loss: 0.7068 - val_acc: 0.7000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2192 - acc: 0.9500 - val_loss: 0.7011 - val_acc: 0.7000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.2490 - acc: 0.9500 - val_loss: 0.6934 - val_acc: 0.7000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1927 - acc: 0.9500 - val_loss: 0.6813 - val_acc: 0.7000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.2057 - acc: 0.9667 - val_loss: 0.6694 - val_acc: 0.7000\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2325 - acc: 0.9167 - val_loss: 0.6509 - val_acc: 0.7000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.2166 - acc: 0.9500 - val_loss: 0.6287 - val_acc: 0.7500\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1931 - acc: 0.9667 - val_loss: 0.6115 - val_acc: 0.7500\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 746us/sample - loss: 0.2249 - acc: 0.9333 - val_loss: 0.5956 - val_acc: 0.7000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2039 - acc: 0.9167 - val_loss: 0.5882 - val_acc: 0.7000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2327 - acc: 0.9167 - val_loss: 0.5824 - val_acc: 0.7000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2036 - acc: 0.9333 - val_loss: 0.5765 - val_acc: 0.7000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2106 - acc: 0.9167 - val_loss: 0.5729 - val_acc: 0.7500\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1902 - acc: 0.9667 - val_loss: 0.5715 - val_acc: 0.8000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2648 - acc: 0.9000 - val_loss: 0.5689 - val_acc: 0.8000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1752 - acc: 0.9667 - val_loss: 0.5649 - val_acc: 0.8000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2062 - acc: 0.9667 - val_loss: 0.5618 - val_acc: 0.7500\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2257 - acc: 0.9167 - val_loss: 0.5597 - val_acc: 0.7500\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2271 - acc: 0.9333 - val_loss: 0.5602 - val_acc: 0.7500\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2126 - acc: 0.9167 - val_loss: 0.5623 - val_acc: 0.7500\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.2148 - acc: 0.9333 - val_loss: 0.5653 - val_acc: 0.7500\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2374 - acc: 0.9167 - val_loss: 0.5716 - val_acc: 0.7500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1950 - acc: 0.9500 - val_loss: 0.5729 - val_acc: 0.7500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1991 - acc: 0.9500 - val_loss: 0.5697 - val_acc: 0.7500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.2131 - acc: 0.9500 - val_loss: 0.5637 - val_acc: 0.7500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1847 - acc: 1.0000 - val_loss: 0.5581 - val_acc: 0.7500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1963 - acc: 0.9833 - val_loss: 0.5532 - val_acc: 0.7500\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1751 - acc: 0.9833 - val_loss: 0.5479 - val_acc: 0.7500\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1659 - acc: 0.9833 - val_loss: 0.5454 - val_acc: 0.7500\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.1820 - acc: 0.9667 - val_loss: 0.5441 - val_acc: 0.7500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1864 - acc: 0.9667 - val_loss: 0.5424 - val_acc: 0.7500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1764 - acc: 0.9833 - val_loss: 0.5424 - val_acc: 0.7500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 719us/sample - loss: 0.1909 - acc: 0.9667 - val_loss: 0.5429 - val_acc: 0.7500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2130 - acc: 0.9667 - val_loss: 0.5469 - val_acc: 0.7500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1746 - acc: 0.9500 - val_loss: 0.5507 - val_acc: 0.8000\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1865 - acc: 0.9500 - val_loss: 0.5530 - val_acc: 0.8000\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2382 - acc: 0.9333 - val_loss: 0.5472 - val_acc: 0.8000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1844 - acc: 0.9667 - val_loss: 0.5466 - val_acc: 0.7500\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.1710 - acc: 0.9833 - val_loss: 0.5456 - val_acc: 0.7500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1885 - acc: 0.9500 - val_loss: 0.5420 - val_acc: 0.7500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1648 - acc: 0.9833 - val_loss: 0.5407 - val_acc: 0.8000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.2052 - acc: 0.9333 - val_loss: 0.5408 - val_acc: 0.8000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.1683 - acc: 0.9833 - val_loss: 0.5410 - val_acc: 0.8000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1496 - acc: 1.0000 - val_loss: 0.5459 - val_acc: 0.8000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2084 - acc: 0.9333 - val_loss: 0.5449 - val_acc: 0.7500\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1858 - acc: 0.9500 - val_loss: 0.5449 - val_acc: 0.7500\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1638 - acc: 1.0000 - val_loss: 0.5435 - val_acc: 0.7500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1597 - acc: 0.9667 - val_loss: 0.5434 - val_acc: 0.7500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1613 - acc: 0.9667 - val_loss: 0.5409 - val_acc: 0.7500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1814 - acc: 0.9167 - val_loss: 0.5363 - val_acc: 0.7500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1600 - acc: 0.9667 - val_loss: 0.5265 - val_acc: 0.8000\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1909 - acc: 0.9333 - val_loss: 0.5131 - val_acc: 0.7500\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1494 - acc: 1.0000 - val_loss: 0.5063 - val_acc: 0.7500\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1883 - acc: 0.9500 - val_loss: 0.5001 - val_acc: 0.7500\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1694 - acc: 0.9667 - val_loss: 0.4973 - val_acc: 0.7500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1626 - acc: 0.9500 - val_loss: 0.4959 - val_acc: 0.7500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1332 - acc: 0.9833 - val_loss: 0.4954 - val_acc: 0.7500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1910 - acc: 0.9833 - val_loss: 0.4934 - val_acc: 0.7500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1451 - acc: 0.9667 - val_loss: 0.4909 - val_acc: 0.7500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1754 - acc: 0.9500 - val_loss: 0.4903 - val_acc: 0.7500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1559 - acc: 0.9833 - val_loss: 0.4839 - val_acc: 0.7500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1467 - acc: 0.9667 - val_loss: 0.4787 - val_acc: 0.7500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1753 - acc: 0.9667 - val_loss: 0.4727 - val_acc: 0.7500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1361 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.7500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1917 - acc: 0.9333 - val_loss: 0.4659 - val_acc: 0.7500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1720 - acc: 0.9667 - val_loss: 0.4650 - val_acc: 0.7500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1666 - acc: 0.9667 - val_loss: 0.4632 - val_acc: 0.7500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1689 - acc: 0.9500 - val_loss: 0.4651 - val_acc: 0.7500\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1292 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.7500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1700 - acc: 0.9500 - val_loss: 0.4686 - val_acc: 0.7500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1429 - acc: 0.9833 - val_loss: 0.4705 - val_acc: 0.7500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1729 - acc: 0.9833 - val_loss: 0.4705 - val_acc: 0.7500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1643 - acc: 0.9667 - val_loss: 0.4678 - val_acc: 0.7500\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1444 - acc: 0.9833 - val_loss: 0.4635 - val_acc: 0.7500\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1314 - acc: 0.9833 - val_loss: 0.4601 - val_acc: 0.8000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1417 - acc: 0.9667 - val_loss: 0.4581 - val_acc: 0.8000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.1492 - acc: 0.9833 - val_loss: 0.4570 - val_acc: 0.8000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1544 - acc: 0.9833 - val_loss: 0.4559 - val_acc: 0.8000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1544 - acc: 0.9500 - val_loss: 0.4535 - val_acc: 0.8000\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1502 - acc: 0.9667 - val_loss: 0.4537 - val_acc: 0.7500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 830us/sample - loss: 0.1407 - acc: 0.9667 - val_loss: 0.4550 - val_acc: 0.7500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.1272 - acc: 1.0000 - val_loss: 0.4577 - val_acc: 0.7500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1220 - acc: 0.9833 - val_loss: 0.4608 - val_acc: 0.7500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1497 - acc: 0.9833 - val_loss: 0.4619 - val_acc: 0.7500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1620 - acc: 0.9833 - val_loss: 0.4640 - val_acc: 0.7500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1512 - acc: 0.9833 - val_loss: 0.4670 - val_acc: 0.7500\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1267 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.7500\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1354 - acc: 0.9833 - val_loss: 0.4663 - val_acc: 0.7500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1316 - acc: 0.9833 - val_loss: 0.4685 - val_acc: 0.7500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1491 - acc: 0.9667 - val_loss: 0.4686 - val_acc: 0.7500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1407 - acc: 0.9500 - val_loss: 0.4713 - val_acc: 0.7500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1142 - acc: 1.0000 - val_loss: 0.4734 - val_acc: 0.7500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1451 - acc: 0.9833 - val_loss: 0.4751 - val_acc: 0.7500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1335 - acc: 0.9833 - val_loss: 0.4773 - val_acc: 0.7500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1573 - acc: 0.9833 - val_loss: 0.4862 - val_acc: 0.8000\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1212 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.8000\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.1564 - acc: 0.9667 - val_loss: 0.4917 - val_acc: 0.8000\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1447 - acc: 0.9833 - val_loss: 0.4903 - val_acc: 0.8000\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1369 - acc: 0.9833 - val_loss: 0.4816 - val_acc: 0.8000\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1509 - acc: 0.9667 - val_loss: 0.4740 - val_acc: 0.8000\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1027 - acc: 0.9833 - val_loss: 0.4692 - val_acc: 0.8000\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1487 - acc: 0.9667 - val_loss: 0.4694 - val_acc: 0.8000\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1223 - acc: 0.9667 - val_loss: 0.4736 - val_acc: 0.8000\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 726us/sample - loss: 0.1676 - acc: 0.9500 - val_loss: 0.4759 - val_acc: 0.8000\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1493 - acc: 0.9500 - val_loss: 0.4751 - val_acc: 0.8000\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1259 - acc: 0.9667 - val_loss: 0.4713 - val_acc: 0.8000\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1238 - acc: 0.9833 - val_loss: 0.4654 - val_acc: 0.8000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1189 - acc: 1.0000 - val_loss: 0.4598 - val_acc: 0.8000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1551 - acc: 0.9833 - val_loss: 0.4545 - val_acc: 0.8000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1168 - acc: 0.9833 - val_loss: 0.4508 - val_acc: 0.8000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1082 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.8000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1265 - acc: 0.9833 - val_loss: 0.4464 - val_acc: 0.8000\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.4433 - val_acc: 0.8000\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1344 - acc: 1.0000 - val_loss: 0.4408 - val_acc: 0.8000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.4381 - val_acc: 0.8000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1401 - acc: 0.9667 - val_loss: 0.4368 - val_acc: 0.8000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 0.4385 - val_acc: 0.8000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1142 - acc: 0.9833 - val_loss: 0.4424 - val_acc: 0.8000\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1262 - acc: 0.9833 - val_loss: 0.4468 - val_acc: 0.8000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1142 - acc: 0.9833 - val_loss: 0.4508 - val_acc: 0.8000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1272 - acc: 0.9667 - val_loss: 0.4535 - val_acc: 0.8000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2028 - acc: 0.9333 - val_loss: 0.4529 - val_acc: 0.8000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1213 - acc: 0.9833 - val_loss: 0.4483 - val_acc: 0.8000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1219 - acc: 0.9833 - val_loss: 0.4438 - val_acc: 0.8000\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1105 - acc: 1.0000 - val_loss: 0.4392 - val_acc: 0.8000\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1284 - acc: 0.9667 - val_loss: 0.4342 - val_acc: 0.8000\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1321 - acc: 0.9833 - val_loss: 0.4291 - val_acc: 0.8000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1282 - acc: 0.9833 - val_loss: 0.4250 - val_acc: 0.8000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.1265 - acc: 0.9833 - val_loss: 0.4220 - val_acc: 0.8000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0984 - acc: 1.0000 - val_loss: 0.4229 - val_acc: 0.8000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1147 - acc: 0.9833 - val_loss: 0.4201 - val_acc: 0.8000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1155 - acc: 0.9667 - val_loss: 0.4149 - val_acc: 0.8000\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1589 - acc: 0.9500 - val_loss: 0.4131 - val_acc: 0.8500\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1378 - acc: 0.9667 - val_loss: 0.4122 - val_acc: 0.8500\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.0945 - acc: 1.0000 - val_loss: 0.4116 - val_acc: 0.8500\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1252 - acc: 0.9833 - val_loss: 0.4141 - val_acc: 0.9000\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1235 - acc: 0.9667 - val_loss: 0.4174 - val_acc: 0.9000\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1077 - acc: 1.0000 - val_loss: 0.4155 - val_acc: 0.9000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1321 - acc: 0.9833 - val_loss: 0.4112 - val_acc: 0.9000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1076 - acc: 1.0000 - val_loss: 0.4053 - val_acc: 0.8500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1456 - acc: 0.9667 - val_loss: 0.4020 - val_acc: 0.8500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1468 - acc: 0.9667 - val_loss: 0.4021 - val_acc: 0.8500\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1063 - acc: 0.9833 - val_loss: 0.4037 - val_acc: 0.8000\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1111 - acc: 0.9833 - val_loss: 0.4085 - val_acc: 0.8000\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.4128 - val_acc: 0.8000\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.1046 - acc: 1.0000 - val_loss: 0.4167 - val_acc: 0.8000\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1008 - acc: 0.9667 - val_loss: 0.4161 - val_acc: 0.8000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1400 - acc: 0.9667 - val_loss: 0.4113 - val_acc: 0.8000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0942 - acc: 1.0000 - val_loss: 0.4035 - val_acc: 0.8000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0996 - acc: 0.9833 - val_loss: 0.4022 - val_acc: 0.8500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1131 - acc: 1.0000 - val_loss: 0.4009 - val_acc: 0.8500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1448 - acc: 0.9833 - val_loss: 0.4003 - val_acc: 0.8500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1303 - acc: 1.0000 - val_loss: 0.4030 - val_acc: 0.8500\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1354 - acc: 0.9500 - val_loss: 0.4097 - val_acc: 0.8500\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1132 - acc: 0.9667 - val_loss: 0.4143 - val_acc: 0.8500\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1012 - acc: 0.9833 - val_loss: 0.4149 - val_acc: 0.8500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1007 - acc: 1.0000 - val_loss: 0.4174 - val_acc: 0.8500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1081 - acc: 1.0000 - val_loss: 0.4250 - val_acc: 0.8500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0883 - acc: 1.0000 - val_loss: 0.4309 - val_acc: 0.8500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 0.4392 - val_acc: 0.8000\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1082 - acc: 0.9833 - val_loss: 0.4462 - val_acc: 0.8000\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1150 - acc: 0.9833 - val_loss: 0.4450 - val_acc: 0.8000\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1046 - acc: 0.9833 - val_loss: 0.4403 - val_acc: 0.8000\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1176 - acc: 0.9833 - val_loss: 0.4391 - val_acc: 0.8000\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1144 - acc: 0.9667 - val_loss: 0.4347 - val_acc: 0.8000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1116 - acc: 1.0000 - val_loss: 0.4306 - val_acc: 0.8000\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1445 - acc: 0.9833 - val_loss: 0.4301 - val_acc: 0.8000\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1223 - acc: 1.0000 - val_loss: 0.4275 - val_acc: 0.8000\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1068 - acc: 0.9833 - val_loss: 0.4200 - val_acc: 0.8000\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0886 - acc: 1.0000 - val_loss: 0.4179 - val_acc: 0.8500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.0898 - acc: 1.0000 - val_loss: 0.4178 - val_acc: 0.8500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1208 - acc: 0.9667 - val_loss: 0.4157 - val_acc: 0.8500\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1314 - acc: 0.9833 - val_loss: 0.4191 - val_acc: 0.8000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0874 - acc: 1.0000 - val_loss: 0.4231 - val_acc: 0.8000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1340 - acc: 0.9333 - val_loss: 0.4229 - val_acc: 0.8000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1046 - acc: 1.0000 - val_loss: 0.4262 - val_acc: 0.8000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0897 - acc: 1.0000 - val_loss: 0.4244 - val_acc: 0.8000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.0886 - acc: 1.0000 - val_loss: 0.4270 - val_acc: 0.8000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 769us/sample - loss: 0.0813 - acc: 1.0000 - val_loss: 0.4310 - val_acc: 0.8000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.0847 - acc: 1.0000 - val_loss: 0.4351 - val_acc: 0.8000\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0909 - acc: 1.0000 - val_loss: 0.4362 - val_acc: 0.8000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0943 - acc: 1.0000 - val_loss: 0.4305 - val_acc: 0.8000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1097 - acc: 0.9667 - val_loss: 0.4217 - val_acc: 0.8500\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0829 - acc: 1.0000 - val_loss: 0.4190 - val_acc: 0.8500\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1113 - acc: 1.0000 - val_loss: 0.4168 - val_acc: 0.8500\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1048 - acc: 0.9667 - val_loss: 0.4161 - val_acc: 0.8500\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1330 - acc: 0.9833 - val_loss: 0.4133 - val_acc: 0.8500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0914 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.8500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0900 - acc: 1.0000 - val_loss: 0.4194 - val_acc: 0.8000\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1398 - acc: 0.9500 - val_loss: 0.4264 - val_acc: 0.8000\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1069 - acc: 0.9667 - val_loss: 0.4343 - val_acc: 0.8000\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1032 - acc: 0.9833 - val_loss: 0.4373 - val_acc: 0.8000\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0873 - acc: 0.9833 - val_loss: 0.4408 - val_acc: 0.8000\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.0890 - acc: 0.9833 - val_loss: 0.4476 - val_acc: 0.8000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1059 - acc: 0.9833 - val_loss: 0.4489 - val_acc: 0.8000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0828 - acc: 1.0000 - val_loss: 0.4463 - val_acc: 0.8000\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1064 - acc: 0.9833 - val_loss: 0.4444 - val_acc: 0.8000\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.4353 - val_acc: 0.8000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0905 - acc: 1.0000 - val_loss: 0.4261 - val_acc: 0.8000\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.4166 - val_acc: 0.8000\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0675 - acc: 1.0000 - val_loss: 0.4088 - val_acc: 0.8000\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1076 - acc: 0.9833 - val_loss: 0.4028 - val_acc: 0.8000\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0818 - acc: 0.9833 - val_loss: 0.3980 - val_acc: 0.8500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0777 - acc: 1.0000 - val_loss: 0.3970 - val_acc: 0.8500\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1044 - acc: 0.9833 - val_loss: 0.3961 - val_acc: 0.8500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.4012 - val_acc: 0.8500\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0750 - acc: 1.0000 - val_loss: 0.4087 - val_acc: 0.8500\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0842 - acc: 1.0000 - val_loss: 0.4145 - val_acc: 0.8000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0698 - acc: 1.0000 - val_loss: 0.4242 - val_acc: 0.8000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0772 - acc: 0.9833 - val_loss: 0.4257 - val_acc: 0.8000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1050 - acc: 0.9833 - val_loss: 0.4193 - val_acc: 0.8000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 707us/sample - loss: 0.0990 - acc: 0.9667 - val_loss: 0.4164 - val_acc: 0.8500\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0619 - acc: 1.0000 - val_loss: 0.4125 - val_acc: 0.8500\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0701 - acc: 1.0000 - val_loss: 0.4119 - val_acc: 0.8500\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.4119 - val_acc: 0.8500\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0897 - acc: 1.0000 - val_loss: 0.4146 - val_acc: 0.8500\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1039 - acc: 1.0000 - val_loss: 0.4157 - val_acc: 0.8500\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0793 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.8500\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 0.4219 - val_acc: 0.8500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0858 - acc: 0.9833 - val_loss: 0.4253 - val_acc: 0.8500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0781 - acc: 0.9833 - val_loss: 0.4290 - val_acc: 0.8000\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.8000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0961 - acc: 0.9667 - val_loss: 0.4228 - val_acc: 0.8000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 787us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.4192 - val_acc: 0.8500\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0886 - acc: 1.0000 - val_loss: 0.4162 - val_acc: 0.8500\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0711 - acc: 1.0000 - val_loss: 0.4118 - val_acc: 0.8500\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0858 - acc: 0.9833 - val_loss: 0.4015 - val_acc: 0.8500\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0811 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.8500\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0645 - acc: 1.0000 - val_loss: 0.3969 - val_acc: 0.8500\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0732 - acc: 1.0000 - val_loss: 0.4030 - val_acc: 0.8500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.4098 - val_acc: 0.8500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0792 - acc: 1.0000 - val_loss: 0.4070 - val_acc: 0.8500\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 727us/sample - loss: 0.1747 - acc: 0.9333 - val_loss: 0.4012 - val_acc: 0.8500\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1044 - acc: 0.9833 - val_loss: 0.4143 - val_acc: 0.8500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0770 - acc: 0.9833 - val_loss: 0.4228 - val_acc: 0.8000\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0920 - acc: 0.9833 - val_loss: 0.4237 - val_acc: 0.8000\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0665 - acc: 1.0000 - val_loss: 0.4185 - val_acc: 0.8000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.4231 - val_acc: 0.8000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.8000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0732 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 0.8000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0744 - acc: 1.0000 - val_loss: 0.4099 - val_acc: 0.8000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 771us/sample - loss: 0.0820 - acc: 1.0000 - val_loss: 0.4078 - val_acc: 0.8000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0680 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.8000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0691 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.8000\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0913 - acc: 1.0000 - val_loss: 0.4200 - val_acc: 0.8000\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0992 - acc: 0.9667 - val_loss: 0.4193 - val_acc: 0.8000\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0830 - acc: 1.0000 - val_loss: 0.4361 - val_acc: 0.8000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0887 - acc: 0.9833 - val_loss: 0.4619 - val_acc: 0.7500\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0831 - acc: 0.9833 - val_loss: 0.4778 - val_acc: 0.7500\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0783 - acc: 0.9833 - val_loss: 0.4809 - val_acc: 0.7500\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0672 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.7500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0976 - acc: 1.0000 - val_loss: 0.4903 - val_acc: 0.7500\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0780 - acc: 0.9833 - val_loss: 0.4875 - val_acc: 0.7500\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0792 - acc: 1.0000 - val_loss: 0.4553 - val_acc: 0.7500\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1026 - acc: 0.9667 - val_loss: 0.4262 - val_acc: 0.7500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0735 - acc: 1.0000 - val_loss: 0.3928 - val_acc: 0.8000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.0629 - acc: 1.0000 - val_loss: 0.3811 - val_acc: 0.8000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 0.3875 - val_acc: 0.8000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0929 - acc: 0.9833 - val_loss: 0.4137 - val_acc: 0.8000\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1411 - acc: 0.9500 - val_loss: 0.4122 - val_acc: 0.8000\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0753 - acc: 1.0000 - val_loss: 0.3982 - val_acc: 0.8500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.3919 - val_acc: 0.8500\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0869 - acc: 1.0000 - val_loss: 0.3914 - val_acc: 0.8500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0826 - acc: 1.0000 - val_loss: 0.3996 - val_acc: 0.8500\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0717 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.7500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0826 - acc: 0.9833 - val_loss: 0.4163 - val_acc: 0.7500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0685 - acc: 1.0000 - val_loss: 0.4252 - val_acc: 0.7500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 0.4278 - val_acc: 0.7500\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0766 - acc: 1.0000 - val_loss: 0.4141 - val_acc: 0.7500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.4095 - val_acc: 0.7500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0864 - acc: 0.9667 - val_loss: 0.4090 - val_acc: 0.7500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.4159 - val_acc: 0.7500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.0790 - acc: 0.9833 - val_loss: 0.4340 - val_acc: 0.7500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.4496 - val_acc: 0.7500\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.4685 - val_acc: 0.7500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0947 - acc: 0.9833 - val_loss: 0.4495 - val_acc: 0.7500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 764us/sample - loss: 0.0548 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 0.7500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.4039 - val_acc: 0.8500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0780 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.8500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0517 - acc: 1.0000 - val_loss: 0.3818 - val_acc: 0.8500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.3862 - val_acc: 0.8500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0760 - acc: 1.0000 - val_loss: 0.3917 - val_acc: 0.8500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.0716 - acc: 1.0000 - val_loss: 0.4039 - val_acc: 0.8500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.0475 - acc: 1.0000 - val_loss: 0.4321 - val_acc: 0.7500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.0711 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.7500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0884 - acc: 0.9667 - val_loss: 0.5046 - val_acc: 0.7000\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.7000\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0653 - acc: 1.0000 - val_loss: 0.5320 - val_acc: 0.7000\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0902 - acc: 0.9833 - val_loss: 0.5058 - val_acc: 0.7500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.4753 - val_acc: 0.7500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 720us/sample - loss: 0.0841 - acc: 0.9833 - val_loss: 0.4400 - val_acc: 0.8000\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.0727 - acc: 1.0000 - val_loss: 0.4329 - val_acc: 0.8000\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.4334 - val_acc: 0.8000\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.4368 - val_acc: 0.7500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0558 - acc: 1.0000 - val_loss: 0.4414 - val_acc: 0.7500\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0611 - acc: 1.0000 - val_loss: 0.4375 - val_acc: 0.7500\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.4256 - val_acc: 0.7500\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.4227 - val_acc: 0.7500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0707 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.7500\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0876 - acc: 0.9833 - val_loss: 0.4150 - val_acc: 0.8000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.4175 - val_acc: 0.8000\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.4385 - val_acc: 0.7500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.4456 - val_acc: 0.7500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.4430 - val_acc: 0.7500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0746 - acc: 0.9833 - val_loss: 0.4308 - val_acc: 0.8000\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0691 - acc: 1.0000 - val_loss: 0.4238 - val_acc: 0.8000\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 0.4300 - val_acc: 0.8000\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.4459 - val_acc: 0.8000\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0790 - acc: 0.9833 - val_loss: 0.4450 - val_acc: 0.7500\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.0876 - acc: 0.9833 - val_loss: 0.4528 - val_acc: 0.7500\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0505 - acc: 1.0000 - val_loss: 0.4484 - val_acc: 0.7500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.4542 - val_acc: 0.7500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.4648 - val_acc: 0.7500\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0577 - acc: 1.0000 - val_loss: 0.4855 - val_acc: 0.7500\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0634 - acc: 0.9833 - val_loss: 0.4624 - val_acc: 0.7500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.7500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.4452 - val_acc: 0.7500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1144 - acc: 0.9833 - val_loss: 0.4593 - val_acc: 0.7500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.0498 - acc: 1.0000 - val_loss: 0.4641 - val_acc: 0.7500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0758 - acc: 0.9833 - val_loss: 0.4794 - val_acc: 0.7500\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.7500\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0926 - acc: 1.0000 - val_loss: 0.4909 - val_acc: 0.7500\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 570us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.7500\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.4688 - val_acc: 0.7500\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0587 - acc: 0.9833 - val_loss: 0.4659 - val_acc: 0.7500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0646 - acc: 0.9833 - val_loss: 0.4547 - val_acc: 0.8000\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.8000\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0932 - acc: 1.0000 - val_loss: 0.4644 - val_acc: 0.8000\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 0.4507 - val_acc: 0.8000\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0623 - acc: 1.0000 - val_loss: 0.4538 - val_acc: 0.8000\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.4704 - val_acc: 0.8000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0988 - acc: 0.9833 - val_loss: 0.4918 - val_acc: 0.7500\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0759 - acc: 1.0000 - val_loss: 0.5040 - val_acc: 0.7500\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0737 - acc: 0.9833 - val_loss: 0.5095 - val_acc: 0.7500\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0817 - acc: 0.9833 - val_loss: 0.5043 - val_acc: 0.7500\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.7500\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.7500\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.4581 - val_acc: 0.7500\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.4403 - val_acc: 0.8000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0678 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 0.8500\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0564 - acc: 0.9833 - val_loss: 0.4101 - val_acc: 0.8500\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.4086 - val_acc: 0.8500\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0567 - acc: 1.0000 - val_loss: 0.4083 - val_acc: 0.8500\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0603 - acc: 0.9833 - val_loss: 0.4131 - val_acc: 0.8500\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0667 - acc: 0.9833 - val_loss: 0.4234 - val_acc: 0.8500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 587us/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 0.4135 - val_acc: 0.8500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0831 - acc: 0.9833 - val_loss: 0.4149 - val_acc: 0.8500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.4143 - val_acc: 0.8500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0671 - acc: 0.9667 - val_loss: 0.3910 - val_acc: 0.8500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.3736 - val_acc: 0.8500\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.3659 - val_acc: 0.8500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0862 - acc: 0.9833 - val_loss: 0.3729 - val_acc: 0.8500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.3798 - val_acc: 0.8500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0489 - acc: 1.0000 - val_loss: 0.3874 - val_acc: 0.8500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.3997 - val_acc: 0.8000\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0910 - acc: 0.9833 - val_loss: 0.4048 - val_acc: 0.8000\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.4342 - val_acc: 0.8000\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.4646 - val_acc: 0.7500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.4879 - val_acc: 0.7500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.1461 - acc: 0.9500 - val_loss: 0.4484 - val_acc: 0.7500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.4246 - val_acc: 0.8000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0758 - acc: 0.9667 - val_loss: 0.4221 - val_acc: 0.8000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0463 - acc: 1.0000 - val_loss: 0.4402 - val_acc: 0.7500\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.4597 - val_acc: 0.7500\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.4894 - val_acc: 0.7500\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0527 - acc: 1.0000 - val_loss: 0.4970 - val_acc: 0.7500\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0574 - acc: 1.0000 - val_loss: 0.4911 - val_acc: 0.7500\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.4768 - val_acc: 0.7500\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0780 - acc: 0.9833 - val_loss: 0.4590 - val_acc: 0.7500\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.4325 - val_acc: 0.8000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.4105 - val_acc: 0.8500\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.0683 - acc: 0.9833 - val_loss: 0.4014 - val_acc: 0.8500\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.0672 - acc: 1.0000 - val_loss: 0.3959 - val_acc: 0.8500\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.0786 - acc: 1.0000 - val_loss: 0.4008 - val_acc: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmT4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.7159 - acc: 0.6750\n",
            "test loss, test acc: [0.7158908195182448, 0.675]\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P03E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 1 2 1 2 1 2 1 1 1 2 1 2 2 1 2 1 1 1 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.4962 - acc: 0.2167 - val_loss: 1.3777 - val_acc: 0.3500\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 1.2907 - acc: 0.4833 - val_loss: 1.3689 - val_acc: 0.5000\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 1.2167 - acc: 0.4667 - val_loss: 1.3632 - val_acc: 0.5000\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 1.0980 - acc: 0.6167 - val_loss: 1.3562 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 1.0408 - acc: 0.6000 - val_loss: 1.3475 - val_acc: 0.4500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 1.0010 - acc: 0.5500 - val_loss: 1.3380 - val_acc: 0.5000\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.9819 - acc: 0.7000 - val_loss: 1.3281 - val_acc: 0.5500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.9688 - acc: 0.7000 - val_loss: 1.3174 - val_acc: 0.5000\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.9057 - acc: 0.8000 - val_loss: 1.3066 - val_acc: 0.5000\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.8906 - acc: 0.8000 - val_loss: 1.2954 - val_acc: 0.5000\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.8371 - acc: 0.8000 - val_loss: 1.2840 - val_acc: 0.5000\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.8434 - acc: 0.7833 - val_loss: 1.2727 - val_acc: 0.5000\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.8234 - acc: 0.6667 - val_loss: 1.2614 - val_acc: 0.5000\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.8019 - acc: 0.6833 - val_loss: 1.2498 - val_acc: 0.5000\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.7801 - acc: 0.8167 - val_loss: 1.2384 - val_acc: 0.5000\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.7755 - acc: 0.7833 - val_loss: 1.2272 - val_acc: 0.5000\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.7537 - acc: 0.8000 - val_loss: 1.2161 - val_acc: 0.5000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.7511 - acc: 0.7667 - val_loss: 1.2057 - val_acc: 0.5000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.7303 - acc: 0.7500 - val_loss: 1.1949 - val_acc: 0.5000\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.7263 - acc: 0.8000 - val_loss: 1.1849 - val_acc: 0.5000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.7239 - acc: 0.7667 - val_loss: 1.1747 - val_acc: 0.5000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.7009 - acc: 0.7500 - val_loss: 1.1648 - val_acc: 0.5000\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.7039 - acc: 0.7167 - val_loss: 1.1554 - val_acc: 0.4500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.6720 - acc: 0.7667 - val_loss: 1.1461 - val_acc: 0.4500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.6818 - acc: 0.7500 - val_loss: 1.1371 - val_acc: 0.4500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.6858 - acc: 0.7500 - val_loss: 1.1286 - val_acc: 0.4500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.6541 - acc: 0.7833 - val_loss: 1.1200 - val_acc: 0.4500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.6566 - acc: 0.7333 - val_loss: 1.1123 - val_acc: 0.4500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.6703 - acc: 0.7667 - val_loss: 1.1048 - val_acc: 0.4500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.6468 - acc: 0.7167 - val_loss: 1.0968 - val_acc: 0.4000\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.6523 - acc: 0.7500 - val_loss: 1.0891 - val_acc: 0.4000\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.6712 - acc: 0.7167 - val_loss: 1.0823 - val_acc: 0.4000\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.6155 - acc: 0.7500 - val_loss: 1.0749 - val_acc: 0.4000\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.6228 - acc: 0.8333 - val_loss: 1.0679 - val_acc: 0.4000\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.6139 - acc: 0.7833 - val_loss: 1.0606 - val_acc: 0.4000\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.6128 - acc: 0.7500 - val_loss: 1.0545 - val_acc: 0.4000\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.6067 - acc: 0.8333 - val_loss: 1.0478 - val_acc: 0.4000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.6001 - acc: 0.7833 - val_loss: 1.0418 - val_acc: 0.4000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.6132 - acc: 0.7000 - val_loss: 1.0357 - val_acc: 0.3500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.5796 - acc: 0.7667 - val_loss: 1.0298 - val_acc: 0.3500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.5793 - acc: 0.7833 - val_loss: 1.0256 - val_acc: 0.3500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.5812 - acc: 0.7833 - val_loss: 1.0211 - val_acc: 0.3500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.5732 - acc: 0.8500 - val_loss: 1.0169 - val_acc: 0.3500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5636 - acc: 0.8167 - val_loss: 1.0133 - val_acc: 0.3500\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.5770 - acc: 0.7667 - val_loss: 1.0119 - val_acc: 0.3500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.5576 - acc: 0.8333 - val_loss: 1.0130 - val_acc: 0.3500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.5656 - acc: 0.8000 - val_loss: 1.0141 - val_acc: 0.3500\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.5837 - acc: 0.8000 - val_loss: 1.0133 - val_acc: 0.3500\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.5323 - acc: 0.8333 - val_loss: 1.0143 - val_acc: 0.3500\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5604 - acc: 0.7500 - val_loss: 1.0147 - val_acc: 0.3500\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.5639 - acc: 0.8000 - val_loss: 1.0133 - val_acc: 0.3500\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.5234 - acc: 0.8500 - val_loss: 1.0103 - val_acc: 0.3500\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 584us/sample - loss: 0.5436 - acc: 0.7833 - val_loss: 1.0095 - val_acc: 0.3500\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.5459 - acc: 0.8333 - val_loss: 1.0102 - val_acc: 0.3500\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.5400 - acc: 0.8000 - val_loss: 1.0108 - val_acc: 0.3500\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.4947 - acc: 0.8333 - val_loss: 1.0154 - val_acc: 0.3500\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.5284 - acc: 0.8000 - val_loss: 1.0205 - val_acc: 0.3500\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.5070 - acc: 0.8333 - val_loss: 1.0229 - val_acc: 0.3500\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.5272 - acc: 0.8500 - val_loss: 1.0256 - val_acc: 0.3500\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4882 - acc: 0.8833 - val_loss: 1.0319 - val_acc: 0.3500\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.4993 - acc: 0.8500 - val_loss: 1.0363 - val_acc: 0.3500\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.4845 - acc: 0.8167 - val_loss: 1.0430 - val_acc: 0.3500\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.5277 - acc: 0.7833 - val_loss: 1.0518 - val_acc: 0.3500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.4786 - acc: 0.8500 - val_loss: 1.0542 - val_acc: 0.3500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.4766 - acc: 0.8667 - val_loss: 1.0591 - val_acc: 0.3500\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 762us/sample - loss: 0.4726 - acc: 0.8500 - val_loss: 1.0658 - val_acc: 0.3500\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 721us/sample - loss: 0.4601 - acc: 0.8833 - val_loss: 1.0775 - val_acc: 0.3500\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.4789 - acc: 0.9000 - val_loss: 1.0874 - val_acc: 0.3500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.4333 - acc: 0.9167 - val_loss: 1.1007 - val_acc: 0.3500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.4548 - acc: 0.8667 - val_loss: 1.1134 - val_acc: 0.3500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.4539 - acc: 0.8500 - val_loss: 1.1273 - val_acc: 0.3500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.4568 - acc: 0.8833 - val_loss: 1.1359 - val_acc: 0.3500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4360 - acc: 0.9167 - val_loss: 1.1478 - val_acc: 0.3500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.4459 - acc: 0.8500 - val_loss: 1.1655 - val_acc: 0.3500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.4495 - acc: 0.8333 - val_loss: 1.1739 - val_acc: 0.3500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.4380 - acc: 0.8833 - val_loss: 1.1822 - val_acc: 0.3500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.4120 - acc: 0.9000 - val_loss: 1.1989 - val_acc: 0.3500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.4395 - acc: 0.9333 - val_loss: 1.2123 - val_acc: 0.3500\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.3915 - acc: 0.9167 - val_loss: 1.2481 - val_acc: 0.3500\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3695 - acc: 0.9167 - val_loss: 1.2995 - val_acc: 0.3500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.3720 - acc: 0.9000 - val_loss: 1.3414 - val_acc: 0.3500\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.3959 - acc: 0.8833 - val_loss: 1.3480 - val_acc: 0.3500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.3776 - acc: 0.9000 - val_loss: 1.3433 - val_acc: 0.3500\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.3834 - acc: 0.9000 - val_loss: 1.3382 - val_acc: 0.3500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3935 - acc: 0.8667 - val_loss: 1.3416 - val_acc: 0.3500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3533 - acc: 0.9333 - val_loss: 1.3299 - val_acc: 0.3500\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.4365 - acc: 0.8500 - val_loss: 1.3302 - val_acc: 0.3500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.4021 - acc: 0.9167 - val_loss: 1.3142 - val_acc: 0.3500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.3776 - acc: 0.9167 - val_loss: 1.3232 - val_acc: 0.3500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.3912 - acc: 0.9000 - val_loss: 1.3059 - val_acc: 0.3500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.3339 - acc: 0.9667 - val_loss: 1.3108 - val_acc: 0.3500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.3342 - acc: 0.9500 - val_loss: 1.3211 - val_acc: 0.3500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.3368 - acc: 0.9333 - val_loss: 1.3540 - val_acc: 0.3500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.3405 - acc: 0.9333 - val_loss: 1.3865 - val_acc: 0.3500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3377 - acc: 0.9333 - val_loss: 1.4104 - val_acc: 0.3500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.3804 - acc: 0.9000 - val_loss: 1.4404 - val_acc: 0.3500\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.3415 - acc: 0.9000 - val_loss: 1.4663 - val_acc: 0.3500\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.3221 - acc: 0.9000 - val_loss: 1.4739 - val_acc: 0.3500\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3118 - acc: 0.9333 - val_loss: 1.4792 - val_acc: 0.3500\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3174 - acc: 0.9167 - val_loss: 1.4813 - val_acc: 0.3500\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.3404 - acc: 0.9000 - val_loss: 1.4609 - val_acc: 0.3500\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3766 - acc: 0.8667 - val_loss: 1.4081 - val_acc: 0.3500\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.3521 - acc: 0.9000 - val_loss: 1.3895 - val_acc: 0.3500\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.3096 - acc: 0.9333 - val_loss: 1.3787 - val_acc: 0.3500\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3144 - acc: 0.9833 - val_loss: 1.4069 - val_acc: 0.3500\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.3365 - acc: 0.9000 - val_loss: 1.4532 - val_acc: 0.3500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.2977 - acc: 0.8833 - val_loss: 1.4851 - val_acc: 0.3500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.3252 - acc: 0.9000 - val_loss: 1.5156 - val_acc: 0.3500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3304 - acc: 0.9333 - val_loss: 1.5268 - val_acc: 0.3500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.3263 - acc: 0.9167 - val_loss: 1.5097 - val_acc: 0.3500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.3250 - acc: 0.9000 - val_loss: 1.4597 - val_acc: 0.4000\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2771 - acc: 0.9833 - val_loss: 1.4506 - val_acc: 0.4000\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2870 - acc: 0.9000 - val_loss: 1.4366 - val_acc: 0.4000\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2810 - acc: 0.9333 - val_loss: 1.4557 - val_acc: 0.4000\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2977 - acc: 0.9167 - val_loss: 1.4465 - val_acc: 0.4000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2818 - acc: 0.9500 - val_loss: 1.4871 - val_acc: 0.4000\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.3078 - acc: 0.9500 - val_loss: 1.5199 - val_acc: 0.4000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.3315 - acc: 0.9000 - val_loss: 1.5479 - val_acc: 0.4000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.2866 - acc: 0.9167 - val_loss: 1.5399 - val_acc: 0.3500\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2961 - acc: 0.9167 - val_loss: 1.5342 - val_acc: 0.3500\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2702 - acc: 0.9333 - val_loss: 1.4906 - val_acc: 0.3500\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.2988 - acc: 0.9167 - val_loss: 1.4692 - val_acc: 0.3500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2769 - acc: 0.9667 - val_loss: 1.4722 - val_acc: 0.4000\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2602 - acc: 0.9833 - val_loss: 1.5002 - val_acc: 0.4000\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2610 - acc: 0.9667 - val_loss: 1.5593 - val_acc: 0.4000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.2532 - acc: 0.9833 - val_loss: 1.6427 - val_acc: 0.4000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2475 - acc: 0.9667 - val_loss: 1.7210 - val_acc: 0.4000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2302 - acc: 0.9500 - val_loss: 1.8097 - val_acc: 0.4000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2352 - acc: 0.9167 - val_loss: 1.8514 - val_acc: 0.4000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.2492 - acc: 0.9500 - val_loss: 1.8583 - val_acc: 0.4000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.2393 - acc: 0.9500 - val_loss: 1.8413 - val_acc: 0.4000\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2740 - acc: 0.9500 - val_loss: 1.8122 - val_acc: 0.4000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.2890 - acc: 0.9000 - val_loss: 1.7578 - val_acc: 0.4000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2486 - acc: 0.9167 - val_loss: 1.7671 - val_acc: 0.4000\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2844 - acc: 0.9333 - val_loss: 1.7429 - val_acc: 0.4000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2485 - acc: 0.9500 - val_loss: 1.7052 - val_acc: 0.4000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2318 - acc: 0.9500 - val_loss: 1.6968 - val_acc: 0.4000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2705 - acc: 0.9500 - val_loss: 1.7069 - val_acc: 0.4000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2419 - acc: 0.9167 - val_loss: 1.7352 - val_acc: 0.4000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.2366 - acc: 0.9333 - val_loss: 1.7230 - val_acc: 0.4000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2897 - acc: 0.9167 - val_loss: 1.7732 - val_acc: 0.4000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2174 - acc: 0.9500 - val_loss: 1.7639 - val_acc: 0.4000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.2420 - acc: 0.9333 - val_loss: 1.7420 - val_acc: 0.4000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.2288 - acc: 0.9333 - val_loss: 1.7245 - val_acc: 0.4000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2857 - acc: 0.8833 - val_loss: 1.7265 - val_acc: 0.4000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.2636 - acc: 0.9333 - val_loss: 1.6841 - val_acc: 0.4000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1892 - acc: 0.9833 - val_loss: 1.6418 - val_acc: 0.4000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2638 - acc: 0.8833 - val_loss: 1.6215 - val_acc: 0.4000\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2582 - acc: 0.9000 - val_loss: 1.6086 - val_acc: 0.4000\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2299 - acc: 0.9000 - val_loss: 1.6222 - val_acc: 0.4000\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2359 - acc: 0.9667 - val_loss: 1.6612 - val_acc: 0.4000\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2259 - acc: 0.9500 - val_loss: 1.7096 - val_acc: 0.4000\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2583 - acc: 0.9167 - val_loss: 1.7605 - val_acc: 0.4000\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.2557 - acc: 0.9167 - val_loss: 1.8043 - val_acc: 0.4000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2156 - acc: 0.9333 - val_loss: 1.8037 - val_acc: 0.4000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2151 - acc: 0.9500 - val_loss: 1.8131 - val_acc: 0.4000\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2493 - acc: 0.9000 - val_loss: 1.8354 - val_acc: 0.4000\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2591 - acc: 0.8833 - val_loss: 1.8375 - val_acc: 0.4000\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1924 - acc: 0.9667 - val_loss: 1.8294 - val_acc: 0.4000\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.2338 - acc: 0.9000 - val_loss: 1.8206 - val_acc: 0.4000\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 758us/sample - loss: 0.2359 - acc: 0.9500 - val_loss: 1.7944 - val_acc: 0.4000\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2120 - acc: 0.9333 - val_loss: 1.8169 - val_acc: 0.4000\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1925 - acc: 0.9500 - val_loss: 1.8396 - val_acc: 0.4000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1867 - acc: 0.9500 - val_loss: 1.8683 - val_acc: 0.4000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2277 - acc: 0.9167 - val_loss: 1.9069 - val_acc: 0.4000\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1724 - acc: 0.9500 - val_loss: 1.9159 - val_acc: 0.4000\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.2400 - acc: 0.9500 - val_loss: 1.8755 - val_acc: 0.4000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2146 - acc: 0.9333 - val_loss: 1.7871 - val_acc: 0.4000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2312 - acc: 0.9333 - val_loss: 1.7629 - val_acc: 0.4000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1991 - acc: 0.9500 - val_loss: 1.7361 - val_acc: 0.4000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2068 - acc: 0.9500 - val_loss: 1.7287 - val_acc: 0.4000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2290 - acc: 0.9333 - val_loss: 1.7064 - val_acc: 0.4000\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.2202 - acc: 0.9667 - val_loss: 1.6466 - val_acc: 0.4000\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1971 - acc: 1.0000 - val_loss: 1.6506 - val_acc: 0.4000\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1924 - acc: 1.0000 - val_loss: 1.6860 - val_acc: 0.4000\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1851 - acc: 0.9500 - val_loss: 1.7271 - val_acc: 0.4000\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1917 - acc: 0.9833 - val_loss: 1.7727 - val_acc: 0.4000\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1772 - acc: 0.9833 - val_loss: 1.8407 - val_acc: 0.4000\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1872 - acc: 0.9667 - val_loss: 1.9039 - val_acc: 0.4000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1724 - acc: 0.9500 - val_loss: 1.9216 - val_acc: 0.4000\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2137 - acc: 0.9500 - val_loss: 1.9164 - val_acc: 0.4000\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2388 - acc: 0.9167 - val_loss: 1.8972 - val_acc: 0.4000\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2487 - acc: 0.9000 - val_loss: 1.8469 - val_acc: 0.4000\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.2055 - acc: 0.9167 - val_loss: 1.8245 - val_acc: 0.4000\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.2111 - acc: 0.9500 - val_loss: 1.8199 - val_acc: 0.4000\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1924 - acc: 0.9333 - val_loss: 1.7964 - val_acc: 0.4000\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1891 - acc: 0.9333 - val_loss: 1.7839 - val_acc: 0.4000\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1745 - acc: 0.9833 - val_loss: 1.7740 - val_acc: 0.4000\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1839 - acc: 0.9833 - val_loss: 1.7913 - val_acc: 0.4000\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1797 - acc: 0.9667 - val_loss: 1.7863 - val_acc: 0.4000\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 775us/sample - loss: 0.1898 - acc: 0.9500 - val_loss: 1.7802 - val_acc: 0.4000\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 713us/sample - loss: 0.2307 - acc: 0.9000 - val_loss: 1.7802 - val_acc: 0.4000\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2032 - acc: 0.9667 - val_loss: 1.8289 - val_acc: 0.4000\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.1879 - acc: 0.9833 - val_loss: 1.8951 - val_acc: 0.4000\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1558 - acc: 0.9667 - val_loss: 1.9873 - val_acc: 0.4000\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1878 - acc: 0.9667 - val_loss: 2.0329 - val_acc: 0.4000\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1553 - acc: 0.9833 - val_loss: 2.0338 - val_acc: 0.4000\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.1890 - acc: 0.9333 - val_loss: 2.0148 - val_acc: 0.4000\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.2142 - acc: 0.9500 - val_loss: 2.0002 - val_acc: 0.4000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.2116 - acc: 0.9333 - val_loss: 1.9775 - val_acc: 0.4000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.1750 - acc: 0.9500 - val_loss: 1.9343 - val_acc: 0.4000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1481 - acc: 1.0000 - val_loss: 1.9079 - val_acc: 0.4000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1811 - acc: 0.9667 - val_loss: 1.8569 - val_acc: 0.4000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1834 - acc: 0.9500 - val_loss: 1.8348 - val_acc: 0.4000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.2138 - acc: 0.9500 - val_loss: 1.7912 - val_acc: 0.4000\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1480 - acc: 1.0000 - val_loss: 1.8103 - val_acc: 0.4000\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1991 - acc: 0.9500 - val_loss: 1.8206 - val_acc: 0.4000\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.2013 - acc: 0.9167 - val_loss: 1.7617 - val_acc: 0.4000\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1501 - acc: 0.9667 - val_loss: 1.7242 - val_acc: 0.4000\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1924 - acc: 0.9333 - val_loss: 1.6536 - val_acc: 0.4000\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 739us/sample - loss: 0.1822 - acc: 0.9667 - val_loss: 1.6427 - val_acc: 0.4000\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.2076 - acc: 0.9167 - val_loss: 1.6145 - val_acc: 0.4000\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.2388 - acc: 0.9000 - val_loss: 1.6305 - val_acc: 0.4500\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2307 - acc: 0.9000 - val_loss: 1.6783 - val_acc: 0.4000\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2172 - acc: 0.9333 - val_loss: 1.6728 - val_acc: 0.4500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1502 - acc: 0.9833 - val_loss: 1.7245 - val_acc: 0.4000\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.2055 - acc: 0.9167 - val_loss: 1.7525 - val_acc: 0.4000\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1518 - acc: 0.9667 - val_loss: 1.7294 - val_acc: 0.4000\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1825 - acc: 0.9500 - val_loss: 1.6770 - val_acc: 0.4500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1934 - acc: 0.9667 - val_loss: 1.6066 - val_acc: 0.4500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.1743 - acc: 0.9667 - val_loss: 1.5200 - val_acc: 0.4500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1710 - acc: 0.9333 - val_loss: 1.4905 - val_acc: 0.4500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1707 - acc: 0.9833 - val_loss: 1.4888 - val_acc: 0.4500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.1806 - acc: 0.9833 - val_loss: 1.5250 - val_acc: 0.4500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1713 - acc: 0.9667 - val_loss: 1.5385 - val_acc: 0.4500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1622 - acc: 0.9500 - val_loss: 1.5560 - val_acc: 0.4500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 732us/sample - loss: 0.1486 - acc: 0.9667 - val_loss: 1.5744 - val_acc: 0.4500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.2112 - acc: 0.9500 - val_loss: 1.6013 - val_acc: 0.4500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 754us/sample - loss: 0.1568 - acc: 0.9500 - val_loss: 1.5854 - val_acc: 0.4500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.1322 - acc: 0.9667 - val_loss: 1.5419 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 744us/sample - loss: 0.1539 - acc: 0.9667 - val_loss: 1.5002 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1890 - acc: 0.8833 - val_loss: 1.4072 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2239 - acc: 0.9167 - val_loss: 1.3222 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2249 - acc: 0.9167 - val_loss: 1.3318 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1709 - acc: 0.9667 - val_loss: 1.3458 - val_acc: 0.5000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 843us/sample - loss: 0.1701 - acc: 0.9833 - val_loss: 1.3837 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1849 - acc: 0.9833 - val_loss: 1.4482 - val_acc: 0.4500\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1608 - acc: 0.9500 - val_loss: 1.4889 - val_acc: 0.4500\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1543 - acc: 0.9833 - val_loss: 1.5076 - val_acc: 0.4500\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1755 - acc: 0.9667 - val_loss: 1.5012 - val_acc: 0.4500\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1572 - acc: 0.9833 - val_loss: 1.5009 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1394 - acc: 0.9833 - val_loss: 1.4725 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1789 - acc: 0.9167 - val_loss: 1.4054 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1645 - acc: 0.9667 - val_loss: 1.3462 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1713 - acc: 0.9500 - val_loss: 1.2905 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2102 - acc: 0.9500 - val_loss: 1.2868 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1921 - acc: 0.9833 - val_loss: 1.3218 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1733 - acc: 0.9667 - val_loss: 1.3819 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 724us/sample - loss: 0.1465 - acc: 1.0000 - val_loss: 1.4743 - val_acc: 0.4500\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1063 - acc: 0.9833 - val_loss: 1.5365 - val_acc: 0.4500\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1778 - acc: 0.9667 - val_loss: 1.5755 - val_acc: 0.4500\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.1739 - acc: 0.9500 - val_loss: 1.5859 - val_acc: 0.4500\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1822 - acc: 0.9500 - val_loss: 1.4960 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1484 - acc: 0.9667 - val_loss: 1.4507 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1616 - acc: 0.9500 - val_loss: 1.4129 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1373 - acc: 1.0000 - val_loss: 1.4056 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1507 - acc: 0.9667 - val_loss: 1.4042 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1749 - acc: 0.9500 - val_loss: 1.4401 - val_acc: 0.5000\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1566 - acc: 0.9500 - val_loss: 1.4940 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1426 - acc: 0.9833 - val_loss: 1.4986 - val_acc: 0.5000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1379 - acc: 0.9667 - val_loss: 1.4874 - val_acc: 0.5000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1755 - acc: 0.9667 - val_loss: 1.4449 - val_acc: 0.5000\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.2049 - acc: 0.9167 - val_loss: 1.4117 - val_acc: 0.5000\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1712 - acc: 0.9500 - val_loss: 1.3353 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1754 - acc: 0.9500 - val_loss: 1.2713 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.1262 - acc: 0.9833 - val_loss: 1.2277 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 796us/sample - loss: 0.1322 - acc: 0.9833 - val_loss: 1.2310 - val_acc: 0.5500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1676 - acc: 0.9500 - val_loss: 1.2453 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 810us/sample - loss: 0.1400 - acc: 0.9667 - val_loss: 1.2343 - val_acc: 0.5500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1363 - acc: 1.0000 - val_loss: 1.2445 - val_acc: 0.5500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 720us/sample - loss: 0.1461 - acc: 0.9833 - val_loss: 1.2979 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.1444 - acc: 0.9667 - val_loss: 1.3207 - val_acc: 0.5000\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1786 - acc: 0.9500 - val_loss: 1.3125 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1458 - acc: 0.9667 - val_loss: 1.2783 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1137 - acc: 1.0000 - val_loss: 1.2211 - val_acc: 0.5500\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1892 - acc: 0.9667 - val_loss: 1.1877 - val_acc: 0.5500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1203 - acc: 1.0000 - val_loss: 1.1469 - val_acc: 0.5500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2135 - acc: 0.9167 - val_loss: 1.1042 - val_acc: 0.5500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1407 - acc: 0.9500 - val_loss: 1.0914 - val_acc: 0.6000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1810 - acc: 0.9500 - val_loss: 1.0740 - val_acc: 0.6000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1456 - acc: 0.9833 - val_loss: 1.0686 - val_acc: 0.6000\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1410 - acc: 0.9667 - val_loss: 1.0804 - val_acc: 0.5500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2517 - acc: 0.9500 - val_loss: 1.0540 - val_acc: 0.5500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1551 - acc: 0.9667 - val_loss: 1.0441 - val_acc: 0.5500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1327 - acc: 1.0000 - val_loss: 1.0403 - val_acc: 0.5500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1991 - acc: 0.9500 - val_loss: 1.0525 - val_acc: 0.5500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1457 - acc: 0.9833 - val_loss: 1.0602 - val_acc: 0.5500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1299 - acc: 0.9833 - val_loss: 1.0893 - val_acc: 0.5500\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1763 - acc: 0.9333 - val_loss: 1.1134 - val_acc: 0.5500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1307 - acc: 0.9667 - val_loss: 1.1399 - val_acc: 0.5500\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1112 - acc: 0.9833 - val_loss: 1.1712 - val_acc: 0.5500\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1380 - acc: 0.9667 - val_loss: 1.1975 - val_acc: 0.5500\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1453 - acc: 0.9500 - val_loss: 1.1861 - val_acc: 0.5500\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1577 - acc: 0.9500 - val_loss: 1.1706 - val_acc: 0.5500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1480 - acc: 0.9667 - val_loss: 1.1790 - val_acc: 0.5500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.1280 - acc: 0.9833 - val_loss: 1.2036 - val_acc: 0.5500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1671 - acc: 0.9333 - val_loss: 1.2214 - val_acc: 0.5500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1428 - acc: 0.9500 - val_loss: 1.2757 - val_acc: 0.5500\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1705 - acc: 0.9500 - val_loss: 1.3231 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1481 - acc: 0.9667 - val_loss: 1.3718 - val_acc: 0.5000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1599 - acc: 0.9667 - val_loss: 1.3521 - val_acc: 0.5000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1470 - acc: 0.9333 - val_loss: 1.3030 - val_acc: 0.5000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.1692 - acc: 0.9333 - val_loss: 1.2236 - val_acc: 0.5500\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 781us/sample - loss: 0.1510 - acc: 0.9500 - val_loss: 1.1775 - val_acc: 0.5500\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0978 - acc: 0.9833 - val_loss: 1.1200 - val_acc: 0.5500\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1782 - acc: 0.9167 - val_loss: 1.1087 - val_acc: 0.5500\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1552 - acc: 0.9667 - val_loss: 1.0957 - val_acc: 0.5500\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1289 - acc: 0.9833 - val_loss: 1.1122 - val_acc: 0.5500\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1222 - acc: 1.0000 - val_loss: 1.1882 - val_acc: 0.5500\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1262 - acc: 1.0000 - val_loss: 1.2134 - val_acc: 0.5500\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1405 - acc: 0.9500 - val_loss: 1.2426 - val_acc: 0.5500\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1248 - acc: 0.9667 - val_loss: 1.2712 - val_acc: 0.5500\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1206 - acc: 0.9833 - val_loss: 1.2414 - val_acc: 0.5500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1166 - acc: 0.9833 - val_loss: 1.2190 - val_acc: 0.5500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1141 - acc: 1.0000 - val_loss: 1.1895 - val_acc: 0.5500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.2023 - acc: 0.9167 - val_loss: 1.1663 - val_acc: 0.5500\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1566 - acc: 0.9500 - val_loss: 1.1230 - val_acc: 0.5500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.1398 - acc: 0.9833 - val_loss: 1.1246 - val_acc: 0.5500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1206 - acc: 0.9833 - val_loss: 1.1570 - val_acc: 0.5500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1421 - acc: 0.9833 - val_loss: 1.1514 - val_acc: 0.5500\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1497 - acc: 0.9500 - val_loss: 1.1277 - val_acc: 0.5500\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1510 - acc: 0.9833 - val_loss: 1.1110 - val_acc: 0.5500\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1082 - acc: 0.9833 - val_loss: 1.1083 - val_acc: 0.5500\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1086 - acc: 1.0000 - val_loss: 1.0997 - val_acc: 0.6000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1336 - acc: 0.9833 - val_loss: 1.1392 - val_acc: 0.5500\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1318 - acc: 0.9667 - val_loss: 1.1841 - val_acc: 0.5500\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1592 - acc: 0.9833 - val_loss: 1.2214 - val_acc: 0.5500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 752us/sample - loss: 0.1162 - acc: 0.9833 - val_loss: 1.2268 - val_acc: 0.5500\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 734us/sample - loss: 0.1587 - acc: 0.9500 - val_loss: 1.2056 - val_acc: 0.5500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1189 - acc: 1.0000 - val_loss: 1.2195 - val_acc: 0.5500\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 729us/sample - loss: 0.0942 - acc: 1.0000 - val_loss: 1.2323 - val_acc: 0.5500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.1245 - acc: 0.9833 - val_loss: 1.2169 - val_acc: 0.5500\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1669 - acc: 0.9333 - val_loss: 1.2055 - val_acc: 0.5500\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 751us/sample - loss: 0.1315 - acc: 0.9667 - val_loss: 1.1958 - val_acc: 0.5500\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.1100 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.5500\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1202 - acc: 0.9500 - val_loss: 1.1677 - val_acc: 0.5500\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1428 - acc: 0.9500 - val_loss: 1.1477 - val_acc: 0.5500\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1232 - acc: 0.9833 - val_loss: 1.1248 - val_acc: 0.5500\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.1164 - acc: 0.9833 - val_loss: 1.0802 - val_acc: 0.5500\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1492 - acc: 0.9833 - val_loss: 1.0432 - val_acc: 0.5500\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1270 - acc: 0.9667 - val_loss: 1.0252 - val_acc: 0.5500\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.1353 - acc: 0.9500 - val_loss: 1.0200 - val_acc: 0.6000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1261 - acc: 0.9833 - val_loss: 1.0115 - val_acc: 0.6000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1233 - acc: 0.9667 - val_loss: 0.9843 - val_acc: 0.6000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1646 - acc: 0.9500 - val_loss: 0.9767 - val_acc: 0.5500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 0.9545 - val_acc: 0.5500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1177 - acc: 0.9833 - val_loss: 0.9828 - val_acc: 0.5500\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.1141 - acc: 0.9833 - val_loss: 0.9809 - val_acc: 0.6000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1236 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.6000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1286 - acc: 0.9833 - val_loss: 0.9855 - val_acc: 0.6000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0846 - acc: 1.0000 - val_loss: 1.0055 - val_acc: 0.6000\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1581 - acc: 0.9500 - val_loss: 1.0090 - val_acc: 0.6000\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1381 - acc: 0.9667 - val_loss: 1.0035 - val_acc: 0.6000\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1094 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.6000\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1435 - acc: 0.9500 - val_loss: 0.9807 - val_acc: 0.6000\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 760us/sample - loss: 0.1586 - acc: 0.9833 - val_loss: 0.9503 - val_acc: 0.6000\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1724 - acc: 0.9333 - val_loss: 0.9434 - val_acc: 0.6500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1431 - acc: 0.9833 - val_loss: 0.9603 - val_acc: 0.6000\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0917 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.6000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1387 - acc: 0.9500 - val_loss: 1.0272 - val_acc: 0.5500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1133 - acc: 0.9833 - val_loss: 1.0150 - val_acc: 0.5500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.1059 - acc: 0.9833 - val_loss: 1.0049 - val_acc: 0.5500\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.1170 - acc: 0.9833 - val_loss: 0.9880 - val_acc: 0.6000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1487 - acc: 0.9667 - val_loss: 0.9977 - val_acc: 0.6000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1317 - acc: 0.9833 - val_loss: 1.0048 - val_acc: 0.6000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 763us/sample - loss: 0.1257 - acc: 0.9833 - val_loss: 1.0222 - val_acc: 0.6000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1062 - acc: 0.9833 - val_loss: 1.0556 - val_acc: 0.6000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1122 - acc: 0.9667 - val_loss: 1.0726 - val_acc: 0.6000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1208 - acc: 0.9667 - val_loss: 1.0955 - val_acc: 0.6000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1221 - acc: 0.9500 - val_loss: 1.0971 - val_acc: 0.6000\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1269 - acc: 0.9667 - val_loss: 1.0437 - val_acc: 0.6000\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1036 - acc: 1.0000 - val_loss: 1.0397 - val_acc: 0.6000\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1124 - acc: 0.9833 - val_loss: 1.0522 - val_acc: 0.6000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 806us/sample - loss: 0.1249 - acc: 0.9667 - val_loss: 1.0498 - val_acc: 0.6000\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1356 - acc: 0.9833 - val_loss: 1.0355 - val_acc: 0.6000\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1072 - acc: 0.9833 - val_loss: 1.0458 - val_acc: 0.6000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1038 - acc: 0.9833 - val_loss: 1.0597 - val_acc: 0.6500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1179 - acc: 0.9667 - val_loss: 1.0790 - val_acc: 0.6000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1426 - acc: 0.9833 - val_loss: 1.0681 - val_acc: 0.6000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1244 - acc: 0.9833 - val_loss: 1.0545 - val_acc: 0.6000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.1188 - acc: 0.9500 - val_loss: 1.0294 - val_acc: 0.6500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 744us/sample - loss: 0.1716 - acc: 0.9000 - val_loss: 1.0104 - val_acc: 0.6500\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1602 - acc: 0.9833 - val_loss: 0.9806 - val_acc: 0.6500\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 740us/sample - loss: 0.0974 - acc: 0.9833 - val_loss: 1.0004 - val_acc: 0.6000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0940 - acc: 1.0000 - val_loss: 1.0215 - val_acc: 0.6000\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1499 - acc: 0.9667 - val_loss: 1.0418 - val_acc: 0.5500\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0909 - acc: 1.0000 - val_loss: 1.0418 - val_acc: 0.5500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1288 - acc: 0.9667 - val_loss: 1.0112 - val_acc: 0.6000\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1547 - acc: 0.9500 - val_loss: 0.9861 - val_acc: 0.6000\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.6000\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1214 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.6000\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1072 - acc: 0.9833 - val_loss: 1.0445 - val_acc: 0.5500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0847 - acc: 1.0000 - val_loss: 1.1081 - val_acc: 0.5500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1493 - acc: 0.9667 - val_loss: 1.1370 - val_acc: 0.5500\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1179 - acc: 0.9833 - val_loss: 1.1368 - val_acc: 0.5500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1430 - acc: 0.9833 - val_loss: 1.1026 - val_acc: 0.5500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0933 - acc: 0.9833 - val_loss: 1.1019 - val_acc: 0.5500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1124 - acc: 0.9833 - val_loss: 1.0780 - val_acc: 0.5500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1144 - acc: 0.9833 - val_loss: 1.0340 - val_acc: 0.5500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1244 - acc: 0.9833 - val_loss: 0.9558 - val_acc: 0.6000\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1289 - acc: 0.9667 - val_loss: 0.9280 - val_acc: 0.6000\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1185 - acc: 1.0000 - val_loss: 0.9172 - val_acc: 0.6000\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1311 - acc: 0.9833 - val_loss: 0.9328 - val_acc: 0.6000\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1231 - acc: 0.9833 - val_loss: 0.9396 - val_acc: 0.6000\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.1079 - acc: 0.9833 - val_loss: 0.9709 - val_acc: 0.6000\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0915 - acc: 0.9833 - val_loss: 1.0425 - val_acc: 0.6000\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0956 - acc: 0.9833 - val_loss: 1.0943 - val_acc: 0.5500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1217 - acc: 0.9667 - val_loss: 1.1154 - val_acc: 0.6000\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1128 - acc: 0.9667 - val_loss: 1.0856 - val_acc: 0.6000\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0931 - acc: 1.0000 - val_loss: 1.0608 - val_acc: 0.6500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1119 - acc: 0.9833 - val_loss: 1.0139 - val_acc: 0.6500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1345 - acc: 0.9833 - val_loss: 1.0272 - val_acc: 0.6000\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0951 - acc: 0.9833 - val_loss: 1.0235 - val_acc: 0.6000\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0896 - acc: 0.9833 - val_loss: 1.0332 - val_acc: 0.6000\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 727us/sample - loss: 0.0814 - acc: 0.9833 - val_loss: 1.0567 - val_acc: 0.6000\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1115 - acc: 0.9833 - val_loss: 1.0526 - val_acc: 0.6000\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0882 - acc: 1.0000 - val_loss: 1.0779 - val_acc: 0.6000\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 827us/sample - loss: 0.1059 - acc: 0.9667 - val_loss: 1.0919 - val_acc: 0.6000\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1288 - acc: 0.9833 - val_loss: 1.0833 - val_acc: 0.6000\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 756us/sample - loss: 0.1492 - acc: 0.9333 - val_loss: 1.0831 - val_acc: 0.5500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 722us/sample - loss: 0.0790 - acc: 1.0000 - val_loss: 1.0299 - val_acc: 0.6000\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0830 - acc: 0.9833 - val_loss: 1.0117 - val_acc: 0.6000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1161 - acc: 0.9667 - val_loss: 1.0388 - val_acc: 0.6000\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0997 - acc: 0.9833 - val_loss: 1.0801 - val_acc: 0.6000\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1158 - acc: 0.9833 - val_loss: 1.0986 - val_acc: 0.6000\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0806 - acc: 0.9833 - val_loss: 1.0948 - val_acc: 0.6000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1107 - acc: 0.9833 - val_loss: 1.0691 - val_acc: 0.6000\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1028 - acc: 0.9833 - val_loss: 1.0299 - val_acc: 0.6000\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1181 - acc: 0.9833 - val_loss: 1.0034 - val_acc: 0.6000\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0915 - acc: 1.0000 - val_loss: 0.9807 - val_acc: 0.6500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1251 - acc: 0.9833 - val_loss: 0.9902 - val_acc: 0.6500\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0813 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.6500\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1012 - acc: 0.9667 - val_loss: 0.9551 - val_acc: 0.6500\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1015 - acc: 0.9833 - val_loss: 0.9615 - val_acc: 0.6500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1024 - acc: 0.9833 - val_loss: 0.9479 - val_acc: 0.7000\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0798 - acc: 0.9833 - val_loss: 0.9455 - val_acc: 0.7000\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1144 - acc: 0.9833 - val_loss: 0.9186 - val_acc: 0.7000\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1157 - acc: 0.9833 - val_loss: 0.8990 - val_acc: 0.7000\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0908 - acc: 0.9833 - val_loss: 0.8904 - val_acc: 0.7000\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1298 - acc: 0.9667 - val_loss: 0.8817 - val_acc: 0.7000\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1352 - acc: 0.9833 - val_loss: 0.8697 - val_acc: 0.6500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1127 - acc: 0.9833 - val_loss: 0.8624 - val_acc: 0.6500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1351 - acc: 0.9833 - val_loss: 0.8311 - val_acc: 0.6500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1349 - acc: 0.9833 - val_loss: 0.8328 - val_acc: 0.6500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1236 - acc: 0.9833 - val_loss: 0.8848 - val_acc: 0.6500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.9349 - val_acc: 0.6000\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.0744 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.6000\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1362 - acc: 0.9667 - val_loss: 1.0447 - val_acc: 0.6000\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1018 - acc: 0.9833 - val_loss: 1.0388 - val_acc: 0.6000\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0879 - acc: 1.0000 - val_loss: 1.0119 - val_acc: 0.6000\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1141 - acc: 0.9667 - val_loss: 0.9727 - val_acc: 0.6000\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0966 - acc: 0.9833 - val_loss: 0.9667 - val_acc: 0.6000\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.0875 - acc: 1.0000 - val_loss: 0.9822 - val_acc: 0.6000\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.0769 - acc: 0.9833 - val_loss: 0.9928 - val_acc: 0.6000\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.1094 - acc: 0.9833 - val_loss: 1.0115 - val_acc: 0.6000\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1134 - acc: 1.0000 - val_loss: 1.0141 - val_acc: 0.6500\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0726 - acc: 0.9833 - val_loss: 1.0591 - val_acc: 0.6000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.1201 - acc: 0.9667 - val_loss: 1.1001 - val_acc: 0.6000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0739 - acc: 1.0000 - val_loss: 1.1272 - val_acc: 0.6000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0988 - acc: 1.0000 - val_loss: 1.1072 - val_acc: 0.6000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0808 - acc: 1.0000 - val_loss: 1.0626 - val_acc: 0.7000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0740 - acc: 1.0000 - val_loss: 1.0177 - val_acc: 0.7000\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1129 - acc: 0.9500 - val_loss: 0.9335 - val_acc: 0.7000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1010 - acc: 0.9833 - val_loss: 0.8879 - val_acc: 0.7000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0918 - acc: 0.9833 - val_loss: 0.8620 - val_acc: 0.7000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1047 - acc: 0.9833 - val_loss: 0.8708 - val_acc: 0.7000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1058 - acc: 0.9667 - val_loss: 0.8652 - val_acc: 0.7000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1005 - acc: 1.0000 - val_loss: 0.8798 - val_acc: 0.7000\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1061 - acc: 0.9833 - val_loss: 0.8977 - val_acc: 0.7000\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0735 - acc: 1.0000 - val_loss: 0.9251 - val_acc: 0.7000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0849 - acc: 1.0000 - val_loss: 0.9522 - val_acc: 0.7000\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1010 - acc: 0.9667 - val_loss: 0.9546 - val_acc: 0.7000\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0859 - acc: 0.9667 - val_loss: 0.9524 - val_acc: 0.7000\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.9373 - val_acc: 0.7000\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 738us/sample - loss: 0.1007 - acc: 0.9833 - val_loss: 0.9229 - val_acc: 0.7000\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1306 - acc: 0.9667 - val_loss: 0.8874 - val_acc: 0.7000\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1360 - acc: 0.9667 - val_loss: 0.8421 - val_acc: 0.7000\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.0777 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.7000\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1055 - acc: 0.9667 - val_loss: 0.8152 - val_acc: 0.7000\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0810 - acc: 0.9833 - val_loss: 0.8373 - val_acc: 0.7000\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0942 - acc: 0.9833 - val_loss: 0.8744 - val_acc: 0.7000\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0906 - acc: 0.9833 - val_loss: 0.9082 - val_acc: 0.7000\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1181 - acc: 0.9833 - val_loss: 0.9329 - val_acc: 0.7000\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1054 - acc: 0.9500 - val_loss: 0.9094 - val_acc: 0.7000\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.9101 - val_acc: 0.7000\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0758 - acc: 1.0000 - val_loss: 0.9110 - val_acc: 0.7000\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0931 - acc: 0.9667 - val_loss: 0.9226 - val_acc: 0.7000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1394 - acc: 0.9500 - val_loss: 0.8830 - val_acc: 0.7000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0988 - acc: 0.9833 - val_loss: 0.8605 - val_acc: 0.7000\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.0738 - acc: 1.0000 - val_loss: 0.8576 - val_acc: 0.7000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0862 - acc: 1.0000 - val_loss: 0.8556 - val_acc: 0.7000\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0953 - acc: 1.0000 - val_loss: 0.8980 - val_acc: 0.7000\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1108 - acc: 0.9833 - val_loss: 0.9009 - val_acc: 0.7000\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0817 - acc: 0.9833 - val_loss: 0.9303 - val_acc: 0.7000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0719 - acc: 1.0000 - val_loss: 0.9575 - val_acc: 0.7000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1152 - acc: 0.9833 - val_loss: 0.9608 - val_acc: 0.7000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1193 - acc: 0.9667 - val_loss: 0.9059 - val_acc: 0.7000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1036 - acc: 0.9833 - val_loss: 0.8777 - val_acc: 0.7000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1447 - acc: 0.9667 - val_loss: 0.8544 - val_acc: 0.7000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0977 - acc: 1.0000 - val_loss: 0.8372 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7PMORGYmWXOicDMLHP/BaMkVWQq8FH+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.9026 - acc: 0.6000\n",
            "test loss, test acc: [0.9025908949319273, 0.6]\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P04E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 2 2 2 1 1 1 2 2 2 1 1 2 2 2 1 1 1 2 2]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.3803 - acc: 0.2500 - val_loss: 1.3803 - val_acc: 0.4000\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 1.2279 - acc: 0.5667 - val_loss: 1.3677 - val_acc: 0.5500\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 1.1239 - acc: 0.4667 - val_loss: 1.3541 - val_acc: 0.5000\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 1.0268 - acc: 0.5167 - val_loss: 1.3393 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.9490 - acc: 0.6333 - val_loss: 1.3242 - val_acc: 0.5000\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.8946 - acc: 0.6833 - val_loss: 1.3093 - val_acc: 0.4500\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.8525 - acc: 0.7167 - val_loss: 1.2942 - val_acc: 0.5000\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.8521 - acc: 0.5333 - val_loss: 1.2794 - val_acc: 0.5500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.8183 - acc: 0.7500 - val_loss: 1.2649 - val_acc: 0.5500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.8068 - acc: 0.7333 - val_loss: 1.2506 - val_acc: 0.6000\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.7935 - acc: 0.7167 - val_loss: 1.2367 - val_acc: 0.6000\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 719us/sample - loss: 0.7781 - acc: 0.7167 - val_loss: 1.2236 - val_acc: 0.6000\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.7657 - acc: 0.7500 - val_loss: 1.2109 - val_acc: 0.6000\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.7616 - acc: 0.7167 - val_loss: 1.1984 - val_acc: 0.6000\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.7609 - acc: 0.7500 - val_loss: 1.1859 - val_acc: 0.6000\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.7415 - acc: 0.8167 - val_loss: 1.1736 - val_acc: 0.6000\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.7520 - acc: 0.7667 - val_loss: 1.1622 - val_acc: 0.6000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.7399 - acc: 0.7667 - val_loss: 1.1506 - val_acc: 0.6000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.7225 - acc: 0.7667 - val_loss: 1.1395 - val_acc: 0.5500\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.7043 - acc: 0.8333 - val_loss: 1.1283 - val_acc: 0.6000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.7117 - acc: 0.8667 - val_loss: 1.1174 - val_acc: 0.6000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.7075 - acc: 0.7500 - val_loss: 1.1062 - val_acc: 0.6000\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.6940 - acc: 0.7667 - val_loss: 1.0950 - val_acc: 0.6000\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.7104 - acc: 0.7833 - val_loss: 1.0839 - val_acc: 0.6500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.6755 - acc: 0.9000 - val_loss: 1.0734 - val_acc: 0.6500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.6642 - acc: 0.8500 - val_loss: 1.0633 - val_acc: 0.6500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.6438 - acc: 0.8833 - val_loss: 1.0537 - val_acc: 0.6500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.6718 - acc: 0.8667 - val_loss: 1.0442 - val_acc: 0.6000\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.6507 - acc: 0.9000 - val_loss: 1.0348 - val_acc: 0.6500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.6467 - acc: 0.9000 - val_loss: 1.0256 - val_acc: 0.6500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.6260 - acc: 0.9667 - val_loss: 1.0165 - val_acc: 0.6500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.6255 - acc: 0.8833 - val_loss: 1.0072 - val_acc: 0.6500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.6108 - acc: 0.9000 - val_loss: 0.9986 - val_acc: 0.6500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.6280 - acc: 0.9333 - val_loss: 0.9906 - val_acc: 0.6000\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.6175 - acc: 0.8500 - val_loss: 0.9826 - val_acc: 0.6000\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.6075 - acc: 0.8833 - val_loss: 0.9747 - val_acc: 0.6500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.6048 - acc: 0.8667 - val_loss: 0.9665 - val_acc: 0.7000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.6167 - acc: 0.8333 - val_loss: 0.9586 - val_acc: 0.7000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5846 - acc: 0.9333 - val_loss: 0.9515 - val_acc: 0.7000\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.5947 - acc: 0.9500 - val_loss: 0.9445 - val_acc: 0.6500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.5610 - acc: 0.9000 - val_loss: 0.9371 - val_acc: 0.6500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.5827 - acc: 0.8833 - val_loss: 0.9303 - val_acc: 0.6500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.5768 - acc: 0.9000 - val_loss: 0.9227 - val_acc: 0.6500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.5459 - acc: 0.9000 - val_loss: 0.9156 - val_acc: 0.6500\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.5303 - acc: 0.9667 - val_loss: 0.9081 - val_acc: 0.6500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 774us/sample - loss: 0.5788 - acc: 0.9000 - val_loss: 0.8996 - val_acc: 0.6500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.5342 - acc: 0.9000 - val_loss: 0.8914 - val_acc: 0.6500\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.5354 - acc: 0.9667 - val_loss: 0.8839 - val_acc: 0.6500\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.4888 - acc: 0.9667 - val_loss: 0.8757 - val_acc: 0.6500\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.5006 - acc: 0.9500 - val_loss: 0.8677 - val_acc: 0.6500\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5421 - acc: 0.9167 - val_loss: 0.8596 - val_acc: 0.6500\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.5095 - acc: 0.9167 - val_loss: 0.8508 - val_acc: 0.6500\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.5049 - acc: 0.8833 - val_loss: 0.8431 - val_acc: 0.6500\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.4673 - acc: 0.9500 - val_loss: 0.8342 - val_acc: 0.6500\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.4770 - acc: 0.9333 - val_loss: 0.8253 - val_acc: 0.7000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.4648 - acc: 0.9333 - val_loss: 0.8184 - val_acc: 0.7000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.4643 - acc: 0.9500 - val_loss: 0.8124 - val_acc: 0.7000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.4733 - acc: 0.9000 - val_loss: 0.8059 - val_acc: 0.7000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.4520 - acc: 0.9167 - val_loss: 0.7990 - val_acc: 0.7000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.4728 - acc: 0.9333 - val_loss: 0.7923 - val_acc: 0.7000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.4210 - acc: 0.9667 - val_loss: 0.7853 - val_acc: 0.6500\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 722us/sample - loss: 0.4630 - acc: 0.9167 - val_loss: 0.7792 - val_acc: 0.6500\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.4422 - acc: 0.9333 - val_loss: 0.7732 - val_acc: 0.6500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.4075 - acc: 0.9667 - val_loss: 0.7675 - val_acc: 0.6500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.4218 - acc: 0.9667 - val_loss: 0.7612 - val_acc: 0.7000\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.4177 - acc: 0.9500 - val_loss: 0.7558 - val_acc: 0.7000\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.4239 - acc: 0.9500 - val_loss: 0.7497 - val_acc: 0.7500\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.4187 - acc: 0.9667 - val_loss: 0.7426 - val_acc: 0.7500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.4150 - acc: 0.9333 - val_loss: 0.7367 - val_acc: 0.7500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 752us/sample - loss: 0.4091 - acc: 0.9667 - val_loss: 0.7309 - val_acc: 0.7500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.3979 - acc: 0.9333 - val_loss: 0.7254 - val_acc: 0.7000\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.3770 - acc: 0.9333 - val_loss: 0.7194 - val_acc: 0.7000\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.3427 - acc: 0.9333 - val_loss: 0.7125 - val_acc: 0.7000\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.4079 - acc: 0.9667 - val_loss: 0.7044 - val_acc: 0.7500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.3487 - acc: 0.9500 - val_loss: 0.6991 - val_acc: 0.7500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.3610 - acc: 0.9667 - val_loss: 0.6933 - val_acc: 0.7500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.3751 - acc: 0.9000 - val_loss: 0.6874 - val_acc: 0.7500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3323 - acc: 0.9833 - val_loss: 0.6843 - val_acc: 0.7000\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.3698 - acc: 0.9333 - val_loss: 0.6819 - val_acc: 0.7000\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.3250 - acc: 0.9833 - val_loss: 0.6812 - val_acc: 0.7000\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.3382 - acc: 0.9500 - val_loss: 0.6813 - val_acc: 0.7000\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2988 - acc: 0.9667 - val_loss: 0.6821 - val_acc: 0.6500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.3381 - acc: 0.9333 - val_loss: 0.6857 - val_acc: 0.6500\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.3396 - acc: 0.9167 - val_loss: 0.6864 - val_acc: 0.6500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.3216 - acc: 0.9333 - val_loss: 0.6891 - val_acc: 0.6500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 719us/sample - loss: 0.3157 - acc: 0.9333 - val_loss: 0.6858 - val_acc: 0.6500\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.3060 - acc: 0.9500 - val_loss: 0.6852 - val_acc: 0.6500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3315 - acc: 0.9667 - val_loss: 0.6788 - val_acc: 0.6500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.3228 - acc: 0.9333 - val_loss: 0.6711 - val_acc: 0.6500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3062 - acc: 0.9500 - val_loss: 0.6637 - val_acc: 0.6500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.3191 - acc: 0.9667 - val_loss: 0.6570 - val_acc: 0.6500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.3054 - acc: 0.9667 - val_loss: 0.6483 - val_acc: 0.7000\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.3145 - acc: 0.8833 - val_loss: 0.6371 - val_acc: 0.7000\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3157 - acc: 0.9500 - val_loss: 0.6317 - val_acc: 0.7000\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.3008 - acc: 0.9500 - val_loss: 0.6258 - val_acc: 0.7000\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.2782 - acc: 0.9333 - val_loss: 0.6212 - val_acc: 0.7000\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.2752 - acc: 0.9667 - val_loss: 0.6131 - val_acc: 0.7000\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.3351 - acc: 0.8833 - val_loss: 0.6082 - val_acc: 0.7000\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2719 - acc: 0.9667 - val_loss: 0.6043 - val_acc: 0.7000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2376 - acc: 0.9833 - val_loss: 0.6005 - val_acc: 0.7500\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2816 - acc: 0.9500 - val_loss: 0.6005 - val_acc: 0.7500\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3125 - acc: 0.9333 - val_loss: 0.6026 - val_acc: 0.7000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.3030 - acc: 0.8833 - val_loss: 0.5969 - val_acc: 0.7500\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2663 - acc: 0.9667 - val_loss: 0.5892 - val_acc: 0.7500\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.2994 - acc: 0.9333 - val_loss: 0.5878 - val_acc: 0.7500\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2519 - acc: 0.9500 - val_loss: 0.5826 - val_acc: 0.8000\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2527 - acc: 0.9833 - val_loss: 0.5859 - val_acc: 0.7500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2270 - acc: 0.9833 - val_loss: 0.5889 - val_acc: 0.7500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.2643 - acc: 0.9167 - val_loss: 0.5985 - val_acc: 0.7500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2261 - acc: 0.9833 - val_loss: 0.6046 - val_acc: 0.7500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2225 - acc: 0.9500 - val_loss: 0.6152 - val_acc: 0.7500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 739us/sample - loss: 0.2541 - acc: 0.9500 - val_loss: 0.6207 - val_acc: 0.7500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2275 - acc: 0.9667 - val_loss: 0.6315 - val_acc: 0.7500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2713 - acc: 0.9167 - val_loss: 0.6342 - val_acc: 0.7500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2600 - acc: 0.9333 - val_loss: 0.6276 - val_acc: 0.7500\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2307 - acc: 0.9167 - val_loss: 0.6261 - val_acc: 0.7500\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2237 - acc: 0.9667 - val_loss: 0.6342 - val_acc: 0.7500\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 734us/sample - loss: 0.2355 - acc: 0.9500 - val_loss: 0.6375 - val_acc: 0.7000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2318 - acc: 0.9667 - val_loss: 0.6406 - val_acc: 0.7000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.1993 - acc: 0.9833 - val_loss: 0.6446 - val_acc: 0.7000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2314 - acc: 0.9500 - val_loss: 0.6558 - val_acc: 0.7000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2427 - acc: 0.9333 - val_loss: 0.6490 - val_acc: 0.7000\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2248 - acc: 0.9167 - val_loss: 0.6446 - val_acc: 0.7500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1899 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.7500\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1977 - acc: 0.9833 - val_loss: 0.6323 - val_acc: 0.8000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2134 - acc: 0.9333 - val_loss: 0.6168 - val_acc: 0.8000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1955 - acc: 0.9833 - val_loss: 0.5951 - val_acc: 0.8000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2019 - acc: 0.9667 - val_loss: 0.5770 - val_acc: 0.8000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2122 - acc: 0.9500 - val_loss: 0.5681 - val_acc: 0.8000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2117 - acc: 0.9667 - val_loss: 0.5686 - val_acc: 0.8000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2535 - acc: 0.9333 - val_loss: 0.5705 - val_acc: 0.8000\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2004 - acc: 0.9500 - val_loss: 0.5720 - val_acc: 0.8000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2006 - acc: 0.9667 - val_loss: 0.5697 - val_acc: 0.8000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.2339 - acc: 0.9333 - val_loss: 0.5641 - val_acc: 0.8000\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2131 - acc: 0.9833 - val_loss: 0.5570 - val_acc: 0.8000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2336 - acc: 0.9167 - val_loss: 0.5461 - val_acc: 0.8000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.2334 - acc: 0.9500 - val_loss: 0.5349 - val_acc: 0.8000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2099 - acc: 0.9500 - val_loss: 0.5313 - val_acc: 0.8000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1944 - acc: 0.9333 - val_loss: 0.5267 - val_acc: 0.8000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1984 - acc: 0.9667 - val_loss: 0.5285 - val_acc: 0.8000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1839 - acc: 1.0000 - val_loss: 0.5317 - val_acc: 0.8000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1958 - acc: 0.9833 - val_loss: 0.5321 - val_acc: 0.8000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1703 - acc: 0.9667 - val_loss: 0.5275 - val_acc: 0.8000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1900 - acc: 0.9667 - val_loss: 0.5224 - val_acc: 0.8000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1610 - acc: 1.0000 - val_loss: 0.5180 - val_acc: 0.8000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1894 - acc: 0.9667 - val_loss: 0.5136 - val_acc: 0.8000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1729 - acc: 0.9667 - val_loss: 0.5062 - val_acc: 0.8500\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.1735 - acc: 0.9833 - val_loss: 0.4940 - val_acc: 0.8500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1554 - acc: 0.9833 - val_loss: 0.4856 - val_acc: 0.8500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1985 - acc: 0.9333 - val_loss: 0.4841 - val_acc: 0.8500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1999 - acc: 0.9500 - val_loss: 0.4871 - val_acc: 0.8500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1844 - acc: 0.9667 - val_loss: 0.4923 - val_acc: 0.8500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1867 - acc: 0.9500 - val_loss: 0.4879 - val_acc: 0.8500\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1919 - acc: 0.9833 - val_loss: 0.4742 - val_acc: 0.8500\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.1806 - acc: 0.9500 - val_loss: 0.4581 - val_acc: 0.8500\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1758 - acc: 0.9667 - val_loss: 0.4477 - val_acc: 0.8500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1453 - acc: 0.9667 - val_loss: 0.4352 - val_acc: 0.8500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2003 - acc: 0.9667 - val_loss: 0.4218 - val_acc: 0.8500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1804 - acc: 0.9667 - val_loss: 0.4142 - val_acc: 0.8500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1786 - acc: 0.9500 - val_loss: 0.4104 - val_acc: 0.8500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1830 - acc: 0.9667 - val_loss: 0.4060 - val_acc: 0.8500\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1331 - acc: 0.9833 - val_loss: 0.4052 - val_acc: 0.8500\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1499 - acc: 1.0000 - val_loss: 0.4005 - val_acc: 0.9000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1664 - acc: 1.0000 - val_loss: 0.3951 - val_acc: 0.9000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1701 - acc: 1.0000 - val_loss: 0.3889 - val_acc: 0.9000\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.1594 - acc: 0.9667 - val_loss: 0.3851 - val_acc: 0.9000\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1982 - acc: 0.9500 - val_loss: 0.3813 - val_acc: 0.9000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1477 - acc: 0.9833 - val_loss: 0.3788 - val_acc: 0.9000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1251 - acc: 1.0000 - val_loss: 0.3753 - val_acc: 0.9000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1242 - acc: 0.9833 - val_loss: 0.3719 - val_acc: 0.9000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1883 - acc: 0.9500 - val_loss: 0.3717 - val_acc: 0.9000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1615 - acc: 0.9333 - val_loss: 0.3695 - val_acc: 0.8500\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1487 - acc: 0.9833 - val_loss: 0.3667 - val_acc: 0.8500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1555 - acc: 0.9500 - val_loss: 0.3643 - val_acc: 0.8500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1427 - acc: 0.9667 - val_loss: 0.3628 - val_acc: 0.8500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1453 - acc: 1.0000 - val_loss: 0.3637 - val_acc: 0.8000\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1656 - acc: 0.9833 - val_loss: 0.3693 - val_acc: 0.8000\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1419 - acc: 0.9667 - val_loss: 0.3770 - val_acc: 0.8000\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1113 - acc: 1.0000 - val_loss: 0.3833 - val_acc: 0.8000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1306 - acc: 0.9667 - val_loss: 0.3866 - val_acc: 0.8000\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1361 - acc: 0.9833 - val_loss: 0.3863 - val_acc: 0.8000\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1304 - acc: 0.9667 - val_loss: 0.3763 - val_acc: 0.8000\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1419 - acc: 0.9833 - val_loss: 0.3631 - val_acc: 0.8000\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.1225 - acc: 0.9833 - val_loss: 0.3566 - val_acc: 0.8500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1680 - acc: 0.9500 - val_loss: 0.3531 - val_acc: 0.8500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1249 - acc: 0.9833 - val_loss: 0.3499 - val_acc: 0.8500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1244 - acc: 0.9833 - val_loss: 0.3474 - val_acc: 0.8500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1342 - acc: 0.9833 - val_loss: 0.3464 - val_acc: 0.8500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1576 - acc: 0.9500 - val_loss: 0.3456 - val_acc: 0.8500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1439 - acc: 0.9667 - val_loss: 0.3462 - val_acc: 0.8500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1018 - acc: 1.0000 - val_loss: 0.3455 - val_acc: 0.8500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1165 - acc: 1.0000 - val_loss: 0.3441 - val_acc: 0.8500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1185 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 0.8500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1802 - acc: 0.9500 - val_loss: 0.3431 - val_acc: 0.8500\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1424 - acc: 0.9667 - val_loss: 0.3431 - val_acc: 0.8500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1337 - acc: 0.9833 - val_loss: 0.3438 - val_acc: 0.8500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1405 - acc: 0.9667 - val_loss: 0.3458 - val_acc: 0.8500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1244 - acc: 0.9833 - val_loss: 0.3502 - val_acc: 0.8500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1486 - acc: 0.9667 - val_loss: 0.3593 - val_acc: 0.8000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1186 - acc: 0.9833 - val_loss: 0.3647 - val_acc: 0.8000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1637 - acc: 0.9667 - val_loss: 0.3669 - val_acc: 0.8000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1186 - acc: 0.9833 - val_loss: 0.3642 - val_acc: 0.8000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1069 - acc: 1.0000 - val_loss: 0.3558 - val_acc: 0.8000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1199 - acc: 1.0000 - val_loss: 0.3505 - val_acc: 0.8500\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1090 - acc: 0.9833 - val_loss: 0.3472 - val_acc: 0.8500\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1563 - acc: 0.9833 - val_loss: 0.3463 - val_acc: 0.8500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1055 - acc: 0.9833 - val_loss: 0.3446 - val_acc: 0.8500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1359 - acc: 0.9667 - val_loss: 0.3426 - val_acc: 0.8500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.1302 - acc: 1.0000 - val_loss: 0.3421 - val_acc: 0.8500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1537 - acc: 0.9667 - val_loss: 0.3464 - val_acc: 0.8500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1328 - acc: 0.9500 - val_loss: 0.3530 - val_acc: 0.8000\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.1084 - acc: 0.9833 - val_loss: 0.3536 - val_acc: 0.8000\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0960 - acc: 1.0000 - val_loss: 0.3536 - val_acc: 0.8000\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.1051 - acc: 1.0000 - val_loss: 0.3479 - val_acc: 0.8500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1077 - acc: 0.9833 - val_loss: 0.3436 - val_acc: 0.8500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1014 - acc: 0.9833 - val_loss: 0.3372 - val_acc: 0.8500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1216 - acc: 0.9667 - val_loss: 0.3334 - val_acc: 0.8500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1099 - acc: 1.0000 - val_loss: 0.3312 - val_acc: 0.8500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1221 - acc: 0.9833 - val_loss: 0.3291 - val_acc: 0.8500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1304 - acc: 0.9833 - val_loss: 0.3285 - val_acc: 0.8500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1637 - acc: 0.9667 - val_loss: 0.3274 - val_acc: 0.8500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1037 - acc: 0.9833 - val_loss: 0.3260 - val_acc: 0.8500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1374 - acc: 1.0000 - val_loss: 0.3244 - val_acc: 0.8500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1207 - acc: 0.9833 - val_loss: 0.3251 - val_acc: 0.8500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1308 - acc: 0.9667 - val_loss: 0.3265 - val_acc: 0.8500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1123 - acc: 0.9667 - val_loss: 0.3271 - val_acc: 0.8500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0962 - acc: 1.0000 - val_loss: 0.3278 - val_acc: 0.8500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1295 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 0.8500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0858 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 0.8500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0898 - acc: 1.0000 - val_loss: 0.3305 - val_acc: 0.9000\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0831 - acc: 1.0000 - val_loss: 0.3307 - val_acc: 0.9000\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0786 - acc: 0.9833 - val_loss: 0.3301 - val_acc: 0.9000\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1051 - acc: 0.9833 - val_loss: 0.3289 - val_acc: 0.9000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1289 - acc: 0.9833 - val_loss: 0.3281 - val_acc: 0.9000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0828 - acc: 1.0000 - val_loss: 0.3259 - val_acc: 0.9000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0813 - acc: 1.0000 - val_loss: 0.3245 - val_acc: 0.9000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0952 - acc: 1.0000 - val_loss: 0.3246 - val_acc: 0.9000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.0981 - acc: 1.0000 - val_loss: 0.3253 - val_acc: 0.9000\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0760 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.9000\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0987 - acc: 0.9833 - val_loss: 0.3258 - val_acc: 0.9000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0921 - acc: 1.0000 - val_loss: 0.3237 - val_acc: 0.9000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1146 - acc: 0.9667 - val_loss: 0.3162 - val_acc: 0.9000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1163 - acc: 0.9667 - val_loss: 0.3101 - val_acc: 0.9000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1083 - acc: 0.9833 - val_loss: 0.3073 - val_acc: 0.9000\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1013 - acc: 0.9833 - val_loss: 0.3067 - val_acc: 0.9000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0947 - acc: 0.9833 - val_loss: 0.3078 - val_acc: 0.9000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0829 - acc: 1.0000 - val_loss: 0.3103 - val_acc: 0.9000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1041 - acc: 1.0000 - val_loss: 0.3130 - val_acc: 0.9000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0883 - acc: 1.0000 - val_loss: 0.3149 - val_acc: 0.9000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0720 - acc: 1.0000 - val_loss: 0.3170 - val_acc: 0.8500\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.3189 - val_acc: 0.8500\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0795 - acc: 1.0000 - val_loss: 0.3218 - val_acc: 0.8500\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1080 - acc: 0.9667 - val_loss: 0.3256 - val_acc: 0.9000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1064 - acc: 0.9833 - val_loss: 0.3257 - val_acc: 0.9000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1039 - acc: 0.9833 - val_loss: 0.3275 - val_acc: 0.9000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0958 - acc: 0.9667 - val_loss: 0.3285 - val_acc: 0.9000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1092 - acc: 0.9833 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0760 - acc: 0.9833 - val_loss: 0.3308 - val_acc: 0.9000\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.3284 - val_acc: 0.9000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0975 - acc: 0.9667 - val_loss: 0.3259 - val_acc: 0.9000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0742 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.9000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.0901 - acc: 1.0000 - val_loss: 0.3181 - val_acc: 0.9000\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.9000\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1005 - acc: 0.9667 - val_loss: 0.3099 - val_acc: 0.9000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0877 - acc: 0.9833 - val_loss: 0.3063 - val_acc: 0.9000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1109 - acc: 0.9833 - val_loss: 0.3018 - val_acc: 0.8500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0673 - acc: 1.0000 - val_loss: 0.2983 - val_acc: 0.8500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0885 - acc: 0.9833 - val_loss: 0.2961 - val_acc: 0.8500\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0847 - acc: 1.0000 - val_loss: 0.2925 - val_acc: 0.8500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1139 - acc: 0.9667 - val_loss: 0.2910 - val_acc: 0.8500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0767 - acc: 1.0000 - val_loss: 0.2934 - val_acc: 0.8500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0779 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.9000\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0749 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.9000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1001 - acc: 1.0000 - val_loss: 0.3147 - val_acc: 0.9000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0862 - acc: 1.0000 - val_loss: 0.3160 - val_acc: 0.9000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.0981 - acc: 0.9667 - val_loss: 0.3138 - val_acc: 0.9000\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1298 - acc: 0.9667 - val_loss: 0.3098 - val_acc: 0.9000\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.3097 - val_acc: 0.9000\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0874 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.9000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0687 - acc: 0.9833 - val_loss: 0.3097 - val_acc: 0.9000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0699 - acc: 1.0000 - val_loss: 0.3115 - val_acc: 0.9000\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0868 - acc: 1.0000 - val_loss: 0.3169 - val_acc: 0.9000\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0806 - acc: 0.9833 - val_loss: 0.3203 - val_acc: 0.9000\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 749us/sample - loss: 0.0764 - acc: 0.9833 - val_loss: 0.3221 - val_acc: 0.9000\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 825us/sample - loss: 0.0960 - acc: 0.9667 - val_loss: 0.3204 - val_acc: 0.9000\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0904 - acc: 0.9833 - val_loss: 0.3234 - val_acc: 0.9000\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0767 - acc: 0.9833 - val_loss: 0.3241 - val_acc: 0.9000\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0803 - acc: 1.0000 - val_loss: 0.3321 - val_acc: 0.9000\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.3418 - val_acc: 0.9000\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.3517 - val_acc: 0.9000\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0656 - acc: 1.0000 - val_loss: 0.3695 - val_acc: 0.9000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0702 - acc: 0.9667 - val_loss: 0.3836 - val_acc: 0.9000\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1393 - acc: 0.9333 - val_loss: 0.3823 - val_acc: 0.9000\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0705 - acc: 1.0000 - val_loss: 0.3871 - val_acc: 0.9000\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.3942 - val_acc: 0.9000\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0811 - acc: 0.9833 - val_loss: 0.3954 - val_acc: 0.9000\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1051 - acc: 0.9833 - val_loss: 0.3864 - val_acc: 0.9000\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0855 - acc: 1.0000 - val_loss: 0.3793 - val_acc: 0.9000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.3727 - val_acc: 0.9000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1174 - acc: 0.9500 - val_loss: 0.3675 - val_acc: 0.9000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0728 - acc: 0.9833 - val_loss: 0.3671 - val_acc: 0.9000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.0754 - acc: 1.0000 - val_loss: 0.3662 - val_acc: 0.9000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0914 - acc: 0.9833 - val_loss: 0.3614 - val_acc: 0.9000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0768 - acc: 1.0000 - val_loss: 0.3522 - val_acc: 0.9000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0953 - acc: 0.9833 - val_loss: 0.3481 - val_acc: 0.9000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0730 - acc: 0.9833 - val_loss: 0.3471 - val_acc: 0.9000\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.0853 - acc: 1.0000 - val_loss: 0.3472 - val_acc: 0.9000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0788 - acc: 0.9833 - val_loss: 0.3398 - val_acc: 0.9000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 784us/sample - loss: 0.1421 - acc: 0.9667 - val_loss: 0.3254 - val_acc: 0.9000\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0696 - acc: 1.0000 - val_loss: 0.3173 - val_acc: 0.9000\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 0.9000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0883 - acc: 0.9833 - val_loss: 0.3052 - val_acc: 0.9000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0731 - acc: 1.0000 - val_loss: 0.2996 - val_acc: 0.9000\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.2941 - val_acc: 0.9000\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0697 - acc: 1.0000 - val_loss: 0.2909 - val_acc: 0.9000\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.2889 - val_acc: 0.9000\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0739 - acc: 0.9833 - val_loss: 0.2874 - val_acc: 0.8500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0930 - acc: 0.9833 - val_loss: 0.2876 - val_acc: 0.8500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.2884 - val_acc: 0.8500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.2890 - val_acc: 0.8500\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0990 - acc: 0.9500 - val_loss: 0.2916 - val_acc: 0.8500\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1079 - acc: 0.9667 - val_loss: 0.2934 - val_acc: 0.8500\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0659 - acc: 0.9833 - val_loss: 0.2933 - val_acc: 0.8500\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1022 - acc: 0.9833 - val_loss: 0.2960 - val_acc: 0.9000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0531 - acc: 1.0000 - val_loss: 0.2977 - val_acc: 0.9000\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.2999 - val_acc: 0.9000\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0726 - acc: 0.9833 - val_loss: 0.2983 - val_acc: 0.9000\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0742 - acc: 1.0000 - val_loss: 0.2962 - val_acc: 0.9000\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1016 - acc: 0.9833 - val_loss: 0.2955 - val_acc: 0.8500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1203 - acc: 0.9500 - val_loss: 0.2960 - val_acc: 0.9000\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0752 - acc: 1.0000 - val_loss: 0.3009 - val_acc: 0.9000\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.3101 - val_acc: 0.9000\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.0752 - acc: 1.0000 - val_loss: 0.3219 - val_acc: 0.9000\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.3440 - val_acc: 0.9000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0552 - acc: 0.9833 - val_loss: 0.3585 - val_acc: 0.9000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0818 - acc: 0.9833 - val_loss: 0.3595 - val_acc: 0.9000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.3527 - val_acc: 0.9000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0785 - acc: 0.9833 - val_loss: 0.3392 - val_acc: 0.9000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.3308 - val_acc: 0.9000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0642 - acc: 0.9833 - val_loss: 0.3257 - val_acc: 0.9000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0769 - acc: 0.9833 - val_loss: 0.3199 - val_acc: 0.9000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.3228 - val_acc: 0.9000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0656 - acc: 0.9833 - val_loss: 0.3322 - val_acc: 0.9000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0696 - acc: 1.0000 - val_loss: 0.3543 - val_acc: 0.9000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0892 - acc: 0.9833 - val_loss: 0.3678 - val_acc: 0.9000\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0839 - acc: 0.9833 - val_loss: 0.3864 - val_acc: 0.9000\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.3975 - val_acc: 0.9000\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1035 - acc: 0.9833 - val_loss: 0.4038 - val_acc: 0.9000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0725 - acc: 0.9833 - val_loss: 0.3938 - val_acc: 0.9000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.3868 - val_acc: 0.9000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0524 - acc: 0.9833 - val_loss: 0.3790 - val_acc: 0.9000\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0946 - acc: 0.9667 - val_loss: 0.3938 - val_acc: 0.9000\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.4012 - val_acc: 0.9000\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0703 - acc: 1.0000 - val_loss: 0.3990 - val_acc: 0.9000\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.3924 - val_acc: 0.9000\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0835 - acc: 0.9833 - val_loss: 0.3788 - val_acc: 0.9000\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 847us/sample - loss: 0.0777 - acc: 0.9833 - val_loss: 0.3747 - val_acc: 0.9000\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.3698 - val_acc: 0.9000\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.3592 - val_acc: 0.9000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0613 - acc: 0.9833 - val_loss: 0.3498 - val_acc: 0.9000\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.3518 - val_acc: 0.9000\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0602 - acc: 1.0000 - val_loss: 0.3520 - val_acc: 0.9000\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.3567 - val_acc: 0.9000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0486 - acc: 1.0000 - val_loss: 0.3617 - val_acc: 0.9000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0448 - acc: 1.0000 - val_loss: 0.3669 - val_acc: 0.9000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.3802 - val_acc: 0.9000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0625 - acc: 0.9833 - val_loss: 0.3969 - val_acc: 0.9000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.4075 - val_acc: 0.9000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.4177 - val_acc: 0.9000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 749us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4292 - val_acc: 0.9000\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.4421 - val_acc: 0.9000\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0686 - acc: 0.9833 - val_loss: 0.4562 - val_acc: 0.9000\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.4667 - val_acc: 0.9000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0713 - acc: 0.9833 - val_loss: 0.4666 - val_acc: 0.9000\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.4522 - val_acc: 0.9000\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 728us/sample - loss: 0.0679 - acc: 0.9833 - val_loss: 0.4483 - val_acc: 0.9000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 733us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.4372 - val_acc: 0.9000\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.4233 - val_acc: 0.9000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 731us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.4182 - val_acc: 0.9000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0768 - acc: 0.9667 - val_loss: 0.4121 - val_acc: 0.9000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.3932 - val_acc: 0.9000\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.3818 - val_acc: 0.9000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0707 - acc: 0.9833 - val_loss: 0.3597 - val_acc: 0.9000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.0684 - acc: 0.9833 - val_loss: 0.3345 - val_acc: 0.9000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.3179 - val_acc: 0.9000\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.0572 - acc: 0.9833 - val_loss: 0.3012 - val_acc: 0.9000\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0619 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.9000\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0610 - acc: 1.0000 - val_loss: 0.2854 - val_acc: 0.9000\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0722 - acc: 1.0000 - val_loss: 0.2843 - val_acc: 0.9000\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0463 - acc: 1.0000 - val_loss: 0.2823 - val_acc: 0.8500\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.2807 - val_acc: 0.8500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.2814 - val_acc: 0.8500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0719 - acc: 0.9667 - val_loss: 0.2834 - val_acc: 0.8500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0832 - acc: 0.9833 - val_loss: 0.2877 - val_acc: 0.9000\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.8500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.2870 - val_acc: 0.8500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.0656 - acc: 1.0000 - val_loss: 0.2870 - val_acc: 0.8500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.2863 - val_acc: 0.8500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.2848 - val_acc: 0.8500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.0734 - acc: 1.0000 - val_loss: 0.2827 - val_acc: 0.8500\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0722 - acc: 0.9833 - val_loss: 0.2811 - val_acc: 0.8500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0581 - acc: 1.0000 - val_loss: 0.2810 - val_acc: 0.8500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0924 - acc: 0.9667 - val_loss: 0.2826 - val_acc: 0.8500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.2841 - val_acc: 0.8500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.2847 - val_acc: 0.8500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0490 - acc: 1.0000 - val_loss: 0.2850 - val_acc: 0.8500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0572 - acc: 1.0000 - val_loss: 0.2854 - val_acc: 0.8500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.2880 - val_acc: 0.8500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.2942 - val_acc: 0.8500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.3054 - val_acc: 0.9000\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0507 - acc: 1.0000 - val_loss: 0.3167 - val_acc: 0.9000\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.3264 - val_acc: 0.9000\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.9000\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0755 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.9000\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0665 - acc: 0.9833 - val_loss: 0.3343 - val_acc: 0.9000\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0500 - acc: 0.9833 - val_loss: 0.3370 - val_acc: 0.9000\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.0441 - acc: 0.9833 - val_loss: 0.3356 - val_acc: 0.9000\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0568 - acc: 1.0000 - val_loss: 0.3243 - val_acc: 0.9000\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 757us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.3184 - val_acc: 0.9000\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 748us/sample - loss: 0.0577 - acc: 1.0000 - val_loss: 0.3140 - val_acc: 0.9000\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.0662 - acc: 0.9833 - val_loss: 0.3126 - val_acc: 0.9000\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0707 - acc: 0.9833 - val_loss: 0.3204 - val_acc: 0.9000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.3333 - val_acc: 0.9000\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.3441 - val_acc: 0.9000\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.3507 - val_acc: 0.9000\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.3611 - val_acc: 0.9000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0609 - acc: 0.9833 - val_loss: 0.3676 - val_acc: 0.9000\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 726us/sample - loss: 0.0506 - acc: 1.0000 - val_loss: 0.3795 - val_acc: 0.9000\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0703 - acc: 0.9833 - val_loss: 0.3872 - val_acc: 0.9000\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0598 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.9000\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.3856 - val_acc: 0.9000\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.3847 - val_acc: 0.9000\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.3853 - val_acc: 0.9000\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0522 - acc: 0.9833 - val_loss: 0.3750 - val_acc: 0.9000\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0565 - acc: 0.9833 - val_loss: 0.3690 - val_acc: 0.9000\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.3543 - val_acc: 0.9000\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 758us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.3441 - val_acc: 0.9000\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0827 - acc: 0.9667 - val_loss: 0.3441 - val_acc: 0.9000\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.3444 - val_acc: 0.9000\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0400 - acc: 0.9833 - val_loss: 0.3504 - val_acc: 0.9000\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.3537 - val_acc: 0.9000\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.3571 - val_acc: 0.9000\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 0.3580 - val_acc: 0.9000\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.3516 - val_acc: 0.9000\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.3465 - val_acc: 0.9000\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1445 - acc: 0.9333 - val_loss: 0.3234 - val_acc: 0.9000\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.9000\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0575 - acc: 0.9833 - val_loss: 0.2954 - val_acc: 0.9000\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.2800 - val_acc: 0.9000\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.9000\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0521 - acc: 0.9833 - val_loss: 0.2491 - val_acc: 0.9000\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.2472 - val_acc: 0.9000\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0730 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9000\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.2498 - val_acc: 0.9000\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.2501 - val_acc: 0.9000\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.2579 - val_acc: 0.9000\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0633 - acc: 0.9833 - val_loss: 0.2706 - val_acc: 0.9000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.2807 - val_acc: 0.9000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.2924 - val_acc: 0.9000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.3060 - val_acc: 0.9000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 0.9000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.3264 - val_acc: 0.9000\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0623 - acc: 0.9833 - val_loss: 0.3307 - val_acc: 0.9000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.3326 - val_acc: 0.9000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0509 - acc: 0.9833 - val_loss: 0.3277 - val_acc: 0.9000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.3190 - val_acc: 0.9000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0907 - acc: 0.9667 - val_loss: 0.3159 - val_acc: 0.9000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.3064 - val_acc: 0.9000\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.2970 - val_acc: 0.9000\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.2938 - val_acc: 0.9000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 0.2917 - val_acc: 0.9000\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1124 - acc: 0.9500 - val_loss: 0.3063 - val_acc: 0.9000\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.0679 - acc: 0.9833 - val_loss: 0.3208 - val_acc: 0.9000\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 0.9000\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0703 - acc: 0.9833 - val_loss: 0.3626 - val_acc: 0.9000\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0534 - acc: 0.9833 - val_loss: 0.3666 - val_acc: 0.9000\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 757us/sample - loss: 0.0696 - acc: 0.9833 - val_loss: 0.3590 - val_acc: 0.9000\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.3594 - val_acc: 0.9000\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.3604 - val_acc: 0.9000\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.3558 - val_acc: 0.9000\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.3553 - val_acc: 0.9000\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.3458 - val_acc: 0.9000\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1012 - acc: 0.9833 - val_loss: 0.3313 - val_acc: 0.9000\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.3230 - val_acc: 0.9000\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0741 - acc: 1.0000 - val_loss: 0.3087 - val_acc: 0.9000\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.2971 - val_acc: 0.9000\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.0599 - acc: 0.9833 - val_loss: 0.2926 - val_acc: 0.9000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.0532 - acc: 0.9833 - val_loss: 0.2999 - val_acc: 0.9000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.3143 - val_acc: 0.9000\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0990 - acc: 0.9833 - val_loss: 0.3209 - val_acc: 0.9000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.9000\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0423 - acc: 0.9833 - val_loss: 0.3180 - val_acc: 0.9000\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.3123 - val_acc: 0.9000\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0358 - acc: 0.9833 - val_loss: 0.3048 - val_acc: 0.9000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0638 - acc: 0.9833 - val_loss: 0.2891 - val_acc: 0.9000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.2788 - val_acc: 0.9000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0440 - acc: 0.9833 - val_loss: 0.2668 - val_acc: 0.9000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 707us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 0.9000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0670 - acc: 1.0000 - val_loss: 0.2542 - val_acc: 0.9000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.2462 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.4817 - acc: 0.7750\n",
            "test loss, test acc: [0.4816613879636861, 0.775]\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P05E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 2 2 1 2 1 1 2 2 1 1 1 1 1 2 2 2 2 1 2]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.3691 - acc: 0.3667 - val_loss: 1.3669 - val_acc: 0.4500\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 1.2198 - acc: 0.5833 - val_loss: 1.3514 - val_acc: 0.5000\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 1.0997 - acc: 0.5167 - val_loss: 1.3380 - val_acc: 0.5000\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.9758 - acc: 0.6833 - val_loss: 1.3251 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 752us/sample - loss: 0.9199 - acc: 0.6167 - val_loss: 1.3123 - val_acc: 0.4500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.8791 - acc: 0.5667 - val_loss: 1.2999 - val_acc: 0.4500\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.8530 - acc: 0.6333 - val_loss: 1.2877 - val_acc: 0.4500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.8195 - acc: 0.7167 - val_loss: 1.2762 - val_acc: 0.4500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.8031 - acc: 0.7167 - val_loss: 1.2651 - val_acc: 0.4500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.7828 - acc: 0.7500 - val_loss: 1.2540 - val_acc: 0.4500\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.7624 - acc: 0.8000 - val_loss: 1.2433 - val_acc: 0.4500\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.7561 - acc: 0.7500 - val_loss: 1.2333 - val_acc: 0.4500\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.7416 - acc: 0.7833 - val_loss: 1.2236 - val_acc: 0.4500\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.7375 - acc: 0.7833 - val_loss: 1.2143 - val_acc: 0.3500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.7386 - acc: 0.7500 - val_loss: 1.2050 - val_acc: 0.3500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.7184 - acc: 0.8333 - val_loss: 1.1961 - val_acc: 0.3500\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.7172 - acc: 0.8833 - val_loss: 1.1868 - val_acc: 0.3500\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.7127 - acc: 0.8333 - val_loss: 1.1781 - val_acc: 0.3500\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.6855 - acc: 0.8667 - val_loss: 1.1700 - val_acc: 0.3500\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.6962 - acc: 0.7667 - val_loss: 1.1623 - val_acc: 0.3500\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.6911 - acc: 0.9000 - val_loss: 1.1555 - val_acc: 0.3500\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.6602 - acc: 0.8833 - val_loss: 1.1491 - val_acc: 0.3500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.6620 - acc: 0.8333 - val_loss: 1.1425 - val_acc: 0.3500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.6534 - acc: 0.8667 - val_loss: 1.1361 - val_acc: 0.3500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.6590 - acc: 0.8667 - val_loss: 1.1301 - val_acc: 0.3500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.6590 - acc: 0.8333 - val_loss: 1.1240 - val_acc: 0.3500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.6277 - acc: 0.9167 - val_loss: 1.1180 - val_acc: 0.4000\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.6485 - acc: 0.8500 - val_loss: 1.1122 - val_acc: 0.4000\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.6209 - acc: 0.8833 - val_loss: 1.1067 - val_acc: 0.4000\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.6302 - acc: 0.8833 - val_loss: 1.1013 - val_acc: 0.4000\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.6491 - acc: 0.8500 - val_loss: 1.0957 - val_acc: 0.4000\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.6285 - acc: 0.9000 - val_loss: 1.0898 - val_acc: 0.4000\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.6100 - acc: 0.9333 - val_loss: 1.0840 - val_acc: 0.4000\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.6027 - acc: 0.9167 - val_loss: 1.0788 - val_acc: 0.4000\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.5860 - acc: 0.8833 - val_loss: 1.0735 - val_acc: 0.4000\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.5898 - acc: 0.8833 - val_loss: 1.0681 - val_acc: 0.4000\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.5886 - acc: 0.8833 - val_loss: 1.0629 - val_acc: 0.4000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.5893 - acc: 0.9000 - val_loss: 1.0577 - val_acc: 0.4500\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.5644 - acc: 0.8667 - val_loss: 1.0521 - val_acc: 0.4500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.6055 - acc: 0.8500 - val_loss: 1.0469 - val_acc: 0.4500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.5596 - acc: 0.9500 - val_loss: 1.0420 - val_acc: 0.4500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.5828 - acc: 0.8333 - val_loss: 1.0372 - val_acc: 0.4500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.5743 - acc: 0.9000 - val_loss: 1.0327 - val_acc: 0.4500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.5502 - acc: 0.9333 - val_loss: 1.0283 - val_acc: 0.5000\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.5587 - acc: 0.7833 - val_loss: 1.0241 - val_acc: 0.5000\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.5368 - acc: 0.9000 - val_loss: 1.0202 - val_acc: 0.5000\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.5494 - acc: 0.9167 - val_loss: 1.0161 - val_acc: 0.6000\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.5060 - acc: 0.9333 - val_loss: 1.0125 - val_acc: 0.6000\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.5463 - acc: 0.8500 - val_loss: 1.0089 - val_acc: 0.6000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.5441 - acc: 0.8333 - val_loss: 1.0049 - val_acc: 0.6000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.5361 - acc: 0.9000 - val_loss: 1.0008 - val_acc: 0.6000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.5336 - acc: 0.9000 - val_loss: 0.9961 - val_acc: 0.6000\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.5095 - acc: 0.9167 - val_loss: 0.9916 - val_acc: 0.6000\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.5244 - acc: 0.8500 - val_loss: 0.9869 - val_acc: 0.6000\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.5067 - acc: 0.8833 - val_loss: 0.9829 - val_acc: 0.6000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.5242 - acc: 0.8500 - val_loss: 0.9793 - val_acc: 0.6000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.4882 - acc: 0.9000 - val_loss: 0.9760 - val_acc: 0.6000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.5136 - acc: 0.9167 - val_loss: 0.9740 - val_acc: 0.6000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.5109 - acc: 0.9000 - val_loss: 0.9709 - val_acc: 0.6000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.5357 - acc: 0.9000 - val_loss: 0.9664 - val_acc: 0.6000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.4961 - acc: 0.9167 - val_loss: 0.9609 - val_acc: 0.6000\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.4701 - acc: 0.8833 - val_loss: 0.9563 - val_acc: 0.6000\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.4664 - acc: 0.9167 - val_loss: 0.9523 - val_acc: 0.6000\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.4673 - acc: 0.9167 - val_loss: 0.9480 - val_acc: 0.6000\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.4601 - acc: 0.8667 - val_loss: 0.9435 - val_acc: 0.6000\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.4683 - acc: 0.8833 - val_loss: 0.9401 - val_acc: 0.6000\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.4831 - acc: 0.8333 - val_loss: 0.9364 - val_acc: 0.6000\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.4654 - acc: 0.9000 - val_loss: 0.9323 - val_acc: 0.6500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.4565 - acc: 0.9333 - val_loss: 0.9272 - val_acc: 0.6500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 750us/sample - loss: 0.4382 - acc: 0.8833 - val_loss: 0.9220 - val_acc: 0.6500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.4288 - acc: 0.9667 - val_loss: 0.9169 - val_acc: 0.6500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.4459 - acc: 0.9167 - val_loss: 0.9119 - val_acc: 0.6000\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4192 - acc: 0.9833 - val_loss: 0.9072 - val_acc: 0.6000\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.4522 - acc: 0.9000 - val_loss: 0.9019 - val_acc: 0.6000\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.4230 - acc: 0.9500 - val_loss: 0.8980 - val_acc: 0.6500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.4213 - acc: 0.9167 - val_loss: 0.8944 - val_acc: 0.7000\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.4299 - acc: 0.8667 - val_loss: 0.8917 - val_acc: 0.7000\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.4043 - acc: 0.9667 - val_loss: 0.8883 - val_acc: 0.7000\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.4213 - acc: 0.9333 - val_loss: 0.8819 - val_acc: 0.7000\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.4075 - acc: 0.9167 - val_loss: 0.8769 - val_acc: 0.7000\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.4028 - acc: 0.9500 - val_loss: 0.8719 - val_acc: 0.7000\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.4005 - acc: 0.9000 - val_loss: 0.8675 - val_acc: 0.7000\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3921 - acc: 0.9667 - val_loss: 0.8628 - val_acc: 0.7000\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.4121 - acc: 0.9167 - val_loss: 0.8579 - val_acc: 0.7000\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.4002 - acc: 0.9500 - val_loss: 0.8503 - val_acc: 0.7000\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.3999 - acc: 0.9500 - val_loss: 0.8434 - val_acc: 0.7000\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.3749 - acc: 0.9333 - val_loss: 0.8351 - val_acc: 0.7000\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3828 - acc: 0.9500 - val_loss: 0.8273 - val_acc: 0.6500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3542 - acc: 0.9667 - val_loss: 0.8203 - val_acc: 0.6500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.3843 - acc: 0.9333 - val_loss: 0.8115 - val_acc: 0.6500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.4059 - acc: 0.8833 - val_loss: 0.8033 - val_acc: 0.6500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3738 - acc: 0.9500 - val_loss: 0.7963 - val_acc: 0.6500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.3370 - acc: 0.9833 - val_loss: 0.7906 - val_acc: 0.6500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.3741 - acc: 0.9333 - val_loss: 0.7853 - val_acc: 0.6000\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.3540 - acc: 0.9167 - val_loss: 0.7790 - val_acc: 0.6000\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.3244 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.6000\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3401 - acc: 0.9667 - val_loss: 0.7651 - val_acc: 0.5500\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3259 - acc: 0.9833 - val_loss: 0.7587 - val_acc: 0.5000\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3283 - acc: 0.9333 - val_loss: 0.7533 - val_acc: 0.5000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.3403 - acc: 0.9667 - val_loss: 0.7498 - val_acc: 0.5000\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.3189 - acc: 0.9667 - val_loss: 0.7470 - val_acc: 0.5000\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2928 - acc: 0.9500 - val_loss: 0.7431 - val_acc: 0.5000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.3298 - acc: 0.9667 - val_loss: 0.7394 - val_acc: 0.5000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3194 - acc: 0.9333 - val_loss: 0.7378 - val_acc: 0.5000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3270 - acc: 0.9167 - val_loss: 0.7382 - val_acc: 0.5000\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.3148 - acc: 0.9333 - val_loss: 0.7394 - val_acc: 0.5500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.2940 - acc: 0.9667 - val_loss: 0.7379 - val_acc: 0.5500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3158 - acc: 0.9500 - val_loss: 0.7341 - val_acc: 0.5500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2747 - acc: 0.9500 - val_loss: 0.7289 - val_acc: 0.5500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3233 - acc: 0.9167 - val_loss: 0.7289 - val_acc: 0.6000\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2985 - acc: 0.9667 - val_loss: 0.7279 - val_acc: 0.6500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3299 - acc: 0.9000 - val_loss: 0.7281 - val_acc: 0.6500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.2844 - acc: 0.9833 - val_loss: 0.7271 - val_acc: 0.6500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.3007 - acc: 0.9667 - val_loss: 0.7276 - val_acc: 0.6500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2701 - acc: 0.9667 - val_loss: 0.7358 - val_acc: 0.6000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2717 - acc: 0.9833 - val_loss: 0.7435 - val_acc: 0.6000\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2919 - acc: 0.9667 - val_loss: 0.7479 - val_acc: 0.6000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2559 - acc: 1.0000 - val_loss: 0.7562 - val_acc: 0.5500\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2708 - acc: 0.9500 - val_loss: 0.7568 - val_acc: 0.5500\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.2569 - acc: 0.9667 - val_loss: 0.7532 - val_acc: 0.6000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2763 - acc: 0.9333 - val_loss: 0.7438 - val_acc: 0.6000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2802 - acc: 0.9500 - val_loss: 0.7225 - val_acc: 0.6500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2870 - acc: 0.9500 - val_loss: 0.7046 - val_acc: 0.6500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.2408 - acc: 0.9667 - val_loss: 0.6996 - val_acc: 0.6500\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2476 - acc: 1.0000 - val_loss: 0.6979 - val_acc: 0.6500\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2877 - acc: 0.9167 - val_loss: 0.6915 - val_acc: 0.6500\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2497 - acc: 0.9500 - val_loss: 0.6870 - val_acc: 0.6500\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2425 - acc: 0.9333 - val_loss: 0.6778 - val_acc: 0.6500\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2526 - acc: 0.9667 - val_loss: 0.6685 - val_acc: 0.6500\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2298 - acc: 0.9500 - val_loss: 0.6669 - val_acc: 0.6500\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.2190 - acc: 0.9833 - val_loss: 0.6733 - val_acc: 0.6500\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2306 - acc: 0.9667 - val_loss: 0.6838 - val_acc: 0.6500\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2343 - acc: 0.9833 - val_loss: 0.6993 - val_acc: 0.6000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1841 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.6000\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2037 - acc: 0.9833 - val_loss: 0.7070 - val_acc: 0.6000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2367 - acc: 0.9667 - val_loss: 0.7067 - val_acc: 0.6000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2325 - acc: 0.9667 - val_loss: 0.7106 - val_acc: 0.5500\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.2045 - acc: 1.0000 - val_loss: 0.7187 - val_acc: 0.5500\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.2232 - acc: 0.9667 - val_loss: 0.7394 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2004 - acc: 0.9667 - val_loss: 0.7555 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1992 - acc: 0.9833 - val_loss: 0.7640 - val_acc: 0.5500\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2264 - acc: 0.9500 - val_loss: 0.7683 - val_acc: 0.5500\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.2332 - acc: 0.9500 - val_loss: 0.7582 - val_acc: 0.5500\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2136 - acc: 0.9500 - val_loss: 0.7389 - val_acc: 0.5000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2111 - acc: 0.9833 - val_loss: 0.7082 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2160 - acc: 0.9833 - val_loss: 0.6865 - val_acc: 0.6000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1776 - acc: 0.9833 - val_loss: 0.6814 - val_acc: 0.6000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.2024 - acc: 0.9500 - val_loss: 0.6874 - val_acc: 0.5500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1852 - acc: 1.0000 - val_loss: 0.6914 - val_acc: 0.5500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1700 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.5500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1837 - acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.5500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1958 - acc: 0.9500 - val_loss: 0.7042 - val_acc: 0.5500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1638 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.5000\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2211 - acc: 0.9500 - val_loss: 0.7471 - val_acc: 0.5000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1873 - acc: 0.9667 - val_loss: 0.7653 - val_acc: 0.5000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2013 - acc: 0.9500 - val_loss: 0.7885 - val_acc: 0.5500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1903 - acc: 0.9667 - val_loss: 0.8125 - val_acc: 0.5500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1811 - acc: 0.9667 - val_loss: 0.8364 - val_acc: 0.5500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1573 - acc: 0.9833 - val_loss: 0.8500 - val_acc: 0.5500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1808 - acc: 0.9500 - val_loss: 0.8595 - val_acc: 0.5500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1791 - acc: 0.9667 - val_loss: 0.8559 - val_acc: 0.5500\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1262 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.5000\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2268 - acc: 0.9167 - val_loss: 0.8589 - val_acc: 0.5000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1856 - acc: 0.9667 - val_loss: 0.8611 - val_acc: 0.5000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1803 - acc: 0.9333 - val_loss: 0.8350 - val_acc: 0.5500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1956 - acc: 0.9833 - val_loss: 0.8248 - val_acc: 0.5500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1541 - acc: 0.9833 - val_loss: 0.8159 - val_acc: 0.5500\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1441 - acc: 0.9833 - val_loss: 0.8111 - val_acc: 0.5500\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1732 - acc: 0.9667 - val_loss: 0.7916 - val_acc: 0.5000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1793 - acc: 0.9833 - val_loss: 0.7841 - val_acc: 0.5000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1453 - acc: 0.9833 - val_loss: 0.7797 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 726us/sample - loss: 0.1599 - acc: 0.9833 - val_loss: 0.7705 - val_acc: 0.5000\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1746 - acc: 0.9833 - val_loss: 0.7593 - val_acc: 0.5000\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.1410 - acc: 0.9833 - val_loss: 0.7475 - val_acc: 0.5000\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1639 - acc: 0.9667 - val_loss: 0.7234 - val_acc: 0.5000\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1673 - acc: 0.9333 - val_loss: 0.6901 - val_acc: 0.5500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1920 - acc: 0.9500 - val_loss: 0.6721 - val_acc: 0.5500\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1238 - acc: 1.0000 - val_loss: 0.6895 - val_acc: 0.5500\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1854 - acc: 0.9167 - val_loss: 0.7105 - val_acc: 0.5000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.1856 - acc: 0.9667 - val_loss: 0.7348 - val_acc: 0.4500\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1672 - acc: 1.0000 - val_loss: 0.7573 - val_acc: 0.5000\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1596 - acc: 0.9833 - val_loss: 0.7846 - val_acc: 0.5000\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1475 - acc: 0.9667 - val_loss: 0.8070 - val_acc: 0.5000\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1638 - acc: 0.9833 - val_loss: 0.7988 - val_acc: 0.5000\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2200 - acc: 0.9333 - val_loss: 0.7593 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1759 - acc: 0.9667 - val_loss: 0.7145 - val_acc: 0.6000\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1272 - acc: 1.0000 - val_loss: 0.6719 - val_acc: 0.6000\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2003 - acc: 0.9500 - val_loss: 0.6573 - val_acc: 0.6000\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1343 - acc: 1.0000 - val_loss: 0.6282 - val_acc: 0.7500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1259 - acc: 1.0000 - val_loss: 0.6053 - val_acc: 0.7500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1390 - acc: 0.9833 - val_loss: 0.5976 - val_acc: 0.7500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1272 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.7500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1449 - acc: 0.9667 - val_loss: 0.6216 - val_acc: 0.7500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1673 - acc: 0.9667 - val_loss: 0.6535 - val_acc: 0.6000\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.1417 - acc: 0.9833 - val_loss: 0.6989 - val_acc: 0.5500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1596 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.5500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1795 - acc: 0.9333 - val_loss: 0.7001 - val_acc: 0.6000\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1384 - acc: 1.0000 - val_loss: 0.6906 - val_acc: 0.6000\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1146 - acc: 0.9667 - val_loss: 0.6750 - val_acc: 0.6000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1293 - acc: 0.9833 - val_loss: 0.6813 - val_acc: 0.6000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1971 - acc: 0.9667 - val_loss: 0.6712 - val_acc: 0.6000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1437 - acc: 0.9833 - val_loss: 0.6678 - val_acc: 0.6000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1913 - acc: 0.9500 - val_loss: 0.6726 - val_acc: 0.6000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1459 - acc: 0.9667 - val_loss: 0.6795 - val_acc: 0.6000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1329 - acc: 0.9833 - val_loss: 0.6877 - val_acc: 0.6000\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1436 - acc: 0.9667 - val_loss: 0.6800 - val_acc: 0.6000\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1387 - acc: 0.9833 - val_loss: 0.6790 - val_acc: 0.6000\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1304 - acc: 0.9833 - val_loss: 0.6785 - val_acc: 0.6000\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1142 - acc: 0.9833 - val_loss: 0.6664 - val_acc: 0.6500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1215 - acc: 0.9667 - val_loss: 0.6550 - val_acc: 0.7000\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.7500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1322 - acc: 0.9833 - val_loss: 0.6294 - val_acc: 0.7500\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1269 - acc: 0.9833 - val_loss: 0.6257 - val_acc: 0.7500\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1489 - acc: 0.9500 - val_loss: 0.6273 - val_acc: 0.7500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1359 - acc: 1.0000 - val_loss: 0.6293 - val_acc: 0.7500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1256 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.7500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1243 - acc: 0.9833 - val_loss: 0.6356 - val_acc: 0.7000\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1021 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 0.7000\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 798us/sample - loss: 0.1000 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.7000\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1332 - acc: 0.9667 - val_loss: 0.6408 - val_acc: 0.7500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1202 - acc: 0.9667 - val_loss: 0.6414 - val_acc: 0.7500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1029 - acc: 0.9833 - val_loss: 0.6442 - val_acc: 0.7500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1127 - acc: 0.9833 - val_loss: 0.6460 - val_acc: 0.7500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1291 - acc: 1.0000 - val_loss: 0.6503 - val_acc: 0.7500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1409 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.7500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1096 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.7500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1418 - acc: 0.9667 - val_loss: 0.6545 - val_acc: 0.7500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1752 - acc: 0.9333 - val_loss: 0.6520 - val_acc: 0.7500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1441 - acc: 0.9833 - val_loss: 0.6372 - val_acc: 0.7500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1081 - acc: 1.0000 - val_loss: 0.6235 - val_acc: 0.8000\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1143 - acc: 0.9833 - val_loss: 0.6127 - val_acc: 0.8000\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1348 - acc: 0.9667 - val_loss: 0.6018 - val_acc: 0.8000\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1004 - acc: 0.9833 - val_loss: 0.6022 - val_acc: 0.8000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1108 - acc: 0.9833 - val_loss: 0.6017 - val_acc: 0.8000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1332 - acc: 1.0000 - val_loss: 0.6056 - val_acc: 0.8000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1119 - acc: 0.9500 - val_loss: 0.6127 - val_acc: 0.8000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.1113 - acc: 0.9833 - val_loss: 0.6240 - val_acc: 0.8000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0959 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.8000\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1115 - acc: 0.9833 - val_loss: 0.6487 - val_acc: 0.8000\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1189 - acc: 1.0000 - val_loss: 0.6645 - val_acc: 0.8000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.6752 - val_acc: 0.7500\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.6837 - val_acc: 0.7500\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1651 - acc: 0.9833 - val_loss: 0.6941 - val_acc: 0.7500\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 0.6965 - val_acc: 0.7500\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1365 - acc: 0.9833 - val_loss: 0.6938 - val_acc: 0.7500\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1359 - acc: 0.9333 - val_loss: 0.6862 - val_acc: 0.7500\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1193 - acc: 1.0000 - val_loss: 0.6784 - val_acc: 0.8000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1028 - acc: 0.9833 - val_loss: 0.6638 - val_acc: 0.8000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0974 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.8000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1048 - acc: 0.9667 - val_loss: 0.6471 - val_acc: 0.8000\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1050 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 0.8000\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1310 - acc: 0.9667 - val_loss: 0.6437 - val_acc: 0.8000\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1113 - acc: 0.9833 - val_loss: 0.6432 - val_acc: 0.8000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0973 - acc: 0.9833 - val_loss: 0.6492 - val_acc: 0.8000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1103 - acc: 1.0000 - val_loss: 0.6557 - val_acc: 0.8000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0999 - acc: 0.9833 - val_loss: 0.6593 - val_acc: 0.8000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1207 - acc: 0.9833 - val_loss: 0.6621 - val_acc: 0.8000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0856 - acc: 1.0000 - val_loss: 0.6657 - val_acc: 0.8000\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0781 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.8000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0969 - acc: 0.9833 - val_loss: 0.6688 - val_acc: 0.8000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.1134 - acc: 0.9667 - val_loss: 0.6633 - val_acc: 0.8000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1330 - acc: 0.9667 - val_loss: 0.6661 - val_acc: 0.8000\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1373 - acc: 0.9333 - val_loss: 0.6751 - val_acc: 0.8000\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1138 - acc: 0.9667 - val_loss: 0.6772 - val_acc: 0.7500\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1029 - acc: 0.9833 - val_loss: 0.6818 - val_acc: 0.7500\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1082 - acc: 0.9833 - val_loss: 0.6820 - val_acc: 0.7500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1171 - acc: 1.0000 - val_loss: 0.6917 - val_acc: 0.7500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1288 - acc: 0.9833 - val_loss: 0.7092 - val_acc: 0.7500\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0943 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.7500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1112 - acc: 0.9667 - val_loss: 0.7432 - val_acc: 0.7500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1155 - acc: 0.9833 - val_loss: 0.7445 - val_acc: 0.7500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1341 - acc: 0.9667 - val_loss: 0.7430 - val_acc: 0.7500\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1077 - acc: 1.0000 - val_loss: 0.7438 - val_acc: 0.7500\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0940 - acc: 1.0000 - val_loss: 0.7421 - val_acc: 0.7500\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1131 - acc: 0.9667 - val_loss: 0.7404 - val_acc: 0.7500\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1220 - acc: 0.9833 - val_loss: 0.7350 - val_acc: 0.7500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1318 - acc: 0.9500 - val_loss: 0.7177 - val_acc: 0.7500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1072 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.7500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0860 - acc: 1.0000 - val_loss: 0.7000 - val_acc: 0.7500\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0820 - acc: 0.9833 - val_loss: 0.6831 - val_acc: 0.7500\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0982 - acc: 0.9833 - val_loss: 0.6754 - val_acc: 0.7500\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0918 - acc: 1.0000 - val_loss: 0.6736 - val_acc: 0.7500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.0832 - acc: 1.0000 - val_loss: 0.6875 - val_acc: 0.7500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1081 - acc: 1.0000 - val_loss: 0.7042 - val_acc: 0.7500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1048 - acc: 0.9833 - val_loss: 0.7107 - val_acc: 0.7500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0812 - acc: 0.9833 - val_loss: 0.7344 - val_acc: 0.7500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1076 - acc: 0.9833 - val_loss: 0.7650 - val_acc: 0.7500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0864 - acc: 0.9833 - val_loss: 0.7797 - val_acc: 0.7500\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1004 - acc: 1.0000 - val_loss: 0.7931 - val_acc: 0.7500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1130 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.7500\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1326 - acc: 0.9667 - val_loss: 0.8041 - val_acc: 0.7000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1268 - acc: 0.9667 - val_loss: 0.8108 - val_acc: 0.7000\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0966 - acc: 0.9833 - val_loss: 0.8029 - val_acc: 0.7000\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0800 - acc: 1.0000 - val_loss: 0.7954 - val_acc: 0.7500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 742us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.8017 - val_acc: 0.7500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.7948 - val_acc: 0.7500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1034 - acc: 0.9667 - val_loss: 0.7769 - val_acc: 0.7500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1052 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.7500\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1033 - acc: 0.9833 - val_loss: 0.7533 - val_acc: 0.7500\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1125 - acc: 0.9667 - val_loss: 0.7256 - val_acc: 0.8000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0748 - acc: 1.0000 - val_loss: 0.7150 - val_acc: 0.8000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0950 - acc: 0.9833 - val_loss: 0.7216 - val_acc: 0.8000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.8000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0753 - acc: 1.0000 - val_loss: 0.7527 - val_acc: 0.7500\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0816 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.7500\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1048 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.7500\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0971 - acc: 0.9833 - val_loss: 0.7673 - val_acc: 0.7500\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1112 - acc: 0.9833 - val_loss: 0.7324 - val_acc: 0.7500\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1181 - acc: 0.9667 - val_loss: 0.7144 - val_acc: 0.7500\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0874 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.8000\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.0852 - acc: 1.0000 - val_loss: 0.7042 - val_acc: 0.8000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.0752 - acc: 1.0000 - val_loss: 0.7044 - val_acc: 0.8000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1512 - acc: 0.9333 - val_loss: 0.7285 - val_acc: 0.7500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0963 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.7500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.0778 - acc: 1.0000 - val_loss: 0.7447 - val_acc: 0.7500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0938 - acc: 0.9833 - val_loss: 0.7441 - val_acc: 0.7500\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0788 - acc: 0.9833 - val_loss: 0.7410 - val_acc: 0.7500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0913 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.8000\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0666 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.8000\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.8000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0663 - acc: 0.9833 - val_loss: 0.7309 - val_acc: 0.8000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.7313 - val_acc: 0.8000\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1156 - acc: 0.9667 - val_loss: 0.7394 - val_acc: 0.7500\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 752us/sample - loss: 0.1325 - acc: 0.9833 - val_loss: 0.7476 - val_acc: 0.7500\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1333 - acc: 0.9333 - val_loss: 0.7435 - val_acc: 0.7500\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0855 - acc: 0.9833 - val_loss: 0.7400 - val_acc: 0.7500\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1106 - acc: 0.9833 - val_loss: 0.7364 - val_acc: 0.7500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0677 - acc: 1.0000 - val_loss: 0.7418 - val_acc: 0.7500\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.7456 - val_acc: 0.7500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0842 - acc: 0.9833 - val_loss: 0.7514 - val_acc: 0.7500\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0734 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.7500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1380 - acc: 0.9833 - val_loss: 0.7553 - val_acc: 0.7500\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 0.7500\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0663 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.7500\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0780 - acc: 0.9833 - val_loss: 0.7636 - val_acc: 0.7500\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0645 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.8000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0805 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.8000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0738 - acc: 1.0000 - val_loss: 0.7586 - val_acc: 0.8000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 745us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.8000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0503 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.8000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0835 - acc: 0.9833 - val_loss: 0.7716 - val_acc: 0.8000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0703 - acc: 0.9833 - val_loss: 0.7645 - val_acc: 0.8000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.0796 - acc: 0.9833 - val_loss: 0.7635 - val_acc: 0.8000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.7605 - val_acc: 0.8000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1452 - acc: 0.9500 - val_loss: 0.7502 - val_acc: 0.8000\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 0.7492 - val_acc: 0.8000\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.8000\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1010 - acc: 0.9833 - val_loss: 0.7693 - val_acc: 0.8000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0703 - acc: 1.0000 - val_loss: 0.7914 - val_acc: 0.7500\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0606 - acc: 1.0000 - val_loss: 0.8071 - val_acc: 0.7500\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0873 - acc: 0.9833 - val_loss: 0.8253 - val_acc: 0.7500\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0937 - acc: 0.9833 - val_loss: 0.8677 - val_acc: 0.7500\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.9312 - val_acc: 0.8000\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0885 - acc: 0.9833 - val_loss: 0.9717 - val_acc: 0.8000\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1098 - acc: 0.9833 - val_loss: 0.9934 - val_acc: 0.8000\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1171 - acc: 1.0000 - val_loss: 1.0369 - val_acc: 0.7500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0827 - acc: 1.0000 - val_loss: 1.0923 - val_acc: 0.7500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 1.1265 - val_acc: 0.7500\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0849 - acc: 1.0000 - val_loss: 1.1516 - val_acc: 0.7500\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0812 - acc: 1.0000 - val_loss: 1.1324 - val_acc: 0.7500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0766 - acc: 0.9833 - val_loss: 1.0844 - val_acc: 0.7500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0615 - acc: 1.0000 - val_loss: 1.0560 - val_acc: 0.7500\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0730 - acc: 0.9833 - val_loss: 1.0357 - val_acc: 0.7500\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0868 - acc: 0.9833 - val_loss: 1.0043 - val_acc: 0.7500\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0729 - acc: 1.0000 - val_loss: 0.9738 - val_acc: 0.7500\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0646 - acc: 1.0000 - val_loss: 0.9433 - val_acc: 0.7500\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 743us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.9027 - val_acc: 0.7500\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0987 - acc: 0.9833 - val_loss: 0.8789 - val_acc: 0.7500\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 0.7500\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.8553 - val_acc: 0.7500\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.8429 - val_acc: 0.7500\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0563 - acc: 1.0000 - val_loss: 0.8390 - val_acc: 0.7500\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.8500 - val_acc: 0.7500\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0799 - acc: 0.9833 - val_loss: 0.8514 - val_acc: 0.7500\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1109 - acc: 0.9667 - val_loss: 0.8721 - val_acc: 0.7500\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0757 - acc: 1.0000 - val_loss: 0.9235 - val_acc: 0.7500\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0579 - acc: 0.9833 - val_loss: 0.9623 - val_acc: 0.7500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1203 - acc: 0.9500 - val_loss: 0.9840 - val_acc: 0.8000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0673 - acc: 0.9833 - val_loss: 1.0001 - val_acc: 0.7500\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0868 - acc: 0.9833 - val_loss: 0.9800 - val_acc: 0.7500\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1046 - acc: 0.9667 - val_loss: 0.8974 - val_acc: 0.7500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.8513 - val_acc: 0.7500\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0951 - acc: 0.9833 - val_loss: 0.8176 - val_acc: 0.8000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0733 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.8000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0734 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.7500\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0992 - acc: 0.9667 - val_loss: 0.7634 - val_acc: 0.7000\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.1167 - acc: 0.9667 - val_loss: 0.7650 - val_acc: 0.8000\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.8000\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.7500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0680 - acc: 1.0000 - val_loss: 0.8119 - val_acc: 0.7500\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0569 - acc: 1.0000 - val_loss: 0.8220 - val_acc: 0.7500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.8403 - val_acc: 0.7500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.8356 - val_acc: 0.7500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0771 - acc: 1.0000 - val_loss: 0.8390 - val_acc: 0.7500\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0796 - acc: 0.9833 - val_loss: 0.8320 - val_acc: 0.7500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0753 - acc: 1.0000 - val_loss: 0.8133 - val_acc: 0.7500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0692 - acc: 1.0000 - val_loss: 0.7953 - val_acc: 0.7500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.0509 - acc: 1.0000 - val_loss: 0.7942 - val_acc: 0.7500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0762 - acc: 1.0000 - val_loss: 0.7958 - val_acc: 0.7500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.8069 - val_acc: 0.7500\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0673 - acc: 0.9833 - val_loss: 0.8341 - val_acc: 0.7500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0854 - acc: 0.9833 - val_loss: 0.8686 - val_acc: 0.7500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0755 - acc: 1.0000 - val_loss: 0.8687 - val_acc: 0.7500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0752 - acc: 0.9833 - val_loss: 0.8955 - val_acc: 0.7500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 0.9165 - val_acc: 0.7500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0731 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.7500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.9251 - val_acc: 0.7500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0805 - acc: 0.9833 - val_loss: 0.9104 - val_acc: 0.7500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0638 - acc: 1.0000 - val_loss: 0.8855 - val_acc: 0.7500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0958 - acc: 0.9833 - val_loss: 0.8381 - val_acc: 0.7500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.0747 - acc: 1.0000 - val_loss: 0.7966 - val_acc: 0.7500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1301 - acc: 0.9667 - val_loss: 0.7727 - val_acc: 0.7500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0806 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.8000\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0899 - acc: 0.9667 - val_loss: 0.7642 - val_acc: 0.7500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0871 - acc: 0.9667 - val_loss: 0.7708 - val_acc: 0.7500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0920 - acc: 0.9833 - val_loss: 0.7771 - val_acc: 0.7500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0973 - acc: 0.9833 - val_loss: 0.7887 - val_acc: 0.8000\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0669 - acc: 0.9833 - val_loss: 0.8057 - val_acc: 0.8000\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0863 - acc: 0.9667 - val_loss: 0.8096 - val_acc: 0.7500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0595 - acc: 0.9833 - val_loss: 0.8002 - val_acc: 0.8000\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1036 - acc: 0.9667 - val_loss: 0.7988 - val_acc: 0.8000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.7968 - val_acc: 0.8000\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.0728 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.7500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.0836 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.7500\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.7500\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0882 - acc: 0.9833 - val_loss: 0.8338 - val_acc: 0.7500\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0865 - acc: 0.9833 - val_loss: 0.8565 - val_acc: 0.7500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0560 - acc: 0.9833 - val_loss: 0.8919 - val_acc: 0.7500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0929 - acc: 0.9667 - val_loss: 0.9276 - val_acc: 0.7500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.9283 - val_acc: 0.7500\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0644 - acc: 0.9833 - val_loss: 0.9265 - val_acc: 0.7500\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0797 - acc: 0.9833 - val_loss: 0.9219 - val_acc: 0.7500\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.9302 - val_acc: 0.7500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.7500\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0620 - acc: 1.0000 - val_loss: 0.9602 - val_acc: 0.7500\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.9829 - val_acc: 0.7500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1388 - acc: 0.9333 - val_loss: 0.9634 - val_acc: 0.7500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0702 - acc: 0.9833 - val_loss: 0.9062 - val_acc: 0.7500\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.0640 - acc: 1.0000 - val_loss: 0.8764 - val_acc: 0.7500\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.8502 - val_acc: 0.7500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.7500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.8461 - val_acc: 0.7500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.8438 - val_acc: 0.7500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0931 - acc: 0.9833 - val_loss: 0.8212 - val_acc: 0.7500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0682 - acc: 0.9833 - val_loss: 0.7964 - val_acc: 0.7500\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.0689 - acc: 0.9833 - val_loss: 0.7916 - val_acc: 0.7500\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0570 - acc: 1.0000 - val_loss: 0.7922 - val_acc: 0.7500\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0778 - acc: 1.0000 - val_loss: 0.7914 - val_acc: 0.7500\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0646 - acc: 0.9667 - val_loss: 0.7795 - val_acc: 0.7500\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.7500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0957 - acc: 0.9833 - val_loss: 0.7513 - val_acc: 0.8000\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0859 - acc: 0.9833 - val_loss: 0.7628 - val_acc: 0.8000\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.7500\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0675 - acc: 1.0000 - val_loss: 0.7870 - val_acc: 0.7500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.0724 - acc: 0.9833 - val_loss: 0.7751 - val_acc: 0.7500\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.8000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0689 - acc: 1.0000 - val_loss: 0.7526 - val_acc: 0.8000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.8000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.8000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0726 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.8000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0682 - acc: 0.9833 - val_loss: 0.7231 - val_acc: 0.8000\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.0694 - acc: 1.0000 - val_loss: 0.7221 - val_acc: 0.8000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.8000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.8000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0897 - acc: 0.9833 - val_loss: 0.7370 - val_acc: 0.8000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.7494 - val_acc: 0.8000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1013 - acc: 1.0000 - val_loss: 0.7635 - val_acc: 0.8000\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1034 - acc: 0.9667 - val_loss: 0.7709 - val_acc: 0.8000\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0795 - acc: 0.9833 - val_loss: 0.7725 - val_acc: 0.8000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0642 - acc: 1.0000 - val_loss: 0.7948 - val_acc: 0.7500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 753us/sample - loss: 0.1258 - acc: 0.9667 - val_loss: 0.8597 - val_acc: 0.7500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0778 - acc: 0.9667 - val_loss: 0.9197 - val_acc: 0.7500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.0640 - acc: 0.9833 - val_loss: 0.9493 - val_acc: 0.7500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.9769 - val_acc: 0.7000\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.7000\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0579 - acc: 0.9833 - val_loss: 0.9530 - val_acc: 0.7500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0592 - acc: 0.9833 - val_loss: 0.9310 - val_acc: 0.7500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0890 - acc: 0.9667 - val_loss: 0.9467 - val_acc: 0.7500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0480 - acc: 1.0000 - val_loss: 0.9529 - val_acc: 0.7500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.9492 - val_acc: 0.7500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 776us/sample - loss: 0.0800 - acc: 0.9667 - val_loss: 0.9420 - val_acc: 0.7500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0803 - acc: 0.9667 - val_loss: 0.9090 - val_acc: 0.7500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.7500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.8504 - val_acc: 0.7500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.8000\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.8072 - val_acc: 0.8000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.7914 - val_acc: 0.8000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0834 - acc: 0.9667 - val_loss: 0.7833 - val_acc: 0.8000\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.7828 - val_acc: 0.8000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0711 - acc: 0.9833 - val_loss: 0.8382 - val_acc: 0.7500\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.7500\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.0779 - acc: 0.9667 - val_loss: 0.9735 - val_acc: 0.7500\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0423 - acc: 1.0000 - val_loss: 1.0316 - val_acc: 0.8000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.0775 - acc: 0.9667 - val_loss: 1.0523 - val_acc: 0.8000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.0586 - acc: 1.0000 - val_loss: 1.0937 - val_acc: 0.7500\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.7500\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0600 - acc: 0.9833 - val_loss: 1.0714 - val_acc: 0.7500\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0671 - acc: 0.9833 - val_loss: 1.0085 - val_acc: 0.7500\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1066 - acc: 0.9667 - val_loss: 0.9249 - val_acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.7391 - acc: 0.6500\n",
            "test loss, test acc: [0.7391264736170114, 0.65]\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P06E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[2 1 2 2 2 2 1 1 2 1 2 2 1 2 2 1 1 2 2 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.5077 - acc: 0.3167 - val_loss: 1.3749 - val_acc: 0.4500\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 1.2718 - acc: 0.5000 - val_loss: 1.3626 - val_acc: 0.4500\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 1.1360 - acc: 0.6167 - val_loss: 1.3508 - val_acc: 0.5500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 1.0488 - acc: 0.6667 - val_loss: 1.3385 - val_acc: 0.6500\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.9748 - acc: 0.6667 - val_loss: 1.3258 - val_acc: 0.6500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.9271 - acc: 0.7000 - val_loss: 1.3134 - val_acc: 0.7000\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.8764 - acc: 0.7667 - val_loss: 1.3010 - val_acc: 0.6500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 741us/sample - loss: 0.8524 - acc: 0.7167 - val_loss: 1.2890 - val_acc: 0.6500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.8244 - acc: 0.7500 - val_loss: 1.2776 - val_acc: 0.6500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.8233 - acc: 0.6833 - val_loss: 1.2665 - val_acc: 0.6000\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.7951 - acc: 0.8000 - val_loss: 1.2554 - val_acc: 0.6500\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.7900 - acc: 0.7667 - val_loss: 1.2450 - val_acc: 0.6500\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.7709 - acc: 0.8000 - val_loss: 1.2348 - val_acc: 0.6000\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.7589 - acc: 0.8167 - val_loss: 1.2250 - val_acc: 0.6000\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.7431 - acc: 0.7667 - val_loss: 1.2159 - val_acc: 0.5500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.7438 - acc: 0.7833 - val_loss: 1.2068 - val_acc: 0.5500\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.7286 - acc: 0.8167 - val_loss: 1.1979 - val_acc: 0.5500\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.7265 - acc: 0.8333 - val_loss: 1.1894 - val_acc: 0.5500\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.6951 - acc: 0.8667 - val_loss: 1.1814 - val_acc: 0.5000\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.7084 - acc: 0.7833 - val_loss: 1.1735 - val_acc: 0.5000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.6995 - acc: 0.8333 - val_loss: 1.1655 - val_acc: 0.5000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.6986 - acc: 0.7000 - val_loss: 1.1578 - val_acc: 0.5500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.6847 - acc: 0.7500 - val_loss: 1.1500 - val_acc: 0.5500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.6662 - acc: 0.8333 - val_loss: 1.1423 - val_acc: 0.5500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.6561 - acc: 0.8667 - val_loss: 1.1350 - val_acc: 0.5000\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.6452 - acc: 0.8333 - val_loss: 1.1278 - val_acc: 0.4500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.6539 - acc: 0.8167 - val_loss: 1.1207 - val_acc: 0.4500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.6356 - acc: 0.8500 - val_loss: 1.1139 - val_acc: 0.4500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.6469 - acc: 0.8167 - val_loss: 1.1075 - val_acc: 0.4500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.6358 - acc: 0.8500 - val_loss: 1.1010 - val_acc: 0.4500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.6233 - acc: 0.8833 - val_loss: 1.0947 - val_acc: 0.4500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.6439 - acc: 0.8000 - val_loss: 1.0887 - val_acc: 0.4500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.6195 - acc: 0.8167 - val_loss: 1.0826 - val_acc: 0.4500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.6052 - acc: 0.8500 - val_loss: 1.0766 - val_acc: 0.4500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.6172 - acc: 0.8667 - val_loss: 1.0711 - val_acc: 0.4500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.5902 - acc: 0.9167 - val_loss: 1.0655 - val_acc: 0.4500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.5996 - acc: 0.8333 - val_loss: 1.0600 - val_acc: 0.4500\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.6043 - acc: 0.8667 - val_loss: 1.0545 - val_acc: 0.5000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.6015 - acc: 0.8333 - val_loss: 1.0493 - val_acc: 0.4500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.5864 - acc: 0.9000 - val_loss: 1.0440 - val_acc: 0.4500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.5676 - acc: 0.8833 - val_loss: 1.0385 - val_acc: 0.5000\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.5589 - acc: 0.8833 - val_loss: 1.0334 - val_acc: 0.5000\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.5544 - acc: 0.9000 - val_loss: 1.0277 - val_acc: 0.5500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.5570 - acc: 0.9000 - val_loss: 1.0217 - val_acc: 0.5000\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.5541 - acc: 0.9167 - val_loss: 1.0165 - val_acc: 0.5000\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.5614 - acc: 0.8500 - val_loss: 1.0110 - val_acc: 0.5500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.5518 - acc: 0.8833 - val_loss: 1.0061 - val_acc: 0.5000\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.5499 - acc: 0.8167 - val_loss: 1.0014 - val_acc: 0.5000\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.5228 - acc: 0.9167 - val_loss: 0.9962 - val_acc: 0.5000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.5278 - acc: 0.9167 - val_loss: 0.9913 - val_acc: 0.5000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.5270 - acc: 0.9000 - val_loss: 0.9867 - val_acc: 0.5000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.5177 - acc: 0.9167 - val_loss: 0.9810 - val_acc: 0.5000\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.5026 - acc: 0.9000 - val_loss: 0.9749 - val_acc: 0.6500\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.5205 - acc: 0.9000 - val_loss: 0.9697 - val_acc: 0.6500\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.5048 - acc: 0.8500 - val_loss: 0.9648 - val_acc: 0.6500\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.5277 - acc: 0.8667 - val_loss: 0.9607 - val_acc: 0.6000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 760us/sample - loss: 0.5329 - acc: 0.8667 - val_loss: 0.9555 - val_acc: 0.6500\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.4931 - acc: 0.9000 - val_loss: 0.9509 - val_acc: 0.6500\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.4947 - acc: 0.8833 - val_loss: 0.9462 - val_acc: 0.6500\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.4743 - acc: 0.9333 - val_loss: 0.9417 - val_acc: 0.6500\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.5050 - acc: 0.8667 - val_loss: 0.9377 - val_acc: 0.6500\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.5370 - acc: 0.8667 - val_loss: 0.9324 - val_acc: 0.7000\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.4699 - acc: 0.9333 - val_loss: 0.9270 - val_acc: 0.6500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.4868 - acc: 0.9167 - val_loss: 0.9196 - val_acc: 0.7000\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.4662 - acc: 0.9333 - val_loss: 0.9122 - val_acc: 0.7000\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.4554 - acc: 0.9167 - val_loss: 0.9060 - val_acc: 0.7000\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.4846 - acc: 0.9333 - val_loss: 0.8999 - val_acc: 0.7000\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.4821 - acc: 0.9500 - val_loss: 0.8943 - val_acc: 0.7000\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.4668 - acc: 0.9167 - val_loss: 0.8874 - val_acc: 0.7000\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.4526 - acc: 0.9000 - val_loss: 0.8808 - val_acc: 0.7000\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.4436 - acc: 0.9167 - val_loss: 0.8726 - val_acc: 0.7000\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4551 - acc: 0.9667 - val_loss: 0.8651 - val_acc: 0.7000\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4288 - acc: 0.9333 - val_loss: 0.8580 - val_acc: 0.7500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.4221 - acc: 0.9333 - val_loss: 0.8520 - val_acc: 0.7500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.4481 - acc: 0.9667 - val_loss: 0.8453 - val_acc: 0.7500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.4346 - acc: 0.9333 - val_loss: 0.8392 - val_acc: 0.7500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.4215 - acc: 0.9167 - val_loss: 0.8332 - val_acc: 0.7500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.4345 - acc: 0.9333 - val_loss: 0.8276 - val_acc: 0.7500\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4018 - acc: 0.9500 - val_loss: 0.8216 - val_acc: 0.7500\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.4137 - acc: 0.9500 - val_loss: 0.8142 - val_acc: 0.7500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.4212 - acc: 0.9000 - val_loss: 0.8067 - val_acc: 0.7500\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.4265 - acc: 0.9500 - val_loss: 0.7989 - val_acc: 0.7500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3910 - acc: 0.9333 - val_loss: 0.7908 - val_acc: 0.8000\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.3951 - acc: 0.9333 - val_loss: 0.7813 - val_acc: 0.8000\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.3748 - acc: 0.9500 - val_loss: 0.7711 - val_acc: 0.8000\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.3908 - acc: 0.9500 - val_loss: 0.7599 - val_acc: 0.8000\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.3684 - acc: 0.9500 - val_loss: 0.7489 - val_acc: 0.8000\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.3761 - acc: 0.9333 - val_loss: 0.7365 - val_acc: 0.7500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.3298 - acc: 0.9667 - val_loss: 0.7243 - val_acc: 0.7500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3406 - acc: 0.9333 - val_loss: 0.7125 - val_acc: 0.7000\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.3315 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7000\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3102 - acc: 0.9500 - val_loss: 0.6933 - val_acc: 0.7000\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.3420 - acc: 0.9667 - val_loss: 0.6860 - val_acc: 0.6000\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2977 - acc: 0.9500 - val_loss: 0.6776 - val_acc: 0.6500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.3423 - acc: 0.9500 - val_loss: 0.6684 - val_acc: 0.6500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.3103 - acc: 0.9667 - val_loss: 0.6596 - val_acc: 0.6500\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.3032 - acc: 0.9500 - val_loss: 0.6535 - val_acc: 0.6500\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2824 - acc: 0.9667 - val_loss: 0.6501 - val_acc: 0.6000\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2761 - acc: 0.9833 - val_loss: 0.6499 - val_acc: 0.6000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2796 - acc: 0.9500 - val_loss: 0.6492 - val_acc: 0.6000\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3320 - acc: 0.9000 - val_loss: 0.6506 - val_acc: 0.6000\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2460 - acc: 0.9667 - val_loss: 0.6509 - val_acc: 0.6000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2719 - acc: 0.9667 - val_loss: 0.6477 - val_acc: 0.6000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2866 - acc: 0.9500 - val_loss: 0.6399 - val_acc: 0.6000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.2833 - acc: 0.9333 - val_loss: 0.6340 - val_acc: 0.6000\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2562 - acc: 0.9500 - val_loss: 0.6224 - val_acc: 0.6500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2609 - acc: 0.9833 - val_loss: 0.6123 - val_acc: 0.6500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2445 - acc: 0.9667 - val_loss: 0.6040 - val_acc: 0.6500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2535 - acc: 0.9333 - val_loss: 0.5957 - val_acc: 0.6500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2479 - acc: 0.9500 - val_loss: 0.5829 - val_acc: 0.6500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2509 - acc: 0.9500 - val_loss: 0.5728 - val_acc: 0.6500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2312 - acc: 0.9667 - val_loss: 0.5672 - val_acc: 0.6500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2535 - acc: 0.9500 - val_loss: 0.5600 - val_acc: 0.6500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2371 - acc: 0.9833 - val_loss: 0.5514 - val_acc: 0.6500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2437 - acc: 0.9667 - val_loss: 0.5360 - val_acc: 0.6500\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2186 - acc: 0.9833 - val_loss: 0.5152 - val_acc: 0.6500\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2403 - acc: 0.9333 - val_loss: 0.4972 - val_acc: 0.7000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.2369 - acc: 0.9167 - val_loss: 0.4874 - val_acc: 0.8000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2483 - acc: 0.9167 - val_loss: 0.4779 - val_acc: 0.8000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2058 - acc: 0.9833 - val_loss: 0.4632 - val_acc: 0.8000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2118 - acc: 0.9500 - val_loss: 0.4556 - val_acc: 0.8500\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2205 - acc: 0.9667 - val_loss: 0.4488 - val_acc: 0.8500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2259 - acc: 0.9833 - val_loss: 0.4403 - val_acc: 0.8500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2263 - acc: 0.9500 - val_loss: 0.4364 - val_acc: 0.8500\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1990 - acc: 0.9500 - val_loss: 0.4298 - val_acc: 0.8500\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.2350 - acc: 0.9333 - val_loss: 0.4234 - val_acc: 0.8500\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2347 - acc: 0.9167 - val_loss: 0.4176 - val_acc: 0.8500\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2035 - acc: 0.9833 - val_loss: 0.4117 - val_acc: 0.8500\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 816us/sample - loss: 0.2161 - acc: 0.9500 - val_loss: 0.4072 - val_acc: 0.8500\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.2146 - acc: 0.9667 - val_loss: 0.4031 - val_acc: 0.8500\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2379 - acc: 0.9333 - val_loss: 0.3984 - val_acc: 0.8500\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1992 - acc: 0.9500 - val_loss: 0.3956 - val_acc: 0.8500\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2105 - acc: 0.9500 - val_loss: 0.3945 - val_acc: 0.8500\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1700 - acc: 0.9500 - val_loss: 0.3919 - val_acc: 0.8500\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1992 - acc: 0.9500 - val_loss: 0.3895 - val_acc: 0.9000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.2351 - acc: 0.9000 - val_loss: 0.3793 - val_acc: 0.9000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2316 - acc: 0.9500 - val_loss: 0.3706 - val_acc: 0.9000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1881 - acc: 0.9667 - val_loss: 0.3651 - val_acc: 0.9000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2083 - acc: 0.9500 - val_loss: 0.3640 - val_acc: 0.9000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2184 - acc: 0.9500 - val_loss: 0.3616 - val_acc: 0.9000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2153 - acc: 0.9500 - val_loss: 0.3562 - val_acc: 0.9000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1701 - acc: 1.0000 - val_loss: 0.3491 - val_acc: 0.9000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1682 - acc: 0.9833 - val_loss: 0.3380 - val_acc: 0.9000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1970 - acc: 0.9500 - val_loss: 0.3276 - val_acc: 0.9000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1659 - acc: 0.9667 - val_loss: 0.3120 - val_acc: 0.9000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.1852 - acc: 0.9667 - val_loss: 0.2985 - val_acc: 0.9000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1372 - acc: 0.9833 - val_loss: 0.2868 - val_acc: 0.9000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1692 - acc: 0.9833 - val_loss: 0.2758 - val_acc: 0.9000\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1783 - acc: 0.9333 - val_loss: 0.2669 - val_acc: 0.9000\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1542 - acc: 0.9833 - val_loss: 0.2612 - val_acc: 0.9000\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1889 - acc: 0.9833 - val_loss: 0.2571 - val_acc: 0.9000\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1809 - acc: 0.9667 - val_loss: 0.2531 - val_acc: 0.9000\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.1585 - acc: 0.9833 - val_loss: 0.2474 - val_acc: 0.9000\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1616 - acc: 0.9667 - val_loss: 0.2414 - val_acc: 0.9000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1852 - acc: 1.0000 - val_loss: 0.2359 - val_acc: 0.9000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.2017 - acc: 0.9333 - val_loss: 0.2322 - val_acc: 0.9000\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1676 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9000\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1293 - acc: 1.0000 - val_loss: 0.2374 - val_acc: 0.9000\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1776 - acc: 0.9833 - val_loss: 0.2417 - val_acc: 0.9000\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1624 - acc: 0.9833 - val_loss: 0.2435 - val_acc: 0.9000\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1665 - acc: 0.9833 - val_loss: 0.2416 - val_acc: 0.9000\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1570 - acc: 0.9667 - val_loss: 0.2396 - val_acc: 0.9000\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1580 - acc: 0.9833 - val_loss: 0.2377 - val_acc: 0.9000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.2159 - acc: 0.9333 - val_loss: 0.2348 - val_acc: 0.9000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1207 - acc: 0.9833 - val_loss: 0.2271 - val_acc: 0.9000\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1672 - acc: 0.9667 - val_loss: 0.2165 - val_acc: 0.9000\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1454 - acc: 0.9667 - val_loss: 0.2051 - val_acc: 0.9000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1702 - acc: 0.9667 - val_loss: 0.1961 - val_acc: 0.9000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1548 - acc: 0.9833 - val_loss: 0.1898 - val_acc: 0.9000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1353 - acc: 0.9833 - val_loss: 0.1850 - val_acc: 0.9500\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1700 - acc: 0.9833 - val_loss: 0.1823 - val_acc: 0.9500\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1671 - acc: 0.9667 - val_loss: 0.1792 - val_acc: 0.9500\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1398 - acc: 1.0000 - val_loss: 0.1752 - val_acc: 0.9500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1764 - acc: 0.9667 - val_loss: 0.1719 - val_acc: 0.9500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1622 - acc: 0.9833 - val_loss: 0.1714 - val_acc: 0.9500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1402 - acc: 0.9833 - val_loss: 0.1712 - val_acc: 0.9500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1831 - acc: 0.9500 - val_loss: 0.1714 - val_acc: 0.9500\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1521 - acc: 0.9500 - val_loss: 0.1706 - val_acc: 0.9500\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1265 - acc: 0.9833 - val_loss: 0.1699 - val_acc: 0.9500\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1778 - acc: 0.9500 - val_loss: 0.1694 - val_acc: 0.9500\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1448 - acc: 0.9667 - val_loss: 0.1684 - val_acc: 0.9500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1284 - acc: 0.9667 - val_loss: 0.1671 - val_acc: 0.9500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1566 - acc: 0.9833 - val_loss: 0.1663 - val_acc: 0.9500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1489 - acc: 0.9833 - val_loss: 0.1640 - val_acc: 0.9500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1651 - acc: 0.9833 - val_loss: 0.1629 - val_acc: 0.9500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1333 - acc: 1.0000 - val_loss: 0.1620 - val_acc: 0.9500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1434 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1252 - acc: 0.9667 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1211 - acc: 0.9833 - val_loss: 0.1584 - val_acc: 0.9500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1294 - acc: 1.0000 - val_loss: 0.1585 - val_acc: 0.9500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1201 - acc: 0.9833 - val_loss: 0.1586 - val_acc: 0.9500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1918 - acc: 0.9333 - val_loss: 0.1614 - val_acc: 0.9000\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1206 - acc: 0.9833 - val_loss: 0.1645 - val_acc: 0.9000\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1487 - acc: 0.9667 - val_loss: 0.1673 - val_acc: 0.9000\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1535 - acc: 0.9667 - val_loss: 0.1702 - val_acc: 0.9000\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1608 - acc: 0.9500 - val_loss: 0.1733 - val_acc: 0.9000\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1069 - acc: 0.9833 - val_loss: 0.1767 - val_acc: 0.9000\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1152 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9000\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1159 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1095 - acc: 1.0000 - val_loss: 0.1758 - val_acc: 0.9000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1170 - acc: 0.9833 - val_loss: 0.1718 - val_acc: 0.9000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1412 - acc: 0.9833 - val_loss: 0.1676 - val_acc: 0.9000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1215 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.9000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1369 - acc: 0.9833 - val_loss: 0.1578 - val_acc: 0.9500\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1079 - acc: 0.9833 - val_loss: 0.1554 - val_acc: 0.9500\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1156 - acc: 0.9833 - val_loss: 0.1538 - val_acc: 0.9500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1629 - acc: 0.9500 - val_loss: 0.1516 - val_acc: 0.9500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1162 - acc: 0.9833 - val_loss: 0.1492 - val_acc: 0.9500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1214 - acc: 1.0000 - val_loss: 0.1468 - val_acc: 0.9500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1152 - acc: 0.9833 - val_loss: 0.1450 - val_acc: 0.9500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1482 - acc: 0.9667 - val_loss: 0.1447 - val_acc: 0.9500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1488 - acc: 0.9667 - val_loss: 0.1468 - val_acc: 0.9500\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1423 - acc: 0.9833 - val_loss: 0.1490 - val_acc: 0.9500\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1086 - acc: 1.0000 - val_loss: 0.1511 - val_acc: 0.9500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1151 - acc: 1.0000 - val_loss: 0.1511 - val_acc: 0.9500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1194 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.9500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1160 - acc: 1.0000 - val_loss: 0.1472 - val_acc: 0.9500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.2062 - acc: 0.9667 - val_loss: 0.1447 - val_acc: 0.9500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1042 - acc: 0.9833 - val_loss: 0.1437 - val_acc: 0.9500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1090 - acc: 0.9833 - val_loss: 0.1417 - val_acc: 0.9500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1408 - acc: 0.9667 - val_loss: 0.1406 - val_acc: 0.9500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1035 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.9500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1817 - acc: 0.9500 - val_loss: 0.1390 - val_acc: 0.9500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 729us/sample - loss: 0.1109 - acc: 0.9667 - val_loss: 0.1389 - val_acc: 0.9500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 765us/sample - loss: 0.1302 - acc: 1.0000 - val_loss: 0.1384 - val_acc: 0.9500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1989 - acc: 0.9667 - val_loss: 0.1366 - val_acc: 0.9500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1320 - acc: 0.9667 - val_loss: 0.1353 - val_acc: 0.9500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1355 - acc: 0.9833 - val_loss: 0.1337 - val_acc: 0.9500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0980 - acc: 1.0000 - val_loss: 0.1330 - val_acc: 0.9500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1173 - acc: 0.9667 - val_loss: 0.1316 - val_acc: 0.9500\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1128 - acc: 0.9667 - val_loss: 0.1303 - val_acc: 0.9500\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1296 - acc: 0.9833 - val_loss: 0.1290 - val_acc: 0.9500\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1050 - acc: 0.9667 - val_loss: 0.1303 - val_acc: 0.9500\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.0960 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 1.0000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1108 - acc: 0.9833 - val_loss: 0.1333 - val_acc: 1.0000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1112 - acc: 1.0000 - val_loss: 0.1324 - val_acc: 1.0000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1019 - acc: 1.0000 - val_loss: 0.1312 - val_acc: 0.9500\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0848 - acc: 1.0000 - val_loss: 0.1297 - val_acc: 0.9500\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1030 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9500\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0965 - acc: 1.0000 - val_loss: 0.1281 - val_acc: 0.9500\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1028 - acc: 0.9833 - val_loss: 0.1263 - val_acc: 0.9500\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1125 - acc: 0.9833 - val_loss: 0.1246 - val_acc: 0.9500\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0953 - acc: 1.0000 - val_loss: 0.1229 - val_acc: 0.9500\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1111 - acc: 0.9833 - val_loss: 0.1218 - val_acc: 0.9500\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1060 - acc: 1.0000 - val_loss: 0.1214 - val_acc: 0.9500\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 0.1217 - val_acc: 0.9500\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1076 - acc: 0.9833 - val_loss: 0.1206 - val_acc: 0.9500\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9500\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0797 - acc: 1.0000 - val_loss: 0.1210 - val_acc: 0.9500\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0999 - acc: 0.9833 - val_loss: 0.1230 - val_acc: 0.9500\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0976 - acc: 0.9833 - val_loss: 0.1229 - val_acc: 0.9500\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9500\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0985 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9500\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0893 - acc: 0.9833 - val_loss: 0.1181 - val_acc: 0.9500\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 0.9500\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0904 - acc: 0.9667 - val_loss: 0.1173 - val_acc: 0.9500\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 707us/sample - loss: 0.1302 - acc: 0.9833 - val_loss: 0.1180 - val_acc: 0.9500\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1103 - acc: 0.9500 - val_loss: 0.1215 - val_acc: 0.9500\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0905 - acc: 1.0000 - val_loss: 0.1220 - val_acc: 1.0000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0977 - acc: 1.0000 - val_loss: 0.1235 - val_acc: 1.0000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1417 - acc: 0.9667 - val_loss: 0.1249 - val_acc: 1.0000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0986 - acc: 0.9833 - val_loss: 0.1222 - val_acc: 0.9500\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0977 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9500\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.0851 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9500\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1314 - acc: 0.9833 - val_loss: 0.1145 - val_acc: 0.9500\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.1104 - acc: 0.9667 - val_loss: 0.1137 - val_acc: 0.9500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0994 - acc: 0.9833 - val_loss: 0.1135 - val_acc: 0.9500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0811 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9500\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0766 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1111 - acc: 0.9833 - val_loss: 0.1107 - val_acc: 0.9500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1009 - acc: 0.9833 - val_loss: 0.1098 - val_acc: 0.9500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0947 - acc: 0.9833 - val_loss: 0.1094 - val_acc: 0.9500\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0904 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9500\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1010 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9500\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.1096 - val_acc: 0.9500\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0862 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0980 - acc: 0.9833 - val_loss: 0.1073 - val_acc: 0.9500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0825 - acc: 0.9833 - val_loss: 0.1069 - val_acc: 0.9500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1070 - acc: 0.9833 - val_loss: 0.1070 - val_acc: 0.9500\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0620 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9500\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0829 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9500\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 707us/sample - loss: 0.0943 - acc: 0.9833 - val_loss: 0.1095 - val_acc: 0.9500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0906 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0857 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 0.9500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1096 - acc: 0.9667 - val_loss: 0.1136 - val_acc: 0.9500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0618 - acc: 1.0000 - val_loss: 0.1176 - val_acc: 0.9500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0854 - acc: 0.9833 - val_loss: 0.1191 - val_acc: 0.9500\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1044 - acc: 0.9833 - val_loss: 0.1183 - val_acc: 0.9500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 0.9500\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0845 - acc: 0.9833 - val_loss: 0.1123 - val_acc: 0.9500\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0960 - acc: 0.9833 - val_loss: 0.1092 - val_acc: 0.9500\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1019 - acc: 0.9833 - val_loss: 0.1066 - val_acc: 0.9500\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1116 - acc: 0.9833 - val_loss: 0.1081 - val_acc: 0.9500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0933 - acc: 0.9833 - val_loss: 0.1114 - val_acc: 0.9500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.1170 - val_acc: 0.9500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 771us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.1205 - val_acc: 0.9500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0856 - acc: 0.9833 - val_loss: 0.1232 - val_acc: 0.9500\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0882 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9500\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.0839 - acc: 0.9833 - val_loss: 0.1258 - val_acc: 0.9500\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1318 - acc: 0.9500 - val_loss: 0.1246 - val_acc: 0.9500\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0852 - acc: 0.9833 - val_loss: 0.1271 - val_acc: 0.9500\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0828 - acc: 0.9833 - val_loss: 0.1318 - val_acc: 0.9500\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.1142 - acc: 0.9833 - val_loss: 0.1322 - val_acc: 0.9500\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.0745 - acc: 0.9833 - val_loss: 0.1360 - val_acc: 0.9500\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0892 - acc: 0.9833 - val_loss: 0.1367 - val_acc: 0.9500\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0988 - acc: 1.0000 - val_loss: 0.1367 - val_acc: 0.9500\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0886 - acc: 0.9833 - val_loss: 0.1368 - val_acc: 0.9500\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1389 - acc: 0.9500 - val_loss: 0.1357 - val_acc: 0.9500\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0784 - acc: 0.9833 - val_loss: 0.1345 - val_acc: 0.9500\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.0976 - acc: 1.0000 - val_loss: 0.1365 - val_acc: 0.9500\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.0784 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 0.9500\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.0758 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.9500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0749 - acc: 1.0000 - val_loss: 0.1379 - val_acc: 0.9500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1020 - acc: 0.9833 - val_loss: 0.1353 - val_acc: 0.9500\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.0800 - acc: 1.0000 - val_loss: 0.1328 - val_acc: 0.9500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0592 - acc: 1.0000 - val_loss: 0.1302 - val_acc: 0.9500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1037 - acc: 0.9833 - val_loss: 0.1267 - val_acc: 0.9500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0874 - acc: 0.9833 - val_loss: 0.1193 - val_acc: 0.9500\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0615 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9500\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0713 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9500\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0784 - acc: 0.9833 - val_loss: 0.1050 - val_acc: 0.9500\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9500\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1018 - acc: 0.9833 - val_loss: 0.1009 - val_acc: 0.9500\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0923 - acc: 0.9833 - val_loss: 0.1011 - val_acc: 0.9500\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0710 - acc: 1.0000 - val_loss: 0.1024 - val_acc: 0.9500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1028 - acc: 0.9833 - val_loss: 0.1028 - val_acc: 0.9500\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0775 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9500\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0971 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.0941 - acc: 0.9667 - val_loss: 0.1097 - val_acc: 0.9500\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.0751 - acc: 0.9833 - val_loss: 0.1110 - val_acc: 0.9500\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0825 - acc: 1.0000 - val_loss: 0.1112 - val_acc: 0.9500\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0651 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9500\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0830 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9500\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9500\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.1158 - val_acc: 0.9500\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0679 - acc: 0.9833 - val_loss: 0.1171 - val_acc: 0.9500\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0901 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9500\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.1134 - val_acc: 0.9500\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0697 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 0.9500\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1215 - acc: 0.9500 - val_loss: 0.1091 - val_acc: 0.9500\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9500\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0657 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 0.9500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0732 - acc: 0.9833 - val_loss: 0.1086 - val_acc: 0.9500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0880 - acc: 0.9833 - val_loss: 0.1030 - val_acc: 0.9500\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0781 - acc: 0.9833 - val_loss: 0.0994 - val_acc: 0.9500\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0915 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9500\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0851 - acc: 0.9833 - val_loss: 0.0952 - val_acc: 0.9500\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9500\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0844 - acc: 0.9833 - val_loss: 0.0940 - val_acc: 0.9500\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0728 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 0.9500\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.0906 - val_acc: 0.9500\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0550 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9500\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.0883 - val_acc: 0.9500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 728us/sample - loss: 0.0751 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9500\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0838 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9500\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0814 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9500\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0660 - acc: 0.9833 - val_loss: 0.0778 - val_acc: 0.9500\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0607 - acc: 0.9833 - val_loss: 0.0789 - val_acc: 0.9500\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0742 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 1.0000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0715 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 1.0000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0851 - acc: 0.9833 - val_loss: 0.0837 - val_acc: 1.0000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 801us/sample - loss: 0.0651 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 1.0000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0543 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9500\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 0.9500\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9500\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0815 - acc: 0.9833 - val_loss: 0.0870 - val_acc: 0.9500\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0735 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9500\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1062 - acc: 0.9833 - val_loss: 0.0879 - val_acc: 0.9500\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9500\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.0730 - acc: 0.9833 - val_loss: 0.0908 - val_acc: 0.9500\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0484 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 0.9500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0652 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9500\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0754 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 0.9500\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 726us/sample - loss: 0.0961 - acc: 0.9833 - val_loss: 0.0881 - val_acc: 0.9500\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9500\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0928 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9500\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0734 - acc: 0.9833 - val_loss: 0.0857 - val_acc: 0.9500\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9500\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9500\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0811 - acc: 0.9833 - val_loss: 0.0880 - val_acc: 0.9500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 0.9500\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0769 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9500\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0570 - acc: 0.9833 - val_loss: 0.0997 - val_acc: 0.9500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.0756 - acc: 0.9833 - val_loss: 0.1025 - val_acc: 0.9500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0626 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9500\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 0.9500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0726 - acc: 0.9833 - val_loss: 0.1136 - val_acc: 0.9500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0673 - acc: 1.0000 - val_loss: 0.1122 - val_acc: 0.9500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0587 - acc: 1.0000 - val_loss: 0.1130 - val_acc: 0.9500\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1137 - val_acc: 0.9500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0772 - acc: 0.9833 - val_loss: 0.1161 - val_acc: 0.9500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0662 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 0.9500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0594 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0665 - acc: 0.9833 - val_loss: 0.1260 - val_acc: 0.9500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0772 - acc: 0.9833 - val_loss: 0.1259 - val_acc: 0.9500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0625 - acc: 0.9833 - val_loss: 0.1201 - val_acc: 0.9500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0664 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0486 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 0.1048 - val_acc: 0.9500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9500\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0823 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 0.9500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 734us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.0947 - val_acc: 0.9500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0647 - acc: 0.9833 - val_loss: 0.0923 - val_acc: 0.9500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9500\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0599 - acc: 1.0000 - val_loss: 0.0899 - val_acc: 0.9500\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1077 - acc: 0.9667 - val_loss: 0.0876 - val_acc: 0.9500\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 0.9500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0801 - acc: 0.9667 - val_loss: 0.0873 - val_acc: 0.9500\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9500\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9500\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0554 - acc: 0.9833 - val_loss: 0.0855 - val_acc: 0.9500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 0.9500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0775 - acc: 0.9833 - val_loss: 0.0880 - val_acc: 0.9500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.0586 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 0.9500\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0629 - acc: 0.9833 - val_loss: 0.0904 - val_acc: 0.9500\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0743 - acc: 0.9833 - val_loss: 0.0908 - val_acc: 0.9500\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 0.9500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0765 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9500\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.0509 - acc: 0.9833 - val_loss: 0.0868 - val_acc: 0.9500\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9500\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0633 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9500\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0548 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 0.9500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0643 - acc: 0.9833 - val_loss: 0.0779 - val_acc: 0.9500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0761 - acc: 0.9833 - val_loss: 0.0773 - val_acc: 0.9500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.0763 - val_acc: 0.9500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0473 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 0.9500\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9500\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 0.9500\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.0797 - val_acc: 0.9500\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9500\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 0.9500\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9500\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9500\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 0.9500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0620 - acc: 0.9833 - val_loss: 0.0794 - val_acc: 0.9500\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0704 - acc: 0.9833 - val_loss: 0.0793 - val_acc: 0.9500\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1128 - acc: 0.9667 - val_loss: 0.0814 - val_acc: 0.9500\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9500\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9500\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 0.9500\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0625 - acc: 0.9833 - val_loss: 0.0766 - val_acc: 0.9500\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0648 - acc: 0.9833 - val_loss: 0.0770 - val_acc: 0.9500\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9500\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.0614 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9500\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9500\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9500\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9500\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9500\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 0.9500\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0733 - acc: 0.9833 - val_loss: 0.0794 - val_acc: 0.9500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0529 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0431 - acc: 1.0000 - val_loss: 0.0738 - val_acc: 0.9500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9500\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0920 - acc: 1.0000 - val_loss: 0.0711 - val_acc: 0.9500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0597 - acc: 0.9833 - val_loss: 0.0726 - val_acc: 0.9500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0496 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0729 - acc: 0.9833 - val_loss: 0.0708 - val_acc: 0.9500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0630 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.0568 - acc: 0.9833 - val_loss: 0.0699 - val_acc: 0.9500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1032 - acc: 0.9500 - val_loss: 0.0716 - val_acc: 0.9500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0597 - acc: 0.9833 - val_loss: 0.0711 - val_acc: 0.9500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 1.0000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0653 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0551 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 1.0000\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0370 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 1.0000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 1.0000\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 1.0000\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 1.0000\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0548 - acc: 0.9833 - val_loss: 0.0702 - val_acc: 1.0000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 1.0000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 731us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 1.0000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0770 - acc: 0.9667 - val_loss: 0.0703 - val_acc: 1.0000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 1.0000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 1.0000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0574 - acc: 0.9833 - val_loss: 0.0674 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLx3iNawAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.7722 - acc: 0.7500\n",
            "test loss, test acc: [0.7722064129018691, 0.75]\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P07E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.4193 - acc: 0.3333 - val_loss: 1.3809 - val_acc: 0.2000\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 1.2385 - acc: 0.5000 - val_loss: 1.3691 - val_acc: 0.4500\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 1.0811 - acc: 0.5667 - val_loss: 1.3571 - val_acc: 0.4500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.9925 - acc: 0.6000 - val_loss: 1.3454 - val_acc: 0.4000\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.9188 - acc: 0.6167 - val_loss: 1.3332 - val_acc: 0.3500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.8662 - acc: 0.6333 - val_loss: 1.3209 - val_acc: 0.3000\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.8285 - acc: 0.6333 - val_loss: 1.3086 - val_acc: 0.2500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.8036 - acc: 0.6167 - val_loss: 1.2972 - val_acc: 0.2000\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.7694 - acc: 0.6167 - val_loss: 1.2856 - val_acc: 0.2000\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.7624 - acc: 0.6667 - val_loss: 1.2747 - val_acc: 0.2000\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.7349 - acc: 0.6500 - val_loss: 1.2644 - val_acc: 0.2000\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.7388 - acc: 0.6167 - val_loss: 1.2545 - val_acc: 0.1500\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.7103 - acc: 0.7000 - val_loss: 1.2454 - val_acc: 0.1500\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.6964 - acc: 0.6833 - val_loss: 1.2364 - val_acc: 0.2000\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.6897 - acc: 0.7000 - val_loss: 1.2272 - val_acc: 0.2000\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.6854 - acc: 0.7500 - val_loss: 1.2186 - val_acc: 0.2000\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.6642 - acc: 0.7833 - val_loss: 1.2106 - val_acc: 0.2000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.6824 - acc: 0.7167 - val_loss: 1.2025 - val_acc: 0.2000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.6641 - acc: 0.7333 - val_loss: 1.1938 - val_acc: 0.2000\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.6307 - acc: 0.8167 - val_loss: 1.1860 - val_acc: 0.2000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.6309 - acc: 0.8167 - val_loss: 1.1790 - val_acc: 0.2000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.6402 - acc: 0.7667 - val_loss: 1.1730 - val_acc: 0.2000\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.6248 - acc: 0.7833 - val_loss: 1.1666 - val_acc: 0.2000\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.6136 - acc: 0.7833 - val_loss: 1.1595 - val_acc: 0.2000\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.6243 - acc: 0.7833 - val_loss: 1.1533 - val_acc: 0.2000\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.5959 - acc: 0.8333 - val_loss: 1.1478 - val_acc: 0.2000\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.6137 - acc: 0.8000 - val_loss: 1.1408 - val_acc: 0.2000\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.6057 - acc: 0.8333 - val_loss: 1.1341 - val_acc: 0.2500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.5991 - acc: 0.8000 - val_loss: 1.1279 - val_acc: 0.2500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.5783 - acc: 0.8500 - val_loss: 1.1213 - val_acc: 0.2500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.5917 - acc: 0.8500 - val_loss: 1.1149 - val_acc: 0.3000\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.5727 - acc: 0.8833 - val_loss: 1.1091 - val_acc: 0.3000\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.5667 - acc: 0.9000 - val_loss: 1.1037 - val_acc: 0.3500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.5635 - acc: 0.8833 - val_loss: 1.0995 - val_acc: 0.3500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.5695 - acc: 0.8167 - val_loss: 1.0956 - val_acc: 0.3500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.5600 - acc: 0.8833 - val_loss: 1.0904 - val_acc: 0.3500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.5653 - acc: 0.8667 - val_loss: 1.0860 - val_acc: 0.3000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.5660 - acc: 0.8500 - val_loss: 1.0852 - val_acc: 0.3000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.5339 - acc: 0.8333 - val_loss: 1.0811 - val_acc: 0.3000\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.5423 - acc: 0.8667 - val_loss: 1.0797 - val_acc: 0.3000\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.5576 - acc: 0.8333 - val_loss: 1.0774 - val_acc: 0.3000\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.5461 - acc: 0.8167 - val_loss: 1.0722 - val_acc: 0.3000\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.5376 - acc: 0.8500 - val_loss: 1.0673 - val_acc: 0.3000\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.5222 - acc: 0.8833 - val_loss: 1.0623 - val_acc: 0.3000\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.5347 - acc: 0.8667 - val_loss: 1.0557 - val_acc: 0.3500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.5319 - acc: 0.8833 - val_loss: 1.0535 - val_acc: 0.3500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.5295 - acc: 0.9000 - val_loss: 1.0529 - val_acc: 0.3500\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.5014 - acc: 0.9167 - val_loss: 1.0546 - val_acc: 0.3500\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.5171 - acc: 0.8833 - val_loss: 1.0561 - val_acc: 0.3000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 754us/sample - loss: 0.4799 - acc: 0.9167 - val_loss: 1.0562 - val_acc: 0.3000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.5084 - acc: 0.8500 - val_loss: 1.0569 - val_acc: 0.3000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.4979 - acc: 0.8833 - val_loss: 1.0549 - val_acc: 0.3000\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.4796 - acc: 0.9167 - val_loss: 1.0553 - val_acc: 0.3000\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.5042 - acc: 0.8667 - val_loss: 1.0569 - val_acc: 0.3000\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.4914 - acc: 0.8833 - val_loss: 1.0565 - val_acc: 0.3000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.4728 - acc: 0.8833 - val_loss: 1.0540 - val_acc: 0.3000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.4872 - acc: 0.8833 - val_loss: 1.0506 - val_acc: 0.3000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.4767 - acc: 0.8667 - val_loss: 1.0469 - val_acc: 0.3000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.4821 - acc: 0.9000 - val_loss: 1.0430 - val_acc: 0.3000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.4962 - acc: 0.8500 - val_loss: 1.0398 - val_acc: 0.3000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.4738 - acc: 0.8833 - val_loss: 1.0404 - val_acc: 0.3000\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 717us/sample - loss: 0.4914 - acc: 0.8833 - val_loss: 1.0415 - val_acc: 0.3000\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.4679 - acc: 0.9000 - val_loss: 1.0413 - val_acc: 0.2500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4458 - acc: 0.9333 - val_loss: 1.0419 - val_acc: 0.2500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.4699 - acc: 0.9000 - val_loss: 1.0451 - val_acc: 0.2500\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.4571 - acc: 0.9000 - val_loss: 1.0450 - val_acc: 0.2500\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.4389 - acc: 0.9333 - val_loss: 1.0486 - val_acc: 0.2000\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.4336 - acc: 0.9333 - val_loss: 1.0527 - val_acc: 0.2000\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.4502 - acc: 0.9167 - val_loss: 1.0578 - val_acc: 0.2000\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.4352 - acc: 0.9333 - val_loss: 1.0551 - val_acc: 0.2000\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.4467 - acc: 0.8833 - val_loss: 1.0501 - val_acc: 0.2000\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.4483 - acc: 0.9333 - val_loss: 1.0458 - val_acc: 0.2500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.4335 - acc: 0.9333 - val_loss: 1.0456 - val_acc: 0.2500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.4402 - acc: 0.9167 - val_loss: 1.0396 - val_acc: 0.2500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.4209 - acc: 0.9500 - val_loss: 1.0355 - val_acc: 0.2500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.3982 - acc: 0.9500 - val_loss: 1.0387 - val_acc: 0.2500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.4262 - acc: 0.9167 - val_loss: 1.0423 - val_acc: 0.2500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.4084 - acc: 0.9667 - val_loss: 1.0473 - val_acc: 0.2000\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.4095 - acc: 0.9500 - val_loss: 1.0473 - val_acc: 0.2000\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.4183 - acc: 0.9333 - val_loss: 1.0527 - val_acc: 0.1500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.4059 - acc: 0.9333 - val_loss: 1.0536 - val_acc: 0.2000\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4070 - acc: 0.9167 - val_loss: 1.0477 - val_acc: 0.2000\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.4195 - acc: 0.9000 - val_loss: 1.0406 - val_acc: 0.2500\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3872 - acc: 0.9500 - val_loss: 1.0377 - val_acc: 0.2500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3975 - acc: 0.9000 - val_loss: 1.0347 - val_acc: 0.2500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.3827 - acc: 0.9333 - val_loss: 1.0341 - val_acc: 0.3000\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.3755 - acc: 0.9500 - val_loss: 1.0380 - val_acc: 0.2500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3658 - acc: 0.9833 - val_loss: 1.0413 - val_acc: 0.2500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.3978 - acc: 0.9333 - val_loss: 1.0410 - val_acc: 0.2500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.3870 - acc: 0.9500 - val_loss: 1.0426 - val_acc: 0.2500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3866 - acc: 0.9833 - val_loss: 1.0461 - val_acc: 0.2500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.4081 - acc: 0.9000 - val_loss: 1.0447 - val_acc: 0.3000\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.3588 - acc: 0.9833 - val_loss: 1.0487 - val_acc: 0.2500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3728 - acc: 0.9333 - val_loss: 1.0531 - val_acc: 0.2500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3802 - acc: 0.9667 - val_loss: 1.0517 - val_acc: 0.2500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.3740 - acc: 0.9500 - val_loss: 1.0448 - val_acc: 0.3000\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3974 - acc: 0.8833 - val_loss: 1.0406 - val_acc: 0.3000\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3682 - acc: 0.9833 - val_loss: 1.0387 - val_acc: 0.3500\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3604 - acc: 0.9667 - val_loss: 1.0341 - val_acc: 0.3500\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3767 - acc: 0.9333 - val_loss: 1.0336 - val_acc: 0.3500\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.3619 - acc: 0.9500 - val_loss: 1.0355 - val_acc: 0.3000\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3987 - acc: 0.8833 - val_loss: 1.0319 - val_acc: 0.3000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3724 - acc: 0.9667 - val_loss: 1.0375 - val_acc: 0.3000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3644 - acc: 0.9667 - val_loss: 1.0368 - val_acc: 0.3000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.3234 - acc: 0.9667 - val_loss: 1.0364 - val_acc: 0.2500\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3557 - acc: 0.9333 - val_loss: 1.0396 - val_acc: 0.2500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.3576 - acc: 0.9833 - val_loss: 1.0443 - val_acc: 0.2500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.3527 - acc: 0.9667 - val_loss: 1.0480 - val_acc: 0.2500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.3495 - acc: 0.9667 - val_loss: 1.0538 - val_acc: 0.2500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.3236 - acc: 1.0000 - val_loss: 1.0582 - val_acc: 0.2500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.3352 - acc: 0.9667 - val_loss: 1.0640 - val_acc: 0.2500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.3395 - acc: 0.9667 - val_loss: 1.0658 - val_acc: 0.2000\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.3417 - acc: 0.9500 - val_loss: 1.0726 - val_acc: 0.2000\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.3287 - acc: 0.9667 - val_loss: 1.0685 - val_acc: 0.2500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3294 - acc: 0.9833 - val_loss: 1.0672 - val_acc: 0.2500\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.3325 - acc: 1.0000 - val_loss: 1.0701 - val_acc: 0.2500\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3178 - acc: 1.0000 - val_loss: 1.0727 - val_acc: 0.3000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.3307 - acc: 0.9667 - val_loss: 1.0738 - val_acc: 0.3000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.3200 - acc: 0.9167 - val_loss: 1.0657 - val_acc: 0.3000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.3213 - acc: 0.9833 - val_loss: 1.0600 - val_acc: 0.3000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2848 - acc: 0.9667 - val_loss: 1.0544 - val_acc: 0.3500\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 743us/sample - loss: 0.3190 - acc: 0.9833 - val_loss: 1.0549 - val_acc: 0.3500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3420 - acc: 0.9667 - val_loss: 1.0526 - val_acc: 0.3500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3212 - acc: 0.9833 - val_loss: 1.0563 - val_acc: 0.3500\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3098 - acc: 0.9833 - val_loss: 1.0527 - val_acc: 0.3500\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.3111 - acc: 1.0000 - val_loss: 1.0654 - val_acc: 0.3500\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.3362 - acc: 0.9833 - val_loss: 1.0840 - val_acc: 0.3000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3288 - acc: 0.9500 - val_loss: 1.1062 - val_acc: 0.3000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.3193 - acc: 0.9500 - val_loss: 1.1231 - val_acc: 0.3000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3047 - acc: 0.9667 - val_loss: 1.1302 - val_acc: 0.2500\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.3045 - acc: 0.9500 - val_loss: 1.1364 - val_acc: 0.2500\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3150 - acc: 0.9833 - val_loss: 1.1424 - val_acc: 0.2500\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.3058 - acc: 0.9667 - val_loss: 1.1426 - val_acc: 0.2500\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.3139 - acc: 0.9000 - val_loss: 1.1284 - val_acc: 0.2500\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.3153 - acc: 0.9500 - val_loss: 1.1105 - val_acc: 0.3000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2876 - acc: 0.9500 - val_loss: 1.0933 - val_acc: 0.3000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2939 - acc: 0.9667 - val_loss: 1.0787 - val_acc: 0.3000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2836 - acc: 0.9833 - val_loss: 1.0628 - val_acc: 0.3500\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3269 - acc: 0.9167 - val_loss: 1.0634 - val_acc: 0.3500\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2666 - acc: 1.0000 - val_loss: 1.0794 - val_acc: 0.3000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2724 - acc: 1.0000 - val_loss: 1.1019 - val_acc: 0.3000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2802 - acc: 0.9667 - val_loss: 1.1227 - val_acc: 0.3000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.2736 - acc: 0.9833 - val_loss: 1.1374 - val_acc: 0.2500\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 707us/sample - loss: 0.2846 - acc: 0.9833 - val_loss: 1.1474 - val_acc: 0.2500\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2588 - acc: 0.9833 - val_loss: 1.1471 - val_acc: 0.3000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3002 - acc: 0.9167 - val_loss: 1.1439 - val_acc: 0.3000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2858 - acc: 0.9500 - val_loss: 1.1371 - val_acc: 0.3000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2696 - acc: 0.9500 - val_loss: 1.1279 - val_acc: 0.3000\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.3095 - acc: 0.9333 - val_loss: 1.1184 - val_acc: 0.3000\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2744 - acc: 0.9833 - val_loss: 1.1049 - val_acc: 0.4000\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2701 - acc: 0.9833 - val_loss: 1.1028 - val_acc: 0.4500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.3042 - acc: 0.9333 - val_loss: 1.1055 - val_acc: 0.4500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.2592 - acc: 0.9833 - val_loss: 1.1042 - val_acc: 0.4500\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.2617 - acc: 1.0000 - val_loss: 1.1168 - val_acc: 0.4000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2597 - acc: 1.0000 - val_loss: 1.1259 - val_acc: 0.4000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.2776 - acc: 0.9333 - val_loss: 1.1344 - val_acc: 0.3500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2500 - acc: 0.9833 - val_loss: 1.1453 - val_acc: 0.3500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2742 - acc: 0.9500 - val_loss: 1.1410 - val_acc: 0.3500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.2672 - acc: 0.9667 - val_loss: 1.1241 - val_acc: 0.4000\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2574 - acc: 0.9833 - val_loss: 1.1093 - val_acc: 0.4000\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2665 - acc: 0.9667 - val_loss: 1.0959 - val_acc: 0.4000\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2652 - acc: 0.9833 - val_loss: 1.0976 - val_acc: 0.4500\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2267 - acc: 1.0000 - val_loss: 1.0857 - val_acc: 0.4500\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2384 - acc: 0.9833 - val_loss: 1.0638 - val_acc: 0.4500\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2731 - acc: 0.9500 - val_loss: 1.0507 - val_acc: 0.4500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.2467 - acc: 0.9667 - val_loss: 1.0243 - val_acc: 0.4500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2751 - acc: 0.9500 - val_loss: 1.0184 - val_acc: 0.4500\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2470 - acc: 0.9667 - val_loss: 1.0099 - val_acc: 0.4500\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2855 - acc: 0.9167 - val_loss: 1.0185 - val_acc: 0.4500\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2311 - acc: 1.0000 - val_loss: 1.0202 - val_acc: 0.4500\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.2588 - acc: 0.9667 - val_loss: 1.0165 - val_acc: 0.4500\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2454 - acc: 0.9667 - val_loss: 1.0130 - val_acc: 0.4500\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2364 - acc: 0.9833 - val_loss: 1.0113 - val_acc: 0.4500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2236 - acc: 0.9500 - val_loss: 1.0083 - val_acc: 0.4500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2142 - acc: 0.9667 - val_loss: 0.9936 - val_acc: 0.4500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2259 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.4500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2298 - acc: 0.9833 - val_loss: 0.9906 - val_acc: 0.4500\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2278 - acc: 0.9833 - val_loss: 0.9894 - val_acc: 0.4500\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2324 - acc: 0.9667 - val_loss: 0.9974 - val_acc: 0.4500\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2713 - acc: 0.9500 - val_loss: 0.9939 - val_acc: 0.4500\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2377 - acc: 0.9833 - val_loss: 0.9865 - val_acc: 0.4500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2179 - acc: 0.9833 - val_loss: 0.9895 - val_acc: 0.4500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2498 - acc: 0.9833 - val_loss: 0.9827 - val_acc: 0.4500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2392 - acc: 0.9667 - val_loss: 0.9892 - val_acc: 0.4500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2593 - acc: 0.9667 - val_loss: 1.0014 - val_acc: 0.4500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2168 - acc: 1.0000 - val_loss: 1.0010 - val_acc: 0.5000\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2608 - acc: 0.9833 - val_loss: 1.0113 - val_acc: 0.5000\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.2170 - acc: 0.9833 - val_loss: 0.9943 - val_acc: 0.4500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2117 - acc: 0.9833 - val_loss: 0.9864 - val_acc: 0.4500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2333 - acc: 0.9667 - val_loss: 0.9797 - val_acc: 0.4500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.2146 - acc: 0.9667 - val_loss: 0.9607 - val_acc: 0.5000\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2362 - acc: 0.9667 - val_loss: 0.9478 - val_acc: 0.4500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2287 - acc: 0.9667 - val_loss: 0.9486 - val_acc: 0.4500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2076 - acc: 0.9833 - val_loss: 0.9414 - val_acc: 0.4500\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2115 - acc: 0.9667 - val_loss: 0.9352 - val_acc: 0.4500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.2263 - acc: 1.0000 - val_loss: 0.9503 - val_acc: 0.4500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2187 - acc: 0.9667 - val_loss: 0.9645 - val_acc: 0.4500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2291 - acc: 0.9667 - val_loss: 0.9823 - val_acc: 0.4500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2273 - acc: 0.9667 - val_loss: 0.9936 - val_acc: 0.5000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 713us/sample - loss: 0.2173 - acc: 0.9833 - val_loss: 0.9910 - val_acc: 0.5000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.2130 - acc: 1.0000 - val_loss: 0.9868 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2227 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2126 - acc: 0.9833 - val_loss: 0.9718 - val_acc: 0.4500\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.2105 - acc: 0.9833 - val_loss: 0.9573 - val_acc: 0.4500\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1902 - acc: 1.0000 - val_loss: 0.9584 - val_acc: 0.4500\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1852 - acc: 0.9667 - val_loss: 0.9558 - val_acc: 0.4500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1916 - acc: 0.9667 - val_loss: 0.9504 - val_acc: 0.4500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2087 - acc: 1.0000 - val_loss: 0.9330 - val_acc: 0.4500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.1971 - acc: 0.9833 - val_loss: 0.9298 - val_acc: 0.4500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1848 - acc: 1.0000 - val_loss: 0.9243 - val_acc: 0.4500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1963 - acc: 0.9833 - val_loss: 0.9392 - val_acc: 0.5000\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2229 - acc: 0.9667 - val_loss: 0.9508 - val_acc: 0.5000\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2257 - acc: 0.9333 - val_loss: 0.9375 - val_acc: 0.5000\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1739 - acc: 1.0000 - val_loss: 0.9327 - val_acc: 0.5500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.1921 - acc: 0.9833 - val_loss: 0.9333 - val_acc: 0.5500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2107 - acc: 0.9500 - val_loss: 0.9228 - val_acc: 0.5500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1981 - acc: 0.9833 - val_loss: 0.9054 - val_acc: 0.5000\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1867 - acc: 0.9833 - val_loss: 0.8966 - val_acc: 0.4500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2030 - acc: 0.9667 - val_loss: 0.8891 - val_acc: 0.4500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1900 - acc: 0.9833 - val_loss: 0.8852 - val_acc: 0.4500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1621 - acc: 0.9833 - val_loss: 0.8791 - val_acc: 0.4500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1851 - acc: 0.9833 - val_loss: 0.8701 - val_acc: 0.4500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1976 - acc: 1.0000 - val_loss: 0.8641 - val_acc: 0.4000\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1830 - acc: 0.9833 - val_loss: 0.8431 - val_acc: 0.4500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1776 - acc: 0.9833 - val_loss: 0.8317 - val_acc: 0.4500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.1977 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.4500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.2042 - acc: 0.9833 - val_loss: 0.8273 - val_acc: 0.4500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1946 - acc: 0.9833 - val_loss: 0.8259 - val_acc: 0.4500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1461 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.4500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1815 - acc: 0.9833 - val_loss: 0.8409 - val_acc: 0.4500\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2215 - acc: 0.9500 - val_loss: 0.8491 - val_acc: 0.4500\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1663 - acc: 0.9667 - val_loss: 0.8437 - val_acc: 0.4500\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1937 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.4500\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1925 - acc: 1.0000 - val_loss: 0.8396 - val_acc: 0.4500\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.1945 - acc: 1.0000 - val_loss: 0.8363 - val_acc: 0.4500\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1682 - acc: 0.9833 - val_loss: 0.8372 - val_acc: 0.4500\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1737 - acc: 1.0000 - val_loss: 0.8370 - val_acc: 0.4500\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1918 - acc: 1.0000 - val_loss: 0.8514 - val_acc: 0.4500\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1671 - acc: 1.0000 - val_loss: 0.8729 - val_acc: 0.5000\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1679 - acc: 0.9833 - val_loss: 0.8872 - val_acc: 0.5000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1774 - acc: 0.9667 - val_loss: 0.8935 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1851 - acc: 0.9833 - val_loss: 0.8911 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1535 - acc: 1.0000 - val_loss: 0.8865 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1838 - acc: 0.9667 - val_loss: 0.8849 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1697 - acc: 0.9833 - val_loss: 0.8729 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1730 - acc: 0.9833 - val_loss: 0.8586 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1641 - acc: 1.0000 - val_loss: 0.8467 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1958 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1816 - acc: 0.9833 - val_loss: 0.8325 - val_acc: 0.5000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1746 - acc: 0.9500 - val_loss: 0.8346 - val_acc: 0.5000\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1710 - acc: 1.0000 - val_loss: 0.8492 - val_acc: 0.5000\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1717 - acc: 1.0000 - val_loss: 0.8786 - val_acc: 0.5000\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1708 - acc: 1.0000 - val_loss: 0.8901 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1505 - acc: 1.0000 - val_loss: 0.8968 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1722 - acc: 0.9833 - val_loss: 0.8955 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1692 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.1466 - acc: 1.0000 - val_loss: 0.8687 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1867 - acc: 0.9500 - val_loss: 0.8586 - val_acc: 0.4500\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1679 - acc: 0.9667 - val_loss: 0.8544 - val_acc: 0.4500\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1534 - acc: 0.9833 - val_loss: 0.8368 - val_acc: 0.4500\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1718 - acc: 1.0000 - val_loss: 0.8303 - val_acc: 0.4500\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1433 - acc: 1.0000 - val_loss: 0.8464 - val_acc: 0.4500\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1749 - acc: 0.9667 - val_loss: 0.8428 - val_acc: 0.4500\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 720us/sample - loss: 0.1570 - acc: 1.0000 - val_loss: 0.8335 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1774 - acc: 0.9833 - val_loss: 0.8378 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1645 - acc: 1.0000 - val_loss: 0.8330 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1547 - acc: 0.9833 - val_loss: 0.8204 - val_acc: 0.5000\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1576 - acc: 1.0000 - val_loss: 0.8207 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1699 - acc: 0.9833 - val_loss: 0.8322 - val_acc: 0.5500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1505 - acc: 0.9833 - val_loss: 0.8568 - val_acc: 0.5500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1588 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1750 - acc: 0.9833 - val_loss: 0.9004 - val_acc: 0.4500\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1657 - acc: 0.9500 - val_loss: 0.8948 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1341 - acc: 1.0000 - val_loss: 0.8924 - val_acc: 0.5500\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1485 - acc: 1.0000 - val_loss: 0.8873 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1581 - acc: 0.9833 - val_loss: 0.8862 - val_acc: 0.5000\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1712 - acc: 1.0000 - val_loss: 0.8743 - val_acc: 0.5000\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1558 - acc: 0.9833 - val_loss: 0.8502 - val_acc: 0.4500\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1358 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.1546 - acc: 0.9833 - val_loss: 0.8412 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1662 - acc: 0.9833 - val_loss: 0.8411 - val_acc: 0.5000\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1652 - acc: 1.0000 - val_loss: 0.8484 - val_acc: 0.4500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1404 - acc: 0.9833 - val_loss: 0.8521 - val_acc: 0.4500\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1541 - acc: 0.9833 - val_loss: 0.8616 - val_acc: 0.4500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1475 - acc: 0.9833 - val_loss: 0.8742 - val_acc: 0.4500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1430 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.4500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 773us/sample - loss: 0.1521 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.4500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1372 - acc: 0.9667 - val_loss: 0.8714 - val_acc: 0.4500\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1616 - acc: 0.9833 - val_loss: 0.8723 - val_acc: 0.4500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1577 - acc: 0.9833 - val_loss: 0.8594 - val_acc: 0.4500\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1601 - acc: 0.9833 - val_loss: 0.8406 - val_acc: 0.4500\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1535 - acc: 0.9667 - val_loss: 0.8291 - val_acc: 0.4500\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1736 - acc: 1.0000 - val_loss: 0.8219 - val_acc: 0.4500\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1321 - acc: 1.0000 - val_loss: 0.8307 - val_acc: 0.4500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1489 - acc: 1.0000 - val_loss: 0.8209 - val_acc: 0.4500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 726us/sample - loss: 0.1333 - acc: 1.0000 - val_loss: 0.8105 - val_acc: 0.4000\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.1424 - acc: 1.0000 - val_loss: 0.8067 - val_acc: 0.4500\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1381 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1259 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1444 - acc: 1.0000 - val_loss: 0.8319 - val_acc: 0.5500\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1505 - acc: 0.9833 - val_loss: 0.8486 - val_acc: 0.5500\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1474 - acc: 1.0000 - val_loss: 0.8467 - val_acc: 0.5500\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1338 - acc: 1.0000 - val_loss: 0.8540 - val_acc: 0.5000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 0.8604 - val_acc: 0.5000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1558 - acc: 1.0000 - val_loss: 0.8551 - val_acc: 0.5000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1548 - acc: 0.9833 - val_loss: 0.8280 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1495 - acc: 1.0000 - val_loss: 0.8067 - val_acc: 0.5000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1443 - acc: 0.9833 - val_loss: 0.7894 - val_acc: 0.5000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1502 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.5000\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1348 - acc: 1.0000 - val_loss: 0.7907 - val_acc: 0.5000\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.1131 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.5000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1557 - acc: 0.9833 - val_loss: 0.7742 - val_acc: 0.5000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1610 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1446 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.5000\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1266 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.5000\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1643 - acc: 0.9500 - val_loss: 0.7688 - val_acc: 0.5000\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1529 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5000\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1454 - acc: 0.9833 - val_loss: 0.7398 - val_acc: 0.5000\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1472 - acc: 1.0000 - val_loss: 0.7445 - val_acc: 0.5000\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1396 - acc: 0.9833 - val_loss: 0.7521 - val_acc: 0.5000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1475 - acc: 0.9833 - val_loss: 0.7489 - val_acc: 0.5000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1390 - acc: 0.9833 - val_loss: 0.7474 - val_acc: 0.5000\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1252 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1418 - acc: 0.9833 - val_loss: 0.7529 - val_acc: 0.5000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1136 - acc: 0.9833 - val_loss: 0.7417 - val_acc: 0.5000\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1420 - acc: 1.0000 - val_loss: 0.7408 - val_acc: 0.5000\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1257 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5000\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1339 - acc: 0.9833 - val_loss: 0.7334 - val_acc: 0.5000\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1384 - acc: 1.0000 - val_loss: 0.7223 - val_acc: 0.4500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1432 - acc: 0.9833 - val_loss: 0.7208 - val_acc: 0.5000\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1095 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.5000\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1633 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.5000\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1288 - acc: 1.0000 - val_loss: 0.7348 - val_acc: 0.5000\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1753 - acc: 0.9833 - val_loss: 0.7351 - val_acc: 0.5000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1166 - acc: 0.9833 - val_loss: 0.7508 - val_acc: 0.5000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1160 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.5000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1368 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.5000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.5000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1582 - acc: 0.9667 - val_loss: 0.7551 - val_acc: 0.5000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1468 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.5000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.1476 - acc: 0.9667 - val_loss: 0.7599 - val_acc: 0.5000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1354 - acc: 0.9833 - val_loss: 0.7708 - val_acc: 0.5000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1175 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 0.5000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1034 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.5000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1331 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.5500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1268 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.5500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1314 - acc: 1.0000 - val_loss: 0.7592 - val_acc: 0.5500\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1102 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.5500\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1278 - acc: 0.9667 - val_loss: 0.7662 - val_acc: 0.5000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1171 - acc: 0.9833 - val_loss: 0.7789 - val_acc: 0.5000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1103 - acc: 1.0000 - val_loss: 0.7903 - val_acc: 0.5000\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1248 - acc: 1.0000 - val_loss: 0.8074 - val_acc: 0.5000\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1266 - acc: 1.0000 - val_loss: 0.7996 - val_acc: 0.5500\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1241 - acc: 1.0000 - val_loss: 0.7931 - val_acc: 0.5500\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1273 - acc: 1.0000 - val_loss: 0.7750 - val_acc: 0.5500\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1281 - acc: 0.9833 - val_loss: 0.7693 - val_acc: 0.5500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1506 - acc: 0.9833 - val_loss: 0.7722 - val_acc: 0.5500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1089 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.5000\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1135 - acc: 1.0000 - val_loss: 0.7306 - val_acc: 0.5000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.1179 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.5500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0928 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.5500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.1290 - acc: 1.0000 - val_loss: 0.7634 - val_acc: 0.5500\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.1171 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.5000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.1259 - acc: 1.0000 - val_loss: 0.7974 - val_acc: 0.5000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1690 - acc: 0.9833 - val_loss: 0.8068 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1114 - acc: 1.0000 - val_loss: 0.8050 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1102 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.5500\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1330 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.5500\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0952 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.5500\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1025 - acc: 1.0000 - val_loss: 0.7758 - val_acc: 0.5500\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1148 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.5500\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1116 - acc: 1.0000 - val_loss: 0.8108 - val_acc: 0.5500\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1206 - acc: 1.0000 - val_loss: 0.8291 - val_acc: 0.5000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1257 - acc: 0.9667 - val_loss: 0.8451 - val_acc: 0.5000\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1181 - acc: 0.9833 - val_loss: 0.8451 - val_acc: 0.5000\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1390 - acc: 0.9833 - val_loss: 0.8012 - val_acc: 0.5000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1118 - acc: 1.0000 - val_loss: 0.7670 - val_acc: 0.5500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1096 - acc: 1.0000 - val_loss: 0.7246 - val_acc: 0.6000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1027 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.6000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1173 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.6000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1016 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.5500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1224 - acc: 1.0000 - val_loss: 0.7229 - val_acc: 0.6000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1412 - acc: 0.9833 - val_loss: 0.7473 - val_acc: 0.6000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1230 - acc: 1.0000 - val_loss: 0.7818 - val_acc: 0.6000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1295 - acc: 1.0000 - val_loss: 0.8131 - val_acc: 0.5500\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1014 - acc: 1.0000 - val_loss: 0.8212 - val_acc: 0.5500\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1100 - acc: 1.0000 - val_loss: 0.8177 - val_acc: 0.5500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1125 - acc: 1.0000 - val_loss: 0.8173 - val_acc: 0.5500\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1123 - acc: 0.9833 - val_loss: 0.7937 - val_acc: 0.5500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1148 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.6000\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1009 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.6000\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.1157 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.6000\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 724us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.6000\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 744us/sample - loss: 0.1265 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.6000\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.1087 - acc: 1.0000 - val_loss: 0.7390 - val_acc: 0.6000\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 727us/sample - loss: 0.1065 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.6000\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1028 - acc: 1.0000 - val_loss: 0.7980 - val_acc: 0.6000\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1099 - acc: 1.0000 - val_loss: 0.8068 - val_acc: 0.6000\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1347 - acc: 0.9833 - val_loss: 0.8012 - val_acc: 0.6000\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1087 - acc: 1.0000 - val_loss: 0.8024 - val_acc: 0.6000\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1163 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.6000\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0949 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.5500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1124 - acc: 1.0000 - val_loss: 0.8052 - val_acc: 0.5500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1050 - acc: 1.0000 - val_loss: 0.8087 - val_acc: 0.5500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1094 - acc: 1.0000 - val_loss: 0.8018 - val_acc: 0.5500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0969 - acc: 0.9833 - val_loss: 0.7909 - val_acc: 0.5500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1253 - acc: 0.9667 - val_loss: 0.7813 - val_acc: 0.5500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1150 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.5500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1229 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.5500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1047 - acc: 1.0000 - val_loss: 0.7311 - val_acc: 0.5500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1339 - acc: 0.9500 - val_loss: 0.7460 - val_acc: 0.5500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1139 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.5500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0979 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.5500\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.5500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0965 - acc: 1.0000 - val_loss: 0.7946 - val_acc: 0.5500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0926 - acc: 1.0000 - val_loss: 0.8134 - val_acc: 0.5500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1189 - acc: 1.0000 - val_loss: 0.8228 - val_acc: 0.5500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1365 - acc: 1.0000 - val_loss: 0.8059 - val_acc: 0.5500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1028 - acc: 1.0000 - val_loss: 0.7844 - val_acc: 0.5500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0907 - acc: 1.0000 - val_loss: 0.7566 - val_acc: 0.5500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1062 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.5500\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1088 - acc: 0.9833 - val_loss: 0.7203 - val_acc: 0.6000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1085 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.5500\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1066 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.5500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.0994 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.5500\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0992 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.5500\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1081 - acc: 1.0000 - val_loss: 0.7148 - val_acc: 0.5500\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0985 - acc: 1.0000 - val_loss: 0.7146 - val_acc: 0.5500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0951 - acc: 1.0000 - val_loss: 0.7223 - val_acc: 0.5500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.1139 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.5500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1006 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.5500\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0916 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.5500\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0843 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5500\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0981 - acc: 0.9833 - val_loss: 0.7810 - val_acc: 0.5500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1180 - acc: 0.9833 - val_loss: 0.7884 - val_acc: 0.5500\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1034 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 0.5500\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.5500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.5500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1004 - acc: 0.9833 - val_loss: 0.7570 - val_acc: 0.5500\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0985 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.5500\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1125 - acc: 0.9833 - val_loss: 0.7600 - val_acc: 0.5500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0944 - acc: 0.9833 - val_loss: 0.7423 - val_acc: 0.5500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1074 - acc: 1.0000 - val_loss: 0.7192 - val_acc: 0.6000\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1144 - acc: 0.9833 - val_loss: 0.7266 - val_acc: 0.5500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0915 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.5500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0829 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.6000\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1119 - acc: 0.9833 - val_loss: 0.7013 - val_acc: 0.6500\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1160 - acc: 1.0000 - val_loss: 0.6828 - val_acc: 0.6500\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0784 - acc: 1.0000 - val_loss: 0.6651 - val_acc: 0.6500\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1046 - acc: 0.9833 - val_loss: 0.6537 - val_acc: 0.6500\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0877 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.6500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0820 - acc: 1.0000 - val_loss: 0.6490 - val_acc: 0.6500\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1067 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.6500\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0943 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.6500\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.0855 - acc: 1.0000 - val_loss: 0.5921 - val_acc: 0.6500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1221 - acc: 1.0000 - val_loss: 0.6007 - val_acc: 0.7000\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1057 - acc: 1.0000 - val_loss: 0.6141 - val_acc: 0.6000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0971 - acc: 1.0000 - val_loss: 0.6418 - val_acc: 0.6000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0836 - acc: 1.0000 - val_loss: 0.6750 - val_acc: 0.6000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1160 - acc: 1.0000 - val_loss: 0.7102 - val_acc: 0.6500\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0898 - acc: 1.0000 - val_loss: 0.7241 - val_acc: 0.6500\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1085 - acc: 0.9833 - val_loss: 0.7278 - val_acc: 0.6500\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0994 - acc: 0.9833 - val_loss: 0.7606 - val_acc: 0.6500\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0846 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.5500\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1026 - acc: 0.9833 - val_loss: 0.7698 - val_acc: 0.5000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0793 - acc: 1.0000 - val_loss: 0.7619 - val_acc: 0.5000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1150 - acc: 0.9833 - val_loss: 0.7354 - val_acc: 0.5500\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0865 - acc: 1.0000 - val_loss: 0.7173 - val_acc: 0.5500\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1176 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.5500\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0848 - acc: 1.0000 - val_loss: 0.6917 - val_acc: 0.6000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0938 - acc: 1.0000 - val_loss: 0.6984 - val_acc: 0.6000\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0952 - acc: 0.9833 - val_loss: 0.7218 - val_acc: 0.5500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0788 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 0.5500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0889 - acc: 1.0000 - val_loss: 0.7148 - val_acc: 0.5500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.0919 - acc: 0.9833 - val_loss: 0.7004 - val_acc: 0.5500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0790 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.5500\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0962 - acc: 1.0000 - val_loss: 0.6982 - val_acc: 0.6000\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0804 - acc: 1.0000 - val_loss: 0.7165 - val_acc: 0.5500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.1180 - acc: 0.9833 - val_loss: 0.7307 - val_acc: 0.5500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0979 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.5500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0983 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 0.5500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1104 - acc: 0.9833 - val_loss: 0.7319 - val_acc: 0.5500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0934 - acc: 0.9833 - val_loss: 0.7209 - val_acc: 0.5500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.0979 - acc: 1.0000 - val_loss: 0.7024 - val_acc: 0.6500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.6500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0870 - acc: 1.0000 - val_loss: 0.6513 - val_acc: 0.6500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1006 - acc: 1.0000 - val_loss: 0.6490 - val_acc: 0.6500\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0986 - acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.6500\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.0981 - acc: 0.9833 - val_loss: 0.6360 - val_acc: 0.6500\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1027 - acc: 0.9833 - val_loss: 0.6296 - val_acc: 0.6500\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0822 - acc: 0.9833 - val_loss: 0.6250 - val_acc: 0.6500\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1009 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 0.6500\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0779 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.6500\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0902 - acc: 1.0000 - val_loss: 0.6560 - val_acc: 0.6000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0750 - acc: 1.0000 - val_loss: 0.6561 - val_acc: 0.6000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0776 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.6000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0945 - acc: 0.9833 - val_loss: 0.6441 - val_acc: 0.6500\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0874 - acc: 1.0000 - val_loss: 0.6516 - val_acc: 0.6000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0782 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.6000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0817 - acc: 1.0000 - val_loss: 0.6783 - val_acc: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngMwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.4744 - acc: 0.7500\n",
            "test loss, test acc: [0.47436710058245807, 0.75]\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P08E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 1 2 2 2 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.4047 - acc: 0.2667 - val_loss: 1.3746 - val_acc: 0.3500\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 1.2201 - acc: 0.5333 - val_loss: 1.3691 - val_acc: 0.4000\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 1.0788 - acc: 0.7167 - val_loss: 1.3603 - val_acc: 0.5500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 1.0038 - acc: 0.5500 - val_loss: 1.3490 - val_acc: 0.5500\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.9349 - acc: 0.5833 - val_loss: 1.3364 - val_acc: 0.6000\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.8826 - acc: 0.6833 - val_loss: 1.3229 - val_acc: 0.5500\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.8487 - acc: 0.6167 - val_loss: 1.3090 - val_acc: 0.5500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.8096 - acc: 0.7333 - val_loss: 1.2952 - val_acc: 0.5500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.7930 - acc: 0.7500 - val_loss: 1.2817 - val_acc: 0.5500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.7842 - acc: 0.7667 - val_loss: 1.2677 - val_acc: 0.5500\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 776us/sample - loss: 0.7652 - acc: 0.7833 - val_loss: 1.2543 - val_acc: 0.5000\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.7603 - acc: 0.7833 - val_loss: 1.2411 - val_acc: 0.5000\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.7497 - acc: 0.8167 - val_loss: 1.2278 - val_acc: 0.4500\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.7359 - acc: 0.8333 - val_loss: 1.2141 - val_acc: 0.5500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.7162 - acc: 0.8667 - val_loss: 1.2010 - val_acc: 0.5500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.7177 - acc: 0.8500 - val_loss: 1.1879 - val_acc: 0.5000\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.7081 - acc: 0.7833 - val_loss: 1.1761 - val_acc: 0.5000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.6938 - acc: 0.8000 - val_loss: 1.1646 - val_acc: 0.4000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.6912 - acc: 0.8167 - val_loss: 1.1535 - val_acc: 0.3500\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.6707 - acc: 0.8500 - val_loss: 1.1427 - val_acc: 0.3500\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.6713 - acc: 0.8667 - val_loss: 1.1323 - val_acc: 0.4000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.6536 - acc: 0.9333 - val_loss: 1.1218 - val_acc: 0.4500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.6274 - acc: 0.9000 - val_loss: 1.1122 - val_acc: 0.4500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.6542 - acc: 0.8667 - val_loss: 1.1024 - val_acc: 0.4500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.6352 - acc: 0.7833 - val_loss: 1.0931 - val_acc: 0.4500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.6264 - acc: 0.8500 - val_loss: 1.0843 - val_acc: 0.4500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.5992 - acc: 0.9000 - val_loss: 1.0766 - val_acc: 0.5000\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5946 - acc: 0.8500 - val_loss: 1.0697 - val_acc: 0.4500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.6062 - acc: 0.8500 - val_loss: 1.0625 - val_acc: 0.4500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.5902 - acc: 0.8833 - val_loss: 1.0551 - val_acc: 0.4500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.5758 - acc: 0.8500 - val_loss: 1.0483 - val_acc: 0.4500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.5873 - acc: 0.8667 - val_loss: 1.0420 - val_acc: 0.4500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.5643 - acc: 0.9000 - val_loss: 1.0362 - val_acc: 0.4500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.5758 - acc: 0.8333 - val_loss: 1.0308 - val_acc: 0.4500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 733us/sample - loss: 0.5447 - acc: 0.8833 - val_loss: 1.0248 - val_acc: 0.4000\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.5527 - acc: 0.8833 - val_loss: 1.0180 - val_acc: 0.4000\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.5380 - acc: 0.9167 - val_loss: 1.0105 - val_acc: 0.4000\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.5503 - acc: 0.8667 - val_loss: 1.0034 - val_acc: 0.4000\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.5342 - acc: 0.9167 - val_loss: 0.9967 - val_acc: 0.4000\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.5476 - acc: 0.9167 - val_loss: 0.9912 - val_acc: 0.4000\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.5016 - acc: 0.9167 - val_loss: 0.9858 - val_acc: 0.4000\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.5153 - acc: 0.9000 - val_loss: 0.9804 - val_acc: 0.4000\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 713us/sample - loss: 0.4907 - acc: 0.9500 - val_loss: 0.9762 - val_acc: 0.4000\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.4946 - acc: 0.9333 - val_loss: 0.9722 - val_acc: 0.4000\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.4985 - acc: 0.8833 - val_loss: 0.9683 - val_acc: 0.4000\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.4993 - acc: 0.9000 - val_loss: 0.9640 - val_acc: 0.4000\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.5006 - acc: 0.9500 - val_loss: 0.9593 - val_acc: 0.4000\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.4743 - acc: 0.9667 - val_loss: 0.9556 - val_acc: 0.4000\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.4710 - acc: 0.9333 - val_loss: 0.9516 - val_acc: 0.4000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.4651 - acc: 0.9500 - val_loss: 0.9462 - val_acc: 0.4000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.4667 - acc: 0.9000 - val_loss: 0.9409 - val_acc: 0.4000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.4671 - acc: 0.9500 - val_loss: 0.9356 - val_acc: 0.4000\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.4534 - acc: 0.9333 - val_loss: 0.9297 - val_acc: 0.4000\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.4344 - acc: 0.9500 - val_loss: 0.9240 - val_acc: 0.4000\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.4854 - acc: 0.9167 - val_loss: 0.9183 - val_acc: 0.4000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.4456 - acc: 0.9500 - val_loss: 0.9121 - val_acc: 0.4000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4377 - acc: 0.9500 - val_loss: 0.9072 - val_acc: 0.4000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4398 - acc: 0.9500 - val_loss: 0.9012 - val_acc: 0.4000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.4343 - acc: 0.9000 - val_loss: 0.8946 - val_acc: 0.4000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.4321 - acc: 0.9167 - val_loss: 0.8897 - val_acc: 0.4000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.4218 - acc: 0.9333 - val_loss: 0.8859 - val_acc: 0.4000\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.4328 - acc: 0.9333 - val_loss: 0.8827 - val_acc: 0.4000\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.4012 - acc: 0.9833 - val_loss: 0.8805 - val_acc: 0.4000\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.4257 - acc: 0.9667 - val_loss: 0.8801 - val_acc: 0.4000\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.4159 - acc: 0.9667 - val_loss: 0.8802 - val_acc: 0.4000\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.4135 - acc: 0.9500 - val_loss: 0.8810 - val_acc: 0.4000\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.4091 - acc: 0.9333 - val_loss: 0.8806 - val_acc: 0.4000\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.3959 - acc: 0.9833 - val_loss: 0.8791 - val_acc: 0.4000\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3797 - acc: 0.9667 - val_loss: 0.8753 - val_acc: 0.4000\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.3796 - acc: 0.9500 - val_loss: 0.8733 - val_acc: 0.4000\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3889 - acc: 0.9667 - val_loss: 0.8699 - val_acc: 0.4500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.3829 - acc: 0.9833 - val_loss: 0.8687 - val_acc: 0.4500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.3673 - acc: 0.9667 - val_loss: 0.8668 - val_acc: 0.4500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.3769 - acc: 0.9667 - val_loss: 0.8644 - val_acc: 0.4500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3911 - acc: 0.9333 - val_loss: 0.8627 - val_acc: 0.4500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3728 - acc: 0.9667 - val_loss: 0.8623 - val_acc: 0.4500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.3653 - acc: 0.9500 - val_loss: 0.8593 - val_acc: 0.4500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.3690 - acc: 0.9667 - val_loss: 0.8550 - val_acc: 0.4500\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3624 - acc: 0.9667 - val_loss: 0.8520 - val_acc: 0.4500\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.3444 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.4500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.3549 - acc: 0.9833 - val_loss: 0.8477 - val_acc: 0.4500\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.3568 - acc: 0.9500 - val_loss: 0.8467 - val_acc: 0.4500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 711us/sample - loss: 0.3447 - acc: 1.0000 - val_loss: 0.8456 - val_acc: 0.4500\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3791 - acc: 1.0000 - val_loss: 0.8462 - val_acc: 0.4500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.3442 - acc: 0.9667 - val_loss: 0.8458 - val_acc: 0.4500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.3403 - acc: 0.9833 - val_loss: 0.8462 - val_acc: 0.4500\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.3319 - acc: 0.9667 - val_loss: 0.8456 - val_acc: 0.4500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3548 - acc: 0.9500 - val_loss: 0.8432 - val_acc: 0.4500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3472 - acc: 0.9667 - val_loss: 0.8406 - val_acc: 0.4500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.3351 - acc: 1.0000 - val_loss: 0.8365 - val_acc: 0.4500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.3305 - acc: 0.9667 - val_loss: 0.8338 - val_acc: 0.4500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3412 - acc: 0.9667 - val_loss: 0.8295 - val_acc: 0.4500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.3475 - acc: 0.9667 - val_loss: 0.8283 - val_acc: 0.4500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 732us/sample - loss: 0.3420 - acc: 0.9833 - val_loss: 0.8265 - val_acc: 0.4500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.3326 - acc: 0.9833 - val_loss: 0.8237 - val_acc: 0.4500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.3251 - acc: 0.9667 - val_loss: 0.8195 - val_acc: 0.4500\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3434 - acc: 0.9667 - val_loss: 0.8158 - val_acc: 0.4500\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3212 - acc: 0.9667 - val_loss: 0.8129 - val_acc: 0.4500\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.3193 - acc: 1.0000 - val_loss: 0.8093 - val_acc: 0.4500\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.3232 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.4500\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.3221 - acc: 0.9833 - val_loss: 0.7999 - val_acc: 0.4500\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3147 - acc: 0.9833 - val_loss: 0.7941 - val_acc: 0.5000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3122 - acc: 0.9833 - val_loss: 0.7888 - val_acc: 0.5500\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3133 - acc: 0.9667 - val_loss: 0.7856 - val_acc: 0.5500\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.3433 - acc: 0.9667 - val_loss: 0.7842 - val_acc: 0.5500\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.3219 - acc: 0.9333 - val_loss: 0.7868 - val_acc: 0.5500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.3139 - acc: 1.0000 - val_loss: 0.7917 - val_acc: 0.5000\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.3316 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.5000\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.3116 - acc: 0.9833 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2986 - acc: 0.9667 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.3143 - acc: 1.0000 - val_loss: 0.7963 - val_acc: 0.5000\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.3073 - acc: 1.0000 - val_loss: 0.7958 - val_acc: 0.5000\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2849 - acc: 0.9833 - val_loss: 0.7921 - val_acc: 0.5000\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3054 - acc: 0.9833 - val_loss: 0.7914 - val_acc: 0.5000\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2890 - acc: 1.0000 - val_loss: 0.7900 - val_acc: 0.5000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.2972 - acc: 0.9667 - val_loss: 0.7884 - val_acc: 0.5000\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.3069 - acc: 0.9500 - val_loss: 0.7869 - val_acc: 0.5000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2999 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3107 - acc: 0.9500 - val_loss: 0.7863 - val_acc: 0.5000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3135 - acc: 0.9667 - val_loss: 0.7869 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2902 - acc: 1.0000 - val_loss: 0.7863 - val_acc: 0.5000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.2793 - acc: 0.9833 - val_loss: 0.7855 - val_acc: 0.5000\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.3011 - acc: 0.9833 - val_loss: 0.7856 - val_acc: 0.5000\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2943 - acc: 0.9667 - val_loss: 0.7868 - val_acc: 0.5000\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2840 - acc: 1.0000 - val_loss: 0.7896 - val_acc: 0.5500\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2856 - acc: 0.9833 - val_loss: 0.7956 - val_acc: 0.5500\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.2930 - acc: 0.9500 - val_loss: 0.7982 - val_acc: 0.5500\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2797 - acc: 0.9833 - val_loss: 0.7983 - val_acc: 0.5500\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.2912 - acc: 1.0000 - val_loss: 0.7997 - val_acc: 0.5500\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.2834 - acc: 0.9833 - val_loss: 0.7964 - val_acc: 0.5500\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2823 - acc: 0.9833 - val_loss: 0.7932 - val_acc: 0.5500\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.2810 - acc: 0.9667 - val_loss: 0.7913 - val_acc: 0.5500\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2661 - acc: 0.9833 - val_loss: 0.7898 - val_acc: 0.5500\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2972 - acc: 0.9500 - val_loss: 0.7873 - val_acc: 0.5500\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.2864 - acc: 1.0000 - val_loss: 0.7878 - val_acc: 0.4500\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.2844 - acc: 0.9833 - val_loss: 0.7851 - val_acc: 0.4500\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.2769 - acc: 0.9833 - val_loss: 0.7851 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2721 - acc: 0.9833 - val_loss: 0.7861 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.2922 - acc: 0.9500 - val_loss: 0.7877 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2708 - acc: 0.9833 - val_loss: 0.7881 - val_acc: 0.5500\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2702 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.5500\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.2925 - acc: 0.9667 - val_loss: 0.7855 - val_acc: 0.6000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2663 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 0.6000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 737us/sample - loss: 0.2699 - acc: 0.9833 - val_loss: 0.7797 - val_acc: 0.6000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2859 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.2827 - acc: 0.9500 - val_loss: 0.7798 - val_acc: 0.5000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2543 - acc: 0.9667 - val_loss: 0.7792 - val_acc: 0.5500\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2688 - acc: 0.9833 - val_loss: 0.7815 - val_acc: 0.5500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.2485 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.5500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2722 - acc: 1.0000 - val_loss: 0.7856 - val_acc: 0.5500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2883 - acc: 0.9500 - val_loss: 0.7882 - val_acc: 0.5500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2627 - acc: 0.9833 - val_loss: 0.7916 - val_acc: 0.5500\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2581 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.5500\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.2657 - acc: 1.0000 - val_loss: 0.7945 - val_acc: 0.5500\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.2582 - acc: 1.0000 - val_loss: 0.7968 - val_acc: 0.5500\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.2715 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.5500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2662 - acc: 0.9500 - val_loss: 0.8035 - val_acc: 0.5500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2460 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.5500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2552 - acc: 0.9833 - val_loss: 0.8073 - val_acc: 0.5500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2667 - acc: 1.0000 - val_loss: 0.8016 - val_acc: 0.5500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2550 - acc: 1.0000 - val_loss: 0.7967 - val_acc: 0.5500\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.2608 - acc: 0.9667 - val_loss: 0.7970 - val_acc: 0.5500\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.2636 - acc: 1.0000 - val_loss: 0.7989 - val_acc: 0.5500\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2526 - acc: 1.0000 - val_loss: 0.8001 - val_acc: 0.5500\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2643 - acc: 1.0000 - val_loss: 0.8055 - val_acc: 0.5500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2492 - acc: 1.0000 - val_loss: 0.8111 - val_acc: 0.5500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2445 - acc: 1.0000 - val_loss: 0.8118 - val_acc: 0.5500\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.2584 - acc: 1.0000 - val_loss: 0.8083 - val_acc: 0.5500\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.2521 - acc: 1.0000 - val_loss: 0.8059 - val_acc: 0.5500\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2320 - acc: 1.0000 - val_loss: 0.8067 - val_acc: 0.5500\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2414 - acc: 1.0000 - val_loss: 0.8063 - val_acc: 0.5500\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2437 - acc: 0.9833 - val_loss: 0.8046 - val_acc: 0.5500\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2586 - acc: 0.9500 - val_loss: 0.8043 - val_acc: 0.5500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.2371 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.5500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2378 - acc: 0.9833 - val_loss: 0.8056 - val_acc: 0.5500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.2252 - acc: 1.0000 - val_loss: 0.8073 - val_acc: 0.5500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2307 - acc: 1.0000 - val_loss: 0.8106 - val_acc: 0.5500\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.2336 - acc: 1.0000 - val_loss: 0.8096 - val_acc: 0.5500\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.2260 - acc: 1.0000 - val_loss: 0.8094 - val_acc: 0.5500\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.2401 - acc: 0.9833 - val_loss: 0.8104 - val_acc: 0.5500\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2241 - acc: 0.9667 - val_loss: 0.8103 - val_acc: 0.5500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.2304 - acc: 1.0000 - val_loss: 0.8118 - val_acc: 0.5500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.2313 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.5500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2422 - acc: 0.9833 - val_loss: 0.8198 - val_acc: 0.5500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.2383 - acc: 1.0000 - val_loss: 0.8196 - val_acc: 0.5500\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2418 - acc: 1.0000 - val_loss: 0.8229 - val_acc: 0.5500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2284 - acc: 1.0000 - val_loss: 0.8252 - val_acc: 0.5500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2289 - acc: 0.9667 - val_loss: 0.8265 - val_acc: 0.5500\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.2081 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.5500\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2449 - acc: 0.9667 - val_loss: 0.8196 - val_acc: 0.5500\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2263 - acc: 0.9833 - val_loss: 0.8152 - val_acc: 0.5500\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2229 - acc: 0.9833 - val_loss: 0.8152 - val_acc: 0.5500\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.2300 - acc: 0.9667 - val_loss: 0.8161 - val_acc: 0.5500\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.2199 - acc: 1.0000 - val_loss: 0.8204 - val_acc: 0.5500\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.2203 - acc: 0.9833 - val_loss: 0.8253 - val_acc: 0.5500\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2289 - acc: 1.0000 - val_loss: 0.8326 - val_acc: 0.5500\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2267 - acc: 0.9833 - val_loss: 0.8371 - val_acc: 0.5500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.2273 - acc: 0.9667 - val_loss: 0.8369 - val_acc: 0.5500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.2243 - acc: 0.9833 - val_loss: 0.8345 - val_acc: 0.5500\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.2408 - acc: 1.0000 - val_loss: 0.8303 - val_acc: 0.5500\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2231 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.5500\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.2229 - acc: 0.9833 - val_loss: 0.8285 - val_acc: 0.5500\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2232 - acc: 1.0000 - val_loss: 0.8280 - val_acc: 0.5500\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2233 - acc: 1.0000 - val_loss: 0.8217 - val_acc: 0.5500\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.2154 - acc: 0.9833 - val_loss: 0.8195 - val_acc: 0.5500\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2195 - acc: 1.0000 - val_loss: 0.8172 - val_acc: 0.5500\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2208 - acc: 1.0000 - val_loss: 0.8183 - val_acc: 0.5500\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2163 - acc: 1.0000 - val_loss: 0.8158 - val_acc: 0.5500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2171 - acc: 1.0000 - val_loss: 0.8163 - val_acc: 0.5500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2442 - acc: 0.9833 - val_loss: 0.8170 - val_acc: 0.5500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2025 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.5500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2058 - acc: 1.0000 - val_loss: 0.8251 - val_acc: 0.5500\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2425 - acc: 0.9667 - val_loss: 0.8274 - val_acc: 0.5500\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1912 - acc: 1.0000 - val_loss: 0.8350 - val_acc: 0.5500\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.2142 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.5500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2072 - acc: 1.0000 - val_loss: 0.8477 - val_acc: 0.5500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2075 - acc: 1.0000 - val_loss: 0.8561 - val_acc: 0.5500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2169 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.5500\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.2202 - acc: 1.0000 - val_loss: 0.8572 - val_acc: 0.5500\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2180 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.5500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.2113 - acc: 1.0000 - val_loss: 0.8619 - val_acc: 0.5500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1791 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.5000\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.2065 - acc: 1.0000 - val_loss: 0.8674 - val_acc: 0.5000\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.2108 - acc: 0.9667 - val_loss: 0.8718 - val_acc: 0.5000\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 770us/sample - loss: 0.2053 - acc: 0.9833 - val_loss: 0.8735 - val_acc: 0.5000\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 752us/sample - loss: 0.1823 - acc: 1.0000 - val_loss: 0.8744 - val_acc: 0.5000\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 723us/sample - loss: 0.2063 - acc: 0.9833 - val_loss: 0.8726 - val_acc: 0.5000\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2085 - acc: 1.0000 - val_loss: 0.8647 - val_acc: 0.5500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2244 - acc: 0.9833 - val_loss: 0.8529 - val_acc: 0.5500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1807 - acc: 1.0000 - val_loss: 0.8425 - val_acc: 0.5500\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1963 - acc: 1.0000 - val_loss: 0.8392 - val_acc: 0.5500\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2002 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.5500\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1956 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1944 - acc: 1.0000 - val_loss: 0.8465 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1778 - acc: 1.0000 - val_loss: 0.8501 - val_acc: 0.4500\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1974 - acc: 1.0000 - val_loss: 0.8508 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1807 - acc: 1.0000 - val_loss: 0.8529 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1912 - acc: 1.0000 - val_loss: 0.8517 - val_acc: 0.5500\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2108 - acc: 0.9833 - val_loss: 0.8539 - val_acc: 0.5500\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2013 - acc: 1.0000 - val_loss: 0.8602 - val_acc: 0.5500\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2048 - acc: 0.9833 - val_loss: 0.8610 - val_acc: 0.5500\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.1990 - acc: 1.0000 - val_loss: 0.8556 - val_acc: 0.5500\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1962 - acc: 1.0000 - val_loss: 0.8476 - val_acc: 0.5500\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2073 - acc: 1.0000 - val_loss: 0.8450 - val_acc: 0.5500\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1871 - acc: 1.0000 - val_loss: 0.8415 - val_acc: 0.5500\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.2018 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.5500\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1860 - acc: 1.0000 - val_loss: 0.8419 - val_acc: 0.5500\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1971 - acc: 1.0000 - val_loss: 0.8391 - val_acc: 0.5500\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1907 - acc: 0.9833 - val_loss: 0.8338 - val_acc: 0.5500\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1873 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 0.5500\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1773 - acc: 1.0000 - val_loss: 0.8258 - val_acc: 0.5500\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1847 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.5500\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1977 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.5500\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1848 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.5500\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.1914 - acc: 1.0000 - val_loss: 0.8342 - val_acc: 0.5500\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1685 - acc: 1.0000 - val_loss: 0.8408 - val_acc: 0.5500\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1931 - acc: 1.0000 - val_loss: 0.8450 - val_acc: 0.5500\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1712 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.5500\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1779 - acc: 1.0000 - val_loss: 0.8388 - val_acc: 0.5500\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1954 - acc: 1.0000 - val_loss: 0.8367 - val_acc: 0.5500\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2002 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.5500\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1834 - acc: 1.0000 - val_loss: 0.8336 - val_acc: 0.5500\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.1825 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 0.5500\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1999 - acc: 1.0000 - val_loss: 0.8303 - val_acc: 0.5500\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1779 - acc: 1.0000 - val_loss: 0.8324 - val_acc: 0.5500\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1857 - acc: 1.0000 - val_loss: 0.8310 - val_acc: 0.5500\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1703 - acc: 0.9833 - val_loss: 0.8324 - val_acc: 0.5500\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1786 - acc: 1.0000 - val_loss: 0.8329 - val_acc: 0.5500\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1765 - acc: 1.0000 - val_loss: 0.8375 - val_acc: 0.5500\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1739 - acc: 1.0000 - val_loss: 0.8404 - val_acc: 0.5500\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1896 - acc: 1.0000 - val_loss: 0.8438 - val_acc: 0.5500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2004 - acc: 1.0000 - val_loss: 0.8442 - val_acc: 0.5500\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1923 - acc: 0.9833 - val_loss: 0.8443 - val_acc: 0.5500\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1650 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1838 - acc: 1.0000 - val_loss: 0.8447 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1740 - acc: 1.0000 - val_loss: 0.8406 - val_acc: 0.5500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1854 - acc: 0.9833 - val_loss: 0.8376 - val_acc: 0.5500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1815 - acc: 0.9833 - val_loss: 0.8343 - val_acc: 0.5000\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1870 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1754 - acc: 1.0000 - val_loss: 0.8352 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1623 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.5500\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1691 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.5500\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1920 - acc: 0.9833 - val_loss: 0.8310 - val_acc: 0.5000\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1725 - acc: 0.9833 - val_loss: 0.8322 - val_acc: 0.5500\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1923 - acc: 1.0000 - val_loss: 0.8344 - val_acc: 0.5500\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1741 - acc: 1.0000 - val_loss: 0.8323 - val_acc: 0.5500\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1574 - acc: 1.0000 - val_loss: 0.8303 - val_acc: 0.5500\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1566 - acc: 1.0000 - val_loss: 0.8290 - val_acc: 0.6000\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1795 - acc: 0.9833 - val_loss: 0.8271 - val_acc: 0.5500\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1647 - acc: 1.0000 - val_loss: 0.8275 - val_acc: 0.5500\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 728us/sample - loss: 0.1727 - acc: 1.0000 - val_loss: 0.8286 - val_acc: 0.5500\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1750 - acc: 1.0000 - val_loss: 0.8319 - val_acc: 0.5500\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1532 - acc: 1.0000 - val_loss: 0.8393 - val_acc: 0.5500\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1702 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.5500\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1594 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.5500\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1872 - acc: 0.9833 - val_loss: 0.8544 - val_acc: 0.5500\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.1762 - acc: 1.0000 - val_loss: 0.8561 - val_acc: 0.5000\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 705us/sample - loss: 0.1575 - acc: 1.0000 - val_loss: 0.8551 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1592 - acc: 1.0000 - val_loss: 0.8552 - val_acc: 0.5500\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1438 - acc: 1.0000 - val_loss: 0.8566 - val_acc: 0.5500\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1657 - acc: 1.0000 - val_loss: 0.8552 - val_acc: 0.5500\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1708 - acc: 1.0000 - val_loss: 0.8505 - val_acc: 0.5500\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1630 - acc: 1.0000 - val_loss: 0.8457 - val_acc: 0.5500\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1539 - acc: 1.0000 - val_loss: 0.8443 - val_acc: 0.5500\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1692 - acc: 0.9833 - val_loss: 0.8426 - val_acc: 0.5500\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1408 - acc: 0.9833 - val_loss: 0.8394 - val_acc: 0.5500\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.1747 - acc: 1.0000 - val_loss: 0.8327 - val_acc: 0.5500\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1830 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.5500\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1685 - acc: 0.9833 - val_loss: 0.8213 - val_acc: 0.5500\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1485 - acc: 1.0000 - val_loss: 0.8247 - val_acc: 0.5500\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1800 - acc: 1.0000 - val_loss: 0.8242 - val_acc: 0.5500\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1643 - acc: 1.0000 - val_loss: 0.8210 - val_acc: 0.5500\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1527 - acc: 1.0000 - val_loss: 0.8233 - val_acc: 0.5500\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 713us/sample - loss: 0.1516 - acc: 1.0000 - val_loss: 0.8220 - val_acc: 0.5500\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1652 - acc: 1.0000 - val_loss: 0.8212 - val_acc: 0.5500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 742us/sample - loss: 0.1635 - acc: 1.0000 - val_loss: 0.8198 - val_acc: 0.5500\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 732us/sample - loss: 0.1505 - acc: 1.0000 - val_loss: 0.8236 - val_acc: 0.5500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1478 - acc: 1.0000 - val_loss: 0.8287 - val_acc: 0.5500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1718 - acc: 1.0000 - val_loss: 0.8355 - val_acc: 0.5500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1649 - acc: 0.9833 - val_loss: 0.8394 - val_acc: 0.6000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1587 - acc: 1.0000 - val_loss: 0.8393 - val_acc: 0.6000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1596 - acc: 1.0000 - val_loss: 0.8377 - val_acc: 0.5500\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1467 - acc: 1.0000 - val_loss: 0.8345 - val_acc: 0.5500\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1400 - acc: 1.0000 - val_loss: 0.8320 - val_acc: 0.5500\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1321 - acc: 1.0000 - val_loss: 0.8315 - val_acc: 0.5500\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1587 - acc: 1.0000 - val_loss: 0.8340 - val_acc: 0.5500\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1488 - acc: 1.0000 - val_loss: 0.8329 - val_acc: 0.5500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1846 - acc: 0.9833 - val_loss: 0.8325 - val_acc: 0.6000\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1389 - acc: 1.0000 - val_loss: 0.8311 - val_acc: 0.6000\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1492 - acc: 0.9833 - val_loss: 0.8286 - val_acc: 0.6000\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.1373 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.5500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1586 - acc: 1.0000 - val_loss: 0.8232 - val_acc: 0.6000\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1360 - acc: 1.0000 - val_loss: 0.8218 - val_acc: 0.5000\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1421 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.5500\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1408 - acc: 1.0000 - val_loss: 0.8274 - val_acc: 0.5500\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 700us/sample - loss: 0.1594 - acc: 1.0000 - val_loss: 0.8336 - val_acc: 0.5500\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1433 - acc: 1.0000 - val_loss: 0.8356 - val_acc: 0.5500\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1567 - acc: 1.0000 - val_loss: 0.8357 - val_acc: 0.5500\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1571 - acc: 1.0000 - val_loss: 0.8360 - val_acc: 0.5500\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1356 - acc: 1.0000 - val_loss: 0.8344 - val_acc: 0.5500\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1440 - acc: 1.0000 - val_loss: 0.8330 - val_acc: 0.5500\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1605 - acc: 0.9833 - val_loss: 0.8305 - val_acc: 0.5500\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 745us/sample - loss: 0.1468 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.5500\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 775us/sample - loss: 0.1323 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.5500\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1311 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.5500\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1569 - acc: 1.0000 - val_loss: 0.8220 - val_acc: 0.5500\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1501 - acc: 1.0000 - val_loss: 0.8215 - val_acc: 0.5500\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1459 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.5500\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1295 - acc: 1.0000 - val_loss: 0.8314 - val_acc: 0.5500\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1528 - acc: 0.9833 - val_loss: 0.8416 - val_acc: 0.5500\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1312 - acc: 1.0000 - val_loss: 0.8480 - val_acc: 0.5500\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1451 - acc: 1.0000 - val_loss: 0.8482 - val_acc: 0.5500\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1451 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.5500\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1367 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.5500\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.1498 - acc: 1.0000 - val_loss: 0.8385 - val_acc: 0.5500\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1527 - acc: 1.0000 - val_loss: 0.8382 - val_acc: 0.5500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1532 - acc: 1.0000 - val_loss: 0.8395 - val_acc: 0.5500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1290 - acc: 1.0000 - val_loss: 0.8423 - val_acc: 0.5500\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1376 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.5500\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 782us/sample - loss: 0.1629 - acc: 1.0000 - val_loss: 0.8448 - val_acc: 0.5500\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1136 - acc: 1.0000 - val_loss: 0.8460 - val_acc: 0.5500\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1407 - acc: 1.0000 - val_loss: 0.8496 - val_acc: 0.5500\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.1314 - acc: 1.0000 - val_loss: 0.8549 - val_acc: 0.5500\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1439 - acc: 1.0000 - val_loss: 0.8617 - val_acc: 0.5500\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1644 - acc: 0.9833 - val_loss: 0.8635 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1285 - acc: 1.0000 - val_loss: 0.8630 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 744us/sample - loss: 0.1328 - acc: 1.0000 - val_loss: 0.8675 - val_acc: 0.5000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1595 - acc: 1.0000 - val_loss: 0.8769 - val_acc: 0.5000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1414 - acc: 1.0000 - val_loss: 0.8805 - val_acc: 0.5000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1223 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.5500\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1594 - acc: 1.0000 - val_loss: 0.8698 - val_acc: 0.5500\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1427 - acc: 1.0000 - val_loss: 0.8618 - val_acc: 0.5500\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1196 - acc: 1.0000 - val_loss: 0.8504 - val_acc: 0.6000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 793us/sample - loss: 0.1315 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.6000\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1317 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.6000\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1511 - acc: 1.0000 - val_loss: 0.8424 - val_acc: 0.6000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1228 - acc: 1.0000 - val_loss: 0.8418 - val_acc: 0.6000\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1458 - acc: 1.0000 - val_loss: 0.8439 - val_acc: 0.6000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1245 - acc: 1.0000 - val_loss: 0.8495 - val_acc: 0.6000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1353 - acc: 1.0000 - val_loss: 0.8536 - val_acc: 0.5500\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1562 - acc: 0.9833 - val_loss: 0.8575 - val_acc: 0.5500\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1270 - acc: 1.0000 - val_loss: 0.8668 - val_acc: 0.5000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1425 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.5500\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1298 - acc: 1.0000 - val_loss: 0.8715 - val_acc: 0.5500\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1446 - acc: 1.0000 - val_loss: 0.8798 - val_acc: 0.5500\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1297 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.5500\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1187 - acc: 1.0000 - val_loss: 0.8880 - val_acc: 0.5500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1491 - acc: 0.9833 - val_loss: 0.8849 - val_acc: 0.5500\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1280 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 0.4500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1168 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.5000\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 780us/sample - loss: 0.1268 - acc: 1.0000 - val_loss: 0.8846 - val_acc: 0.5000\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1379 - acc: 1.0000 - val_loss: 0.8889 - val_acc: 0.4500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.1197 - acc: 1.0000 - val_loss: 0.9000 - val_acc: 0.5000\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1404 - acc: 1.0000 - val_loss: 0.9084 - val_acc: 0.5000\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1395 - acc: 1.0000 - val_loss: 0.9152 - val_acc: 0.5500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1335 - acc: 1.0000 - val_loss: 0.9144 - val_acc: 0.5500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.1122 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.5500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1233 - acc: 1.0000 - val_loss: 0.9082 - val_acc: 0.5000\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 746us/sample - loss: 0.1341 - acc: 1.0000 - val_loss: 0.9114 - val_acc: 0.4500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1235 - acc: 1.0000 - val_loss: 0.9101 - val_acc: 0.5000\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.1537 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.5000\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1388 - acc: 0.9833 - val_loss: 0.9127 - val_acc: 0.4500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1265 - acc: 1.0000 - val_loss: 0.9048 - val_acc: 0.4500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1175 - acc: 1.0000 - val_loss: 0.8985 - val_acc: 0.4500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1359 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.5000\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1309 - acc: 1.0000 - val_loss: 0.8860 - val_acc: 0.5500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1349 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.5500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1125 - acc: 1.0000 - val_loss: 0.8925 - val_acc: 0.5000\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1361 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.4500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1351 - acc: 1.0000 - val_loss: 0.9069 - val_acc: 0.4500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1197 - acc: 1.0000 - val_loss: 0.9125 - val_acc: 0.4500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1209 - acc: 1.0000 - val_loss: 0.9149 - val_acc: 0.4500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1140 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.4500\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1222 - acc: 1.0000 - val_loss: 0.9260 - val_acc: 0.4500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 748us/sample - loss: 0.1279 - acc: 1.0000 - val_loss: 0.9358 - val_acc: 0.4500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1168 - acc: 1.0000 - val_loss: 0.9445 - val_acc: 0.4500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1331 - acc: 0.9667 - val_loss: 0.9404 - val_acc: 0.4500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1184 - acc: 1.0000 - val_loss: 0.9346 - val_acc: 0.4500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1385 - acc: 1.0000 - val_loss: 0.9319 - val_acc: 0.4500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1108 - acc: 1.0000 - val_loss: 0.9338 - val_acc: 0.5000\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1161 - acc: 1.0000 - val_loss: 0.9364 - val_acc: 0.5000\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1292 - acc: 1.0000 - val_loss: 0.9440 - val_acc: 0.5000\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1308 - acc: 1.0000 - val_loss: 0.9540 - val_acc: 0.5000\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1255 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.5500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.1153 - acc: 1.0000 - val_loss: 0.9588 - val_acc: 0.5000\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1181 - acc: 1.0000 - val_loss: 0.9644 - val_acc: 0.5000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1086 - acc: 1.0000 - val_loss: 0.9656 - val_acc: 0.5500\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.0949 - acc: 1.0000 - val_loss: 0.9543 - val_acc: 0.4000\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 709us/sample - loss: 0.1294 - acc: 1.0000 - val_loss: 0.9405 - val_acc: 0.4500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1107 - acc: 1.0000 - val_loss: 0.9362 - val_acc: 0.4000\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1247 - acc: 1.0000 - val_loss: 0.9362 - val_acc: 0.4000\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1187 - acc: 1.0000 - val_loss: 0.9319 - val_acc: 0.4000\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1338 - acc: 1.0000 - val_loss: 0.9233 - val_acc: 0.4000\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 0.9169 - val_acc: 0.5500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1143 - acc: 1.0000 - val_loss: 0.9171 - val_acc: 0.6000\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1389 - acc: 1.0000 - val_loss: 0.9150 - val_acc: 0.6000\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1179 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.6500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 759us/sample - loss: 0.1156 - acc: 1.0000 - val_loss: 0.9070 - val_acc: 0.6500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.1117 - acc: 1.0000 - val_loss: 0.9156 - val_acc: 0.6500\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1254 - acc: 1.0000 - val_loss: 0.9254 - val_acc: 0.6500\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1230 - acc: 1.0000 - val_loss: 0.9373 - val_acc: 0.6500\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1006 - acc: 1.0000 - val_loss: 0.9546 - val_acc: 0.6500\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.1144 - acc: 0.9833 - val_loss: 0.9681 - val_acc: 0.6500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1033 - acc: 1.0000 - val_loss: 0.9740 - val_acc: 0.6500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1206 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.6500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1341 - acc: 1.0000 - val_loss: 0.9748 - val_acc: 0.6500\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1144 - acc: 1.0000 - val_loss: 0.9777 - val_acc: 0.6000\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1082 - acc: 1.0000 - val_loss: 0.9731 - val_acc: 0.5500\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1241 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.5500\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 712us/sample - loss: 0.1141 - acc: 1.0000 - val_loss: 0.9697 - val_acc: 0.5500\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1111 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.5500\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1026 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.4500\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1178 - acc: 1.0000 - val_loss: 0.9515 - val_acc: 0.4500\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1087 - acc: 1.0000 - val_loss: 0.9433 - val_acc: 0.5000\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1175 - acc: 1.0000 - val_loss: 0.9458 - val_acc: 0.5500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1275 - acc: 1.0000 - val_loss: 0.9510 - val_acc: 0.5500\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1125 - acc: 1.0000 - val_loss: 0.9592 - val_acc: 0.6000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 701us/sample - loss: 0.1204 - acc: 1.0000 - val_loss: 0.9690 - val_acc: 0.6000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1272 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.6000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1079 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.6000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 677us/sample - loss: 0.1036 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.6000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1104 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.6500\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1128 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.6000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1143 - acc: 1.0000 - val_loss: 0.9841 - val_acc: 0.6000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1128 - acc: 1.0000 - val_loss: 0.9731 - val_acc: 0.6000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1131 - acc: 1.0000 - val_loss: 0.9557 - val_acc: 0.6000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1004 - acc: 1.0000 - val_loss: 0.9423 - val_acc: 0.6000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1129 - acc: 1.0000 - val_loss: 0.9339 - val_acc: 0.6000\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1202 - acc: 1.0000 - val_loss: 0.9296 - val_acc: 0.6000\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1052 - acc: 1.0000 - val_loss: 0.9363 - val_acc: 0.6000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 0.9461 - val_acc: 0.6000\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0971 - acc: 1.0000 - val_loss: 0.9632 - val_acc: 0.6500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1076 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.6500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1195 - acc: 0.9833 - val_loss: 1.0053 - val_acc: 0.5500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.1161 - acc: 1.0000 - val_loss: 1.0170 - val_acc: 0.5500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1079 - acc: 1.0000 - val_loss: 1.0188 - val_acc: 0.5000\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0983 - acc: 1.0000 - val_loss: 1.0225 - val_acc: 0.5500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1168 - acc: 0.9833 - val_loss: 1.0261 - val_acc: 0.5500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1200 - acc: 0.9833 - val_loss: 1.0191 - val_acc: 0.5500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1016 - acc: 1.0000 - val_loss: 1.0220 - val_acc: 0.5500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0930 - acc: 1.0000 - val_loss: 1.0323 - val_acc: 0.5500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0929 - acc: 1.0000 - val_loss: 1.0362 - val_acc: 0.5500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0828 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.5500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 1.0283 - val_acc: 0.5500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1062 - acc: 1.0000 - val_loss: 1.0190 - val_acc: 0.5000\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1187 - acc: 1.0000 - val_loss: 1.0119 - val_acc: 0.5500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1040 - acc: 1.0000 - val_loss: 1.0173 - val_acc: 0.6000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.1257 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.6000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 1.0400 - val_acc: 0.5500\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.0952 - acc: 1.0000 - val_loss: 1.0478 - val_acc: 0.6000\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 706us/sample - loss: 0.0967 - acc: 1.0000 - val_loss: 1.0534 - val_acc: 0.6000\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1027 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.5500\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0933 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.5500\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1178 - acc: 1.0000 - val_loss: 1.0542 - val_acc: 0.5500\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.1263 - acc: 1.0000 - val_loss: 1.0746 - val_acc: 0.5500\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.0960 - acc: 1.0000 - val_loss: 1.0875 - val_acc: 0.5500\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 671us/sample - loss: 0.1147 - acc: 1.0000 - val_loss: 1.0885 - val_acc: 0.5500\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1013 - acc: 1.0000 - val_loss: 1.0975 - val_acc: 0.5500\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1061 - acc: 1.0000 - val_loss: 1.0851 - val_acc: 0.5500\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1053 - acc: 1.0000 - val_loss: 1.0659 - val_acc: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVBAoiqKUOSoIFEVRypz/DyzbELg4F413AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 1.3609 - acc: 0.4000\n",
            "test loss, test acc: [1.360870299115777, 0.4]\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P09E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[2 1 1 1 1 2 2 1 1 1 1 2 2 2 2 2 2 2 1 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 6ms/sample - loss: 1.3668 - acc: 0.4000 - val_loss: 1.3890 - val_acc: 0.1000\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 1.2721 - acc: 0.6500 - val_loss: 1.3875 - val_acc: 0.1500\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 1.1771 - acc: 0.5667 - val_loss: 1.3824 - val_acc: 0.3000\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 1.1248 - acc: 0.6000 - val_loss: 1.3740 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 1.0675 - acc: 0.6167 - val_loss: 1.3638 - val_acc: 0.5500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.9996 - acc: 0.7667 - val_loss: 1.3517 - val_acc: 0.5000\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.9652 - acc: 0.6833 - val_loss: 1.3388 - val_acc: 0.4500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.9168 - acc: 0.7500 - val_loss: 1.3254 - val_acc: 0.4500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.8846 - acc: 0.7333 - val_loss: 1.3121 - val_acc: 0.4500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 759us/sample - loss: 0.8718 - acc: 0.6833 - val_loss: 1.2987 - val_acc: 0.4500\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.8451 - acc: 0.6833 - val_loss: 1.2855 - val_acc: 0.3500\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.8430 - acc: 0.7500 - val_loss: 1.2724 - val_acc: 0.3000\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.8149 - acc: 0.7167 - val_loss: 1.2600 - val_acc: 0.3000\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 582us/sample - loss: 0.7877 - acc: 0.7333 - val_loss: 1.2479 - val_acc: 0.3500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.7870 - acc: 0.7667 - val_loss: 1.2363 - val_acc: 0.3500\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.7580 - acc: 0.7500 - val_loss: 1.2251 - val_acc: 0.3500\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.7514 - acc: 0.6667 - val_loss: 1.2143 - val_acc: 0.3500\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.7447 - acc: 0.7333 - val_loss: 1.2040 - val_acc: 0.4000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.7296 - acc: 0.7667 - val_loss: 1.1937 - val_acc: 0.4000\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.7415 - acc: 0.6833 - val_loss: 1.1843 - val_acc: 0.4000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.7023 - acc: 0.7667 - val_loss: 1.1751 - val_acc: 0.4000\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.6972 - acc: 0.7667 - val_loss: 1.1665 - val_acc: 0.4000\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.7026 - acc: 0.8000 - val_loss: 1.1581 - val_acc: 0.4500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.7061 - acc: 0.7000 - val_loss: 1.1498 - val_acc: 0.4500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.7049 - acc: 0.7333 - val_loss: 1.1415 - val_acc: 0.4500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.6800 - acc: 0.7500 - val_loss: 1.1338 - val_acc: 0.4500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.6926 - acc: 0.7500 - val_loss: 1.1265 - val_acc: 0.4500\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.6657 - acc: 0.7833 - val_loss: 1.1195 - val_acc: 0.4500\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.6582 - acc: 0.7500 - val_loss: 1.1134 - val_acc: 0.4500\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.6483 - acc: 0.7833 - val_loss: 1.1077 - val_acc: 0.4500\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.6545 - acc: 0.8167 - val_loss: 1.1021 - val_acc: 0.4500\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.6295 - acc: 0.8000 - val_loss: 1.0969 - val_acc: 0.4500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.6536 - acc: 0.7167 - val_loss: 1.0918 - val_acc: 0.4500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.6531 - acc: 0.7667 - val_loss: 1.0867 - val_acc: 0.4500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.6431 - acc: 0.7500 - val_loss: 1.0814 - val_acc: 0.4500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.6289 - acc: 0.7833 - val_loss: 1.0763 - val_acc: 0.4500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.6470 - acc: 0.7833 - val_loss: 1.0710 - val_acc: 0.4500\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.6238 - acc: 0.8333 - val_loss: 1.0658 - val_acc: 0.4500\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.6284 - acc: 0.7500 - val_loss: 1.0608 - val_acc: 0.4500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.6413 - acc: 0.7500 - val_loss: 1.0554 - val_acc: 0.4500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.5959 - acc: 0.8500 - val_loss: 1.0497 - val_acc: 0.4500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.6143 - acc: 0.7833 - val_loss: 1.0441 - val_acc: 0.4500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.5966 - acc: 0.7833 - val_loss: 1.0388 - val_acc: 0.4500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.6185 - acc: 0.8167 - val_loss: 1.0335 - val_acc: 0.4500\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 587us/sample - loss: 0.6064 - acc: 0.8500 - val_loss: 1.0286 - val_acc: 0.4500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.6064 - acc: 0.7667 - val_loss: 1.0241 - val_acc: 0.4500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.6076 - acc: 0.7833 - val_loss: 1.0195 - val_acc: 0.4500\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 710us/sample - loss: 0.5852 - acc: 0.8500 - val_loss: 1.0147 - val_acc: 0.4500\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.5742 - acc: 0.7833 - val_loss: 1.0092 - val_acc: 0.4000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.5678 - acc: 0.8833 - val_loss: 1.0042 - val_acc: 0.4000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.5830 - acc: 0.8167 - val_loss: 0.9994 - val_acc: 0.4000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.5738 - acc: 0.8667 - val_loss: 0.9952 - val_acc: 0.4000\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.5509 - acc: 0.8500 - val_loss: 0.9914 - val_acc: 0.4000\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.5859 - acc: 0.8000 - val_loss: 0.9882 - val_acc: 0.4000\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.5628 - acc: 0.8500 - val_loss: 0.9847 - val_acc: 0.4000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.5537 - acc: 0.8333 - val_loss: 0.9808 - val_acc: 0.3500\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.5693 - acc: 0.8333 - val_loss: 0.9769 - val_acc: 0.4000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.5923 - acc: 0.7833 - val_loss: 0.9726 - val_acc: 0.4000\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.5594 - acc: 0.7667 - val_loss: 0.9688 - val_acc: 0.4000\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.5538 - acc: 0.8500 - val_loss: 0.9646 - val_acc: 0.4000\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.5595 - acc: 0.8000 - val_loss: 0.9606 - val_acc: 0.4000\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.5371 - acc: 0.8500 - val_loss: 0.9562 - val_acc: 0.4000\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.5658 - acc: 0.7833 - val_loss: 0.9512 - val_acc: 0.4000\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.5479 - acc: 0.7667 - val_loss: 0.9461 - val_acc: 0.4000\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.5444 - acc: 0.8667 - val_loss: 0.9413 - val_acc: 0.4000\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.5426 - acc: 0.8500 - val_loss: 0.9365 - val_acc: 0.4000\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.5520 - acc: 0.8333 - val_loss: 0.9322 - val_acc: 0.4000\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.5330 - acc: 0.8500 - val_loss: 0.9279 - val_acc: 0.4000\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.5298 - acc: 0.7833 - val_loss: 0.9244 - val_acc: 0.4000\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.5485 - acc: 0.7833 - val_loss: 0.9204 - val_acc: 0.4000\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.5312 - acc: 0.8333 - val_loss: 0.9167 - val_acc: 0.4500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.5232 - acc: 0.8500 - val_loss: 0.9127 - val_acc: 0.5000\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.5189 - acc: 0.8667 - val_loss: 0.9090 - val_acc: 0.5000\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.5196 - acc: 0.8500 - val_loss: 0.9055 - val_acc: 0.5000\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.4906 - acc: 0.9000 - val_loss: 0.9020 - val_acc: 0.5000\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.5372 - acc: 0.7833 - val_loss: 0.8979 - val_acc: 0.5000\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.5120 - acc: 0.8500 - val_loss: 0.8943 - val_acc: 0.5000\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.4916 - acc: 0.9167 - val_loss: 0.8914 - val_acc: 0.5000\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.4942 - acc: 0.8667 - val_loss: 0.8881 - val_acc: 0.5000\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.4610 - acc: 0.9167 - val_loss: 0.8852 - val_acc: 0.5000\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.4648 - acc: 0.9333 - val_loss: 0.8816 - val_acc: 0.5000\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4925 - acc: 0.8333 - val_loss: 0.8786 - val_acc: 0.5500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.4638 - acc: 0.9333 - val_loss: 0.8753 - val_acc: 0.6000\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.4730 - acc: 0.8833 - val_loss: 0.8718 - val_acc: 0.6000\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4815 - acc: 0.9167 - val_loss: 0.8700 - val_acc: 0.5000\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.4551 - acc: 0.8667 - val_loss: 0.8678 - val_acc: 0.5000\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.4776 - acc: 0.8667 - val_loss: 0.8648 - val_acc: 0.5500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.4778 - acc: 0.8833 - val_loss: 0.8617 - val_acc: 0.6000\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.4505 - acc: 0.9167 - val_loss: 0.8578 - val_acc: 0.6000\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.4838 - acc: 0.8500 - val_loss: 0.8537 - val_acc: 0.5500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.4492 - acc: 0.8667 - val_loss: 0.8499 - val_acc: 0.5500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.4533 - acc: 0.8833 - val_loss: 0.8459 - val_acc: 0.5500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.4522 - acc: 0.9000 - val_loss: 0.8414 - val_acc: 0.5500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.4501 - acc: 0.9000 - val_loss: 0.8372 - val_acc: 0.5500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.4550 - acc: 0.9000 - val_loss: 0.8335 - val_acc: 0.5500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4401 - acc: 0.8667 - val_loss: 0.8318 - val_acc: 0.5000\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.4470 - acc: 0.8500 - val_loss: 0.8307 - val_acc: 0.5000\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.4483 - acc: 0.9500 - val_loss: 0.8297 - val_acc: 0.5000\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.4303 - acc: 0.9167 - val_loss: 0.8268 - val_acc: 0.5000\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.4808 - acc: 0.8500 - val_loss: 0.8240 - val_acc: 0.5000\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.4336 - acc: 0.9000 - val_loss: 0.8212 - val_acc: 0.5000\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.4449 - acc: 0.9167 - val_loss: 0.8196 - val_acc: 0.5000\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.4696 - acc: 0.8167 - val_loss: 0.8187 - val_acc: 0.5000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.4261 - acc: 0.9167 - val_loss: 0.8174 - val_acc: 0.5000\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.4005 - acc: 0.9167 - val_loss: 0.8164 - val_acc: 0.5000\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4185 - acc: 0.8667 - val_loss: 0.8145 - val_acc: 0.5000\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.4202 - acc: 0.8833 - val_loss: 0.8134 - val_acc: 0.5000\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.3955 - acc: 0.9667 - val_loss: 0.8137 - val_acc: 0.5000\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.4474 - acc: 0.8667 - val_loss: 0.8137 - val_acc: 0.5000\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.4239 - acc: 0.9500 - val_loss: 0.8150 - val_acc: 0.5000\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.4190 - acc: 0.9167 - val_loss: 0.8154 - val_acc: 0.5000\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.4050 - acc: 0.8833 - val_loss: 0.8147 - val_acc: 0.5000\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 589us/sample - loss: 0.4101 - acc: 0.9333 - val_loss: 0.8138 - val_acc: 0.5000\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.3819 - acc: 0.9833 - val_loss: 0.8123 - val_acc: 0.5000\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 730us/sample - loss: 0.3811 - acc: 0.9333 - val_loss: 0.8097 - val_acc: 0.5000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.4035 - acc: 0.8667 - val_loss: 0.8068 - val_acc: 0.5000\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3978 - acc: 0.9500 - val_loss: 0.8035 - val_acc: 0.5000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.4130 - acc: 0.9000 - val_loss: 0.8007 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.4063 - acc: 0.9167 - val_loss: 0.7998 - val_acc: 0.5000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.4135 - acc: 0.8500 - val_loss: 0.8016 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.3837 - acc: 0.9333 - val_loss: 0.8028 - val_acc: 0.5000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.4425 - acc: 0.9167 - val_loss: 0.8035 - val_acc: 0.4500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3976 - acc: 0.8833 - val_loss: 0.8029 - val_acc: 0.4500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.3906 - acc: 0.9167 - val_loss: 0.8026 - val_acc: 0.5000\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.4026 - acc: 0.9167 - val_loss: 0.8021 - val_acc: 0.5000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.3887 - acc: 0.9000 - val_loss: 0.8001 - val_acc: 0.5000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.3699 - acc: 0.9000 - val_loss: 0.8005 - val_acc: 0.5000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.3806 - acc: 0.9000 - val_loss: 0.8016 - val_acc: 0.4500\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3856 - acc: 0.9000 - val_loss: 0.8035 - val_acc: 0.5000\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3644 - acc: 0.9000 - val_loss: 0.8049 - val_acc: 0.5000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.3953 - acc: 0.8833 - val_loss: 0.8023 - val_acc: 0.4500\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3573 - acc: 0.9500 - val_loss: 0.8062 - val_acc: 0.5000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.3585 - acc: 0.9667 - val_loss: 0.8111 - val_acc: 0.5000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3668 - acc: 0.9667 - val_loss: 0.8121 - val_acc: 0.5000\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3948 - acc: 0.9000 - val_loss: 0.8129 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3682 - acc: 0.9333 - val_loss: 0.8118 - val_acc: 0.5000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.3580 - acc: 0.9500 - val_loss: 0.8120 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 582us/sample - loss: 0.3630 - acc: 0.9167 - val_loss: 0.8100 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.3720 - acc: 0.9000 - val_loss: 0.8104 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.3569 - acc: 0.9500 - val_loss: 0.8159 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3736 - acc: 0.9000 - val_loss: 0.8136 - val_acc: 0.5000\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.3691 - acc: 0.9167 - val_loss: 0.8127 - val_acc: 0.5000\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.3368 - acc: 0.9333 - val_loss: 0.8143 - val_acc: 0.5500\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.3710 - acc: 0.9167 - val_loss: 0.8173 - val_acc: 0.5500\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3804 - acc: 0.9333 - val_loss: 0.8190 - val_acc: 0.5500\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.3588 - acc: 0.9500 - val_loss: 0.8209 - val_acc: 0.5500\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.3741 - acc: 0.9333 - val_loss: 0.8248 - val_acc: 0.5500\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3458 - acc: 0.9167 - val_loss: 0.8277 - val_acc: 0.5500\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.3503 - acc: 0.9500 - val_loss: 0.8319 - val_acc: 0.5500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.3702 - acc: 0.9167 - val_loss: 0.8334 - val_acc: 0.5500\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.3416 - acc: 0.9333 - val_loss: 0.8304 - val_acc: 0.5500\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.3510 - acc: 0.9500 - val_loss: 0.8255 - val_acc: 0.5000\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.3238 - acc: 0.9833 - val_loss: 0.8243 - val_acc: 0.5000\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3653 - acc: 0.8667 - val_loss: 0.8254 - val_acc: 0.5000\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3828 - acc: 0.9167 - val_loss: 0.8262 - val_acc: 0.5500\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.3598 - acc: 0.9333 - val_loss: 0.8241 - val_acc: 0.5500\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.3435 - acc: 0.9333 - val_loss: 0.8264 - val_acc: 0.5500\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3457 - acc: 0.9500 - val_loss: 0.8250 - val_acc: 0.5500\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.3512 - acc: 0.9167 - val_loss: 0.8339 - val_acc: 0.5500\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.3217 - acc: 0.9667 - val_loss: 0.8372 - val_acc: 0.5500\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.3382 - acc: 0.9167 - val_loss: 0.8381 - val_acc: 0.5500\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.3380 - acc: 0.9333 - val_loss: 0.8396 - val_acc: 0.5500\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.3223 - acc: 0.9667 - val_loss: 0.8361 - val_acc: 0.5500\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 720us/sample - loss: 0.3759 - acc: 0.8833 - val_loss: 0.8382 - val_acc: 0.5500\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.3171 - acc: 0.9500 - val_loss: 0.8396 - val_acc: 0.5500\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.3160 - acc: 0.9500 - val_loss: 0.8465 - val_acc: 0.5500\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.3390 - acc: 0.9167 - val_loss: 0.8561 - val_acc: 0.5500\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.3524 - acc: 0.9167 - val_loss: 0.8571 - val_acc: 0.5000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.3406 - acc: 0.9167 - val_loss: 0.8559 - val_acc: 0.5000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.3442 - acc: 0.9500 - val_loss: 0.8618 - val_acc: 0.5000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.3249 - acc: 0.9500 - val_loss: 0.8611 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.3416 - acc: 0.9167 - val_loss: 0.8612 - val_acc: 0.5000\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3547 - acc: 0.9667 - val_loss: 0.8593 - val_acc: 0.5000\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3381 - acc: 0.9167 - val_loss: 0.8711 - val_acc: 0.5000\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3458 - acc: 0.9333 - val_loss: 0.8812 - val_acc: 0.5000\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.3032 - acc: 0.9333 - val_loss: 0.8895 - val_acc: 0.5000\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3384 - acc: 0.9333 - val_loss: 0.8954 - val_acc: 0.5000\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.3454 - acc: 0.9333 - val_loss: 0.8974 - val_acc: 0.5000\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.3198 - acc: 0.9500 - val_loss: 0.8903 - val_acc: 0.5000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3116 - acc: 0.9333 - val_loss: 0.8821 - val_acc: 0.5000\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.3182 - acc: 0.9500 - val_loss: 0.8765 - val_acc: 0.5500\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.3102 - acc: 0.9333 - val_loss: 0.8709 - val_acc: 0.5500\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.3387 - acc: 0.9333 - val_loss: 0.8790 - val_acc: 0.5500\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.2722 - acc: 0.9833 - val_loss: 0.8836 - val_acc: 0.5500\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3181 - acc: 0.9500 - val_loss: 0.8877 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.3101 - acc: 0.9500 - val_loss: 0.8817 - val_acc: 0.5500\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2907 - acc: 0.9833 - val_loss: 0.8844 - val_acc: 0.5500\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 584us/sample - loss: 0.3137 - acc: 0.9000 - val_loss: 0.8938 - val_acc: 0.5000\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3229 - acc: 0.9333 - val_loss: 0.8974 - val_acc: 0.5000\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.3296 - acc: 0.9667 - val_loss: 0.9074 - val_acc: 0.5000\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2761 - acc: 1.0000 - val_loss: 0.9125 - val_acc: 0.5000\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2933 - acc: 0.9333 - val_loss: 0.9181 - val_acc: 0.5000\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.3182 - acc: 0.9333 - val_loss: 0.9143 - val_acc: 0.5000\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2926 - acc: 0.9500 - val_loss: 0.9058 - val_acc: 0.5000\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.3007 - acc: 0.9667 - val_loss: 0.9022 - val_acc: 0.5000\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.3309 - acc: 0.9333 - val_loss: 0.8975 - val_acc: 0.5000\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2865 - acc: 0.9500 - val_loss: 0.8764 - val_acc: 0.5000\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2590 - acc: 0.9667 - val_loss: 0.8610 - val_acc: 0.5500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2919 - acc: 0.9333 - val_loss: 0.8609 - val_acc: 0.5500\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2844 - acc: 0.9667 - val_loss: 0.8650 - val_acc: 0.5500\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.2650 - acc: 0.9833 - val_loss: 0.8835 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2723 - acc: 0.9833 - val_loss: 0.8939 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2709 - acc: 0.9333 - val_loss: 0.9037 - val_acc: 0.5000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.2845 - acc: 0.9500 - val_loss: 0.9102 - val_acc: 0.5000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.2697 - acc: 0.9833 - val_loss: 0.9127 - val_acc: 0.5000\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.3017 - acc: 0.9833 - val_loss: 0.9077 - val_acc: 0.5000\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.3072 - acc: 0.9333 - val_loss: 0.9079 - val_acc: 0.5000\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.2690 - acc: 0.9833 - val_loss: 0.8987 - val_acc: 0.5000\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.2613 - acc: 0.9667 - val_loss: 0.9016 - val_acc: 0.5000\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2665 - acc: 0.9500 - val_loss: 0.9115 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.2637 - acc: 0.9833 - val_loss: 0.9169 - val_acc: 0.5000\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2828 - acc: 0.9500 - val_loss: 0.9280 - val_acc: 0.5000\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2892 - acc: 0.9500 - val_loss: 0.9426 - val_acc: 0.5000\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.3139 - acc: 0.9167 - val_loss: 0.9517 - val_acc: 0.5000\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2559 - acc: 0.9500 - val_loss: 0.9504 - val_acc: 0.5000\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.3072 - acc: 0.9167 - val_loss: 0.9455 - val_acc: 0.5000\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.3085 - acc: 0.9500 - val_loss: 0.9322 - val_acc: 0.5000\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.2626 - acc: 0.9500 - val_loss: 0.9242 - val_acc: 0.5000\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2288 - acc: 0.9833 - val_loss: 0.9168 - val_acc: 0.5000\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.2839 - acc: 0.9500 - val_loss: 0.9228 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2602 - acc: 0.9833 - val_loss: 0.9323 - val_acc: 0.5000\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2640 - acc: 0.9667 - val_loss: 0.9441 - val_acc: 0.5000\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2378 - acc: 0.9833 - val_loss: 0.9497 - val_acc: 0.5000\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.2732 - acc: 0.9167 - val_loss: 0.9518 - val_acc: 0.5000\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.2504 - acc: 0.9833 - val_loss: 0.9511 - val_acc: 0.5000\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2561 - acc: 0.9500 - val_loss: 0.9448 - val_acc: 0.5000\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2996 - acc: 0.9500 - val_loss: 0.9388 - val_acc: 0.5000\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2439 - acc: 1.0000 - val_loss: 0.9300 - val_acc: 0.5000\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2910 - acc: 0.9167 - val_loss: 0.9306 - val_acc: 0.5000\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2568 - acc: 0.9667 - val_loss: 0.9215 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.2651 - acc: 0.9500 - val_loss: 0.9060 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2670 - acc: 0.9833 - val_loss: 0.9132 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.2729 - acc: 0.9500 - val_loss: 0.9229 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2586 - acc: 0.9500 - val_loss: 0.9203 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2564 - acc: 1.0000 - val_loss: 0.9353 - val_acc: 0.5000\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.2275 - acc: 0.9667 - val_loss: 0.9508 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 587us/sample - loss: 0.2745 - acc: 0.9500 - val_loss: 0.9732 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.2568 - acc: 0.9500 - val_loss: 0.9877 - val_acc: 0.5000\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 681us/sample - loss: 0.2741 - acc: 0.8833 - val_loss: 0.9944 - val_acc: 0.5000\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2679 - acc: 0.9833 - val_loss: 0.9888 - val_acc: 0.5000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2420 - acc: 0.9833 - val_loss: 0.9877 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2283 - acc: 1.0000 - val_loss: 0.9841 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.2413 - acc: 0.9667 - val_loss: 0.9942 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2307 - acc: 0.9833 - val_loss: 1.0118 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2921 - acc: 0.9000 - val_loss: 1.0116 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2340 - acc: 0.9667 - val_loss: 1.0182 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2591 - acc: 0.9333 - val_loss: 1.0273 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2105 - acc: 0.9833 - val_loss: 1.0341 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2494 - acc: 1.0000 - val_loss: 1.0451 - val_acc: 0.5000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2505 - acc: 0.9667 - val_loss: 1.0440 - val_acc: 0.5000\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2441 - acc: 0.9500 - val_loss: 1.0290 - val_acc: 0.5000\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 587us/sample - loss: 0.2370 - acc: 0.9667 - val_loss: 1.0386 - val_acc: 0.5000\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2305 - acc: 0.9833 - val_loss: 1.0477 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2411 - acc: 1.0000 - val_loss: 1.0591 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.2539 - acc: 0.9833 - val_loss: 1.0714 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 587us/sample - loss: 0.2655 - acc: 0.9500 - val_loss: 1.0651 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.2573 - acc: 0.9333 - val_loss: 1.0593 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.3082 - acc: 0.9333 - val_loss: 1.0405 - val_acc: 0.5000\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.2227 - acc: 1.0000 - val_loss: 1.0476 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2272 - acc: 0.9667 - val_loss: 1.0403 - val_acc: 0.5000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2209 - acc: 1.0000 - val_loss: 1.0512 - val_acc: 0.5000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1880 - acc: 1.0000 - val_loss: 1.0573 - val_acc: 0.5000\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 584us/sample - loss: 0.2327 - acc: 0.9500 - val_loss: 1.0654 - val_acc: 0.5000\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 784us/sample - loss: 0.2411 - acc: 0.9667 - val_loss: 1.0902 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2223 - acc: 0.9667 - val_loss: 1.1087 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.2213 - acc: 0.9833 - val_loss: 1.1077 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2331 - acc: 0.9833 - val_loss: 1.1042 - val_acc: 0.5000\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2705 - acc: 0.8833 - val_loss: 1.0837 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.2303 - acc: 0.9500 - val_loss: 1.0751 - val_acc: 0.5000\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2241 - acc: 0.9833 - val_loss: 1.0755 - val_acc: 0.5000\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2004 - acc: 1.0000 - val_loss: 1.0828 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 581us/sample - loss: 0.2376 - acc: 0.9667 - val_loss: 1.0906 - val_acc: 0.5000\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2077 - acc: 0.9833 - val_loss: 1.1025 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.2110 - acc: 0.9833 - val_loss: 1.1203 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2235 - acc: 0.9833 - val_loss: 1.1591 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 691us/sample - loss: 0.2198 - acc: 0.9833 - val_loss: 1.1723 - val_acc: 0.5000\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2075 - acc: 0.9833 - val_loss: 1.1457 - val_acc: 0.5000\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.2211 - acc: 0.9667 - val_loss: 1.1149 - val_acc: 0.5000\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2091 - acc: 0.9667 - val_loss: 1.0936 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2206 - acc: 0.9667 - val_loss: 1.0978 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2301 - acc: 0.9500 - val_loss: 1.1391 - val_acc: 0.5000\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.2501 - acc: 0.9500 - val_loss: 1.1439 - val_acc: 0.5000\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2337 - acc: 0.9500 - val_loss: 1.1313 - val_acc: 0.5000\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2120 - acc: 0.9333 - val_loss: 1.1230 - val_acc: 0.5000\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.2416 - acc: 0.9333 - val_loss: 1.1442 - val_acc: 0.5000\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2030 - acc: 0.9833 - val_loss: 1.1696 - val_acc: 0.5000\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 708us/sample - loss: 0.1963 - acc: 0.9833 - val_loss: 1.1890 - val_acc: 0.5000\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2295 - acc: 0.9667 - val_loss: 1.2159 - val_acc: 0.5000\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.2329 - acc: 0.9833 - val_loss: 1.2272 - val_acc: 0.5000\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1915 - acc: 1.0000 - val_loss: 1.2017 - val_acc: 0.5000\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2592 - acc: 0.9500 - val_loss: 1.1840 - val_acc: 0.5000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 583us/sample - loss: 0.2158 - acc: 0.9833 - val_loss: 1.1910 - val_acc: 0.5000\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1846 - acc: 0.9833 - val_loss: 1.2195 - val_acc: 0.5000\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2308 - acc: 0.9333 - val_loss: 1.2511 - val_acc: 0.5000\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.2021 - acc: 0.9833 - val_loss: 1.2810 - val_acc: 0.5000\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.2167 - acc: 0.9833 - val_loss: 1.2965 - val_acc: 0.5000\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2246 - acc: 0.9667 - val_loss: 1.3038 - val_acc: 0.5000\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.1989 - acc: 0.9833 - val_loss: 1.3457 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2174 - acc: 0.9667 - val_loss: 1.3442 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2103 - acc: 0.9500 - val_loss: 1.3131 - val_acc: 0.5000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 574us/sample - loss: 0.2298 - acc: 0.9500 - val_loss: 1.2804 - val_acc: 0.5000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1834 - acc: 0.9667 - val_loss: 1.2886 - val_acc: 0.5000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1946 - acc: 0.9667 - val_loss: 1.3136 - val_acc: 0.5000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.1985 - acc: 1.0000 - val_loss: 1.3382 - val_acc: 0.5000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2050 - acc: 0.9667 - val_loss: 1.3765 - val_acc: 0.5000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2032 - acc: 0.9667 - val_loss: 1.4055 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2485 - acc: 0.9500 - val_loss: 1.3832 - val_acc: 0.5000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2249 - acc: 0.9500 - val_loss: 1.3382 - val_acc: 0.5000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.2311 - acc: 0.9667 - val_loss: 1.2759 - val_acc: 0.5000\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.2369 - acc: 0.9333 - val_loss: 1.2464 - val_acc: 0.5000\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 575us/sample - loss: 0.1950 - acc: 0.9667 - val_loss: 1.2397 - val_acc: 0.5000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.2247 - acc: 0.9500 - val_loss: 1.2137 - val_acc: 0.5000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.2103 - acc: 0.9833 - val_loss: 1.1738 - val_acc: 0.5000\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2204 - acc: 0.9833 - val_loss: 1.1489 - val_acc: 0.5000\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1949 - acc: 0.9833 - val_loss: 1.1170 - val_acc: 0.5500\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.2033 - acc: 0.9667 - val_loss: 1.1085 - val_acc: 0.5500\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.2109 - acc: 0.9667 - val_loss: 1.1143 - val_acc: 0.5500\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.2341 - acc: 0.9333 - val_loss: 1.1118 - val_acc: 0.5500\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2242 - acc: 0.9167 - val_loss: 1.1045 - val_acc: 0.5500\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1865 - acc: 0.9833 - val_loss: 1.1207 - val_acc: 0.5500\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1736 - acc: 1.0000 - val_loss: 1.1307 - val_acc: 0.5500\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2135 - acc: 0.9667 - val_loss: 1.1511 - val_acc: 0.5500\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.1973 - acc: 0.9833 - val_loss: 1.1747 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1858 - acc: 0.9667 - val_loss: 1.1823 - val_acc: 0.5000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1528 - acc: 1.0000 - val_loss: 1.1746 - val_acc: 0.5000\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.1705 - acc: 1.0000 - val_loss: 1.1594 - val_acc: 0.5000\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.2120 - acc: 0.9500 - val_loss: 1.1406 - val_acc: 0.5500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.1905 - acc: 0.9667 - val_loss: 1.1357 - val_acc: 0.5500\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1743 - acc: 0.9667 - val_loss: 1.1226 - val_acc: 0.5500\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1967 - acc: 0.9667 - val_loss: 1.1042 - val_acc: 0.5500\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1963 - acc: 0.9833 - val_loss: 1.1084 - val_acc: 0.5500\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.2229 - acc: 0.9667 - val_loss: 1.1035 - val_acc: 0.5500\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1805 - acc: 0.9833 - val_loss: 1.1168 - val_acc: 0.5500\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1931 - acc: 0.9667 - val_loss: 1.1356 - val_acc: 0.5000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1904 - acc: 0.9667 - val_loss: 1.1458 - val_acc: 0.5000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2281 - acc: 0.9500 - val_loss: 1.1429 - val_acc: 0.5500\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1519 - acc: 0.9667 - val_loss: 1.1560 - val_acc: 0.5000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.2112 - acc: 0.9667 - val_loss: 1.1837 - val_acc: 0.5000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.2116 - acc: 0.9333 - val_loss: 1.2394 - val_acc: 0.5000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1685 - acc: 0.9833 - val_loss: 1.2943 - val_acc: 0.5000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1569 - acc: 1.0000 - val_loss: 1.3240 - val_acc: 0.5000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2360 - acc: 0.9333 - val_loss: 1.3513 - val_acc: 0.5000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1987 - acc: 0.9833 - val_loss: 1.3382 - val_acc: 0.5000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2001 - acc: 0.9667 - val_loss: 1.3409 - val_acc: 0.5000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.2003 - acc: 0.9500 - val_loss: 1.3197 - val_acc: 0.5000\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1752 - acc: 0.9833 - val_loss: 1.2879 - val_acc: 0.5000\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1595 - acc: 0.9667 - val_loss: 1.2788 - val_acc: 0.5000\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.2128 - acc: 0.9333 - val_loss: 1.2818 - val_acc: 0.5000\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1415 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.5000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1715 - acc: 1.0000 - val_loss: 1.3061 - val_acc: 0.5000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1860 - acc: 0.9833 - val_loss: 1.3225 - val_acc: 0.5000\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1895 - acc: 0.9833 - val_loss: 1.3124 - val_acc: 0.5000\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.1910 - acc: 0.9667 - val_loss: 1.3036 - val_acc: 0.5000\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1811 - acc: 0.9667 - val_loss: 1.3059 - val_acc: 0.5000\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1662 - acc: 0.9833 - val_loss: 1.2947 - val_acc: 0.5000\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1550 - acc: 1.0000 - val_loss: 1.3129 - val_acc: 0.5000\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 592us/sample - loss: 0.1456 - acc: 1.0000 - val_loss: 1.3395 - val_acc: 0.5000\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.1725 - acc: 0.9833 - val_loss: 1.3573 - val_acc: 0.5000\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1715 - acc: 0.9833 - val_loss: 1.3424 - val_acc: 0.5000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1653 - acc: 0.9667 - val_loss: 1.3264 - val_acc: 0.5000\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1819 - acc: 0.9833 - val_loss: 1.3008 - val_acc: 0.5000\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 571us/sample - loss: 0.1622 - acc: 0.9667 - val_loss: 1.3263 - val_acc: 0.5000\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 582us/sample - loss: 0.1655 - acc: 0.9667 - val_loss: 1.3303 - val_acc: 0.5000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.1853 - acc: 0.9500 - val_loss: 1.3206 - val_acc: 0.5000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1489 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1734 - acc: 0.9833 - val_loss: 1.3079 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1645 - acc: 0.9833 - val_loss: 1.3449 - val_acc: 0.5000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1503 - acc: 0.9833 - val_loss: 1.3863 - val_acc: 0.5000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 584us/sample - loss: 0.1484 - acc: 0.9833 - val_loss: 1.3963 - val_acc: 0.5000\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1806 - acc: 0.9667 - val_loss: 1.3978 - val_acc: 0.5000\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1864 - acc: 0.9833 - val_loss: 1.3338 - val_acc: 0.5000\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1577 - acc: 0.9667 - val_loss: 1.2941 - val_acc: 0.5500\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2044 - acc: 0.9500 - val_loss: 1.2607 - val_acc: 0.5500\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1822 - acc: 0.9667 - val_loss: 1.2337 - val_acc: 0.5500\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1612 - acc: 1.0000 - val_loss: 1.2342 - val_acc: 0.5500\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1820 - acc: 0.9667 - val_loss: 1.2778 - val_acc: 0.5000\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1542 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.5000\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1828 - acc: 0.9667 - val_loss: 1.3573 - val_acc: 0.5000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1614 - acc: 0.9833 - val_loss: 1.3541 - val_acc: 0.5000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1457 - acc: 1.0000 - val_loss: 1.3311 - val_acc: 0.5000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1702 - acc: 0.9667 - val_loss: 1.3320 - val_acc: 0.5000\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1675 - acc: 0.9667 - val_loss: 1.3058 - val_acc: 0.5000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1612 - acc: 1.0000 - val_loss: 1.2589 - val_acc: 0.5000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1294 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.5500\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1588 - acc: 0.9833 - val_loss: 1.1551 - val_acc: 0.5500\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.1545 - acc: 1.0000 - val_loss: 1.1485 - val_acc: 0.5500\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1639 - acc: 0.9833 - val_loss: 1.1453 - val_acc: 0.5500\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.1586 - acc: 0.9833 - val_loss: 1.1757 - val_acc: 0.5500\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 740us/sample - loss: 0.1341 - acc: 0.9833 - val_loss: 1.2131 - val_acc: 0.5500\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.1721 - acc: 0.9833 - val_loss: 1.2321 - val_acc: 0.5500\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1298 - acc: 1.0000 - val_loss: 1.2424 - val_acc: 0.5500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.1524 - acc: 0.9833 - val_loss: 1.2577 - val_acc: 0.5500\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1690 - acc: 0.9833 - val_loss: 1.2956 - val_acc: 0.5000\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1582 - acc: 0.9833 - val_loss: 1.2920 - val_acc: 0.5000\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1275 - acc: 0.9833 - val_loss: 1.2663 - val_acc: 0.5500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1714 - acc: 0.9667 - val_loss: 1.2581 - val_acc: 0.5500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.1629 - acc: 0.9667 - val_loss: 1.2547 - val_acc: 0.5500\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 699us/sample - loss: 0.1652 - acc: 0.9500 - val_loss: 1.2499 - val_acc: 0.5500\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.1627 - acc: 0.9333 - val_loss: 1.2450 - val_acc: 0.5500\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1473 - acc: 0.9833 - val_loss: 1.2619 - val_acc: 0.5500\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.1475 - acc: 0.9667 - val_loss: 1.2823 - val_acc: 0.5500\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 589us/sample - loss: 0.1493 - acc: 0.9667 - val_loss: 1.2653 - val_acc: 0.5500\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1509 - acc: 0.9667 - val_loss: 1.2228 - val_acc: 0.5500\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1721 - acc: 1.0000 - val_loss: 1.1816 - val_acc: 0.5500\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1577 - acc: 0.9833 - val_loss: 1.1511 - val_acc: 0.5500\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 581us/sample - loss: 0.1447 - acc: 0.9667 - val_loss: 1.1301 - val_acc: 0.5500\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.2040 - acc: 0.9333 - val_loss: 1.1154 - val_acc: 0.5500\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1229 - acc: 1.0000 - val_loss: 1.1068 - val_acc: 0.5500\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1456 - acc: 1.0000 - val_loss: 1.1216 - val_acc: 0.5500\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1483 - acc: 0.9667 - val_loss: 1.1622 - val_acc: 0.5500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1560 - acc: 1.0000 - val_loss: 1.2236 - val_acc: 0.5500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 731us/sample - loss: 0.1552 - acc: 1.0000 - val_loss: 1.2513 - val_acc: 0.5500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1812 - acc: 0.9333 - val_loss: 1.2358 - val_acc: 0.5500\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.2493 - acc: 0.8667 - val_loss: 1.2040 - val_acc: 0.5500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1705 - acc: 0.9833 - val_loss: 1.1853 - val_acc: 0.5500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1435 - acc: 0.9833 - val_loss: 1.1406 - val_acc: 0.5500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1155 - acc: 1.0000 - val_loss: 1.0860 - val_acc: 0.5500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1386 - acc: 1.0000 - val_loss: 1.0561 - val_acc: 0.5500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 1.0468 - val_acc: 0.5500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1378 - acc: 1.0000 - val_loss: 1.0369 - val_acc: 0.5500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.1484 - acc: 0.9667 - val_loss: 1.0320 - val_acc: 0.5500\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1281 - acc: 0.9833 - val_loss: 1.0638 - val_acc: 0.5500\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1471 - acc: 0.9833 - val_loss: 1.0869 - val_acc: 0.5500\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 584us/sample - loss: 0.1516 - acc: 0.9833 - val_loss: 1.1168 - val_acc: 0.5500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1343 - acc: 0.9833 - val_loss: 1.1469 - val_acc: 0.5500\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 589us/sample - loss: 0.1771 - acc: 0.9333 - val_loss: 1.1556 - val_acc: 0.5500\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1239 - acc: 0.9833 - val_loss: 1.1951 - val_acc: 0.5500\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1207 - acc: 1.0000 - val_loss: 1.2612 - val_acc: 0.5500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1513 - acc: 0.9667 - val_loss: 1.3067 - val_acc: 0.5500\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1212 - acc: 1.0000 - val_loss: 1.3312 - val_acc: 0.5500\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.1414 - acc: 0.9500 - val_loss: 1.3338 - val_acc: 0.5500\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1589 - acc: 0.9833 - val_loss: 1.3158 - val_acc: 0.5500\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1633 - acc: 0.9667 - val_loss: 1.2382 - val_acc: 0.5500\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1070 - acc: 1.0000 - val_loss: 1.1936 - val_acc: 0.5500\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1080 - acc: 1.0000 - val_loss: 1.1728 - val_acc: 0.5500\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1355 - acc: 0.9667 - val_loss: 1.1498 - val_acc: 0.5500\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1507 - acc: 0.9667 - val_loss: 1.1457 - val_acc: 0.5500\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1704 - acc: 0.9333 - val_loss: 1.1546 - val_acc: 0.5500\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1570 - acc: 0.9667 - val_loss: 1.1366 - val_acc: 0.6000\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1243 - acc: 1.0000 - val_loss: 1.1258 - val_acc: 0.6000\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1513 - acc: 0.9833 - val_loss: 1.1207 - val_acc: 0.6000\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1453 - acc: 0.9833 - val_loss: 1.1108 - val_acc: 0.6000\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1127 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.6000\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.1171 - acc: 0.9667 - val_loss: 1.0667 - val_acc: 0.6000\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1375 - acc: 0.9833 - val_loss: 1.0443 - val_acc: 0.6000\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1370 - acc: 1.0000 - val_loss: 1.0306 - val_acc: 0.6000\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1553 - acc: 0.9833 - val_loss: 1.0262 - val_acc: 0.6000\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1522 - acc: 0.9667 - val_loss: 1.0363 - val_acc: 0.6000\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1319 - acc: 0.9833 - val_loss: 1.0561 - val_acc: 0.6000\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.1251 - acc: 1.0000 - val_loss: 1.0812 - val_acc: 0.6000\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.1037 - acc: 1.0000 - val_loss: 1.1041 - val_acc: 0.6000\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1328 - acc: 0.9833 - val_loss: 1.1326 - val_acc: 0.6000\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1372 - acc: 0.9833 - val_loss: 1.1679 - val_acc: 0.6000\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1579 - acc: 0.9667 - val_loss: 1.1660 - val_acc: 0.6000\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.1513 - acc: 0.9667 - val_loss: 1.1817 - val_acc: 0.6000\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1098 - acc: 1.0000 - val_loss: 1.1987 - val_acc: 0.6000\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.1285 - acc: 1.0000 - val_loss: 1.2204 - val_acc: 0.6000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1809 - acc: 0.9667 - val_loss: 1.2104 - val_acc: 0.6000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 1.2171 - val_acc: 0.6000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1178 - acc: 1.0000 - val_loss: 1.2131 - val_acc: 0.6000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1242 - acc: 1.0000 - val_loss: 1.2316 - val_acc: 0.6000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 673us/sample - loss: 0.1518 - acc: 0.9667 - val_loss: 1.2154 - val_acc: 0.6000\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0989 - acc: 1.0000 - val_loss: 1.2127 - val_acc: 0.6000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1310 - acc: 0.9667 - val_loss: 1.2216 - val_acc: 0.6000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1291 - acc: 0.9833 - val_loss: 1.2094 - val_acc: 0.6000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1364 - acc: 0.9833 - val_loss: 1.1919 - val_acc: 0.6000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1453 - acc: 0.9833 - val_loss: 1.2023 - val_acc: 0.6000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0999 - acc: 1.0000 - val_loss: 1.2466 - val_acc: 0.5500\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2135 - acc: 0.9167 - val_loss: 1.2961 - val_acc: 0.5500\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1228 - acc: 0.9833 - val_loss: 1.3126 - val_acc: 0.5500\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1328 - acc: 0.9833 - val_loss: 1.3211 - val_acc: 0.5500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1292 - acc: 0.9833 - val_loss: 1.2969 - val_acc: 0.5500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.1540 - acc: 0.9500 - val_loss: 1.2590 - val_acc: 0.5500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1338 - acc: 0.9833 - val_loss: 1.2351 - val_acc: 0.5500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1140 - acc: 1.0000 - val_loss: 1.2225 - val_acc: 0.5500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 704us/sample - loss: 0.1143 - acc: 1.0000 - val_loss: 1.2465 - val_acc: 0.5500\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0983 - acc: 1.0000 - val_loss: 1.3253 - val_acc: 0.5500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1171 - acc: 1.0000 - val_loss: 1.3664 - val_acc: 0.5500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 849us/sample - loss: 0.1438 - acc: 0.9667 - val_loss: 1.3656 - val_acc: 0.5500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 599us/sample - loss: 0.1422 - acc: 0.9667 - val_loss: 1.3395 - val_acc: 0.5500\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1398 - acc: 0.9667 - val_loss: 1.3199 - val_acc: 0.5500\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.1240 - acc: 0.9833 - val_loss: 1.2867 - val_acc: 0.5500\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 1.2650 - val_acc: 0.5500\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.1245 - acc: 0.9833 - val_loss: 1.2734 - val_acc: 0.5500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1270 - acc: 0.9833 - val_loss: 1.3146 - val_acc: 0.5500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 589us/sample - loss: 0.0840 - acc: 1.0000 - val_loss: 1.3587 - val_acc: 0.5500\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1162 - acc: 0.9833 - val_loss: 1.4104 - val_acc: 0.5500\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.1178 - acc: 1.0000 - val_loss: 1.4613 - val_acc: 0.5000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1489 - acc: 1.0000 - val_loss: 1.4626 - val_acc: 0.5500\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 689us/sample - loss: 0.1293 - acc: 0.9833 - val_loss: 1.4264 - val_acc: 0.5500\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1814 - acc: 0.9333 - val_loss: 1.3992 - val_acc: 0.5500\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1303 - acc: 0.9833 - val_loss: 1.3673 - val_acc: 0.5500\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.1128 - acc: 0.9667 - val_loss: 1.3591 - val_acc: 0.5500\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.1084 - acc: 0.9833 - val_loss: 1.3811 - val_acc: 0.5500\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.1183 - acc: 1.0000 - val_loss: 1.4202 - val_acc: 0.5000\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1294 - acc: 0.9833 - val_loss: 1.4410 - val_acc: 0.5000\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 1.4758 - val_acc: 0.5000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1294 - acc: 0.9667 - val_loss: 1.4974 - val_acc: 0.5000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1352 - acc: 0.9833 - val_loss: 1.5070 - val_acc: 0.5000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1425 - acc: 0.9667 - val_loss: 1.5348 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd3gc1bn/P++upFW3LMmWbcm2XGQb\nd4wxzXTTDMG5oQQIIRC4QEILJfmRmwYkN+WmAuEmlySQQBIIIQ0IhE4oCdi4YLDBvcldsq3eVnt+\nf8zM7uxqdiVLWrV9P8+jR7szZ2bO7M6e7znv+573iDEGRVEUJXXx9XcFFEVRlP5FhUBRFCXFUSFQ\nFEVJcVQIFEVRUhwVAkVRlBRHhUBRFCXFUSFQUgIRKRcRIyJpXSh7pYi82Rf1UpSBgAqBMuAQka0i\n0ioixTHbV9qNeXn/1ExRhiYqBMpAZQtwqfNGRGYB2f1XnYFBV0Y0inK4qBAoA5VHgStc7z8DPOIu\nICLDROQREdkvIttE5Ksi4rP3+UXkByJSJSKbgXM9jv2ViOwWkZ0i8i0R8XelYiLyRxHZIyI1IvK6\niMxw7csSkR/a9akRkTdFJMvet1BE/iUih0Rkh4hcaW9/TUSucZ0jyjRlj4JuEJENwAZ72732OWpF\nZLmInOgq7xeR/xKRTSJSZ+8fKyIPiMgPY+7lKRG5tSv3rQxdVAiUgcrbQL6IHGE30JcAv40pcz8w\nDJgInIwlHFfZ+/4TOA84EpgPXBhz7K+BIDDZLnMmcA1d4zmgAhgJrAB+59r3A+Ao4HigEPgSEBKR\n8fZx9wMjgLnAqi5eD+DjwDHAdPv9MvschcDvgT+KSKa97zas0dRiIB/4LNAI/Aa41CWWxcAi+3gl\nlTHG6J/+Dag/YCtWA/VV4DvA2cCLQBpggHLAD7QC013HXQe8Zr9+Bbjete9M+9g0oARoAbJc+y8F\nXrVfXwm82cW6FtjnHYbVsWoC5niU+zLwlzjneA24xvU+6vr2+U/rpB4HnesC64Alccp9CJxhv74R\neLa/v2/96/8/tTcqA5lHgdeBCcSYhYBiIB3Y5tq2DSi1X48BdsTscxhvH7tbRJxtvpjyntijk/8G\nLsLq2Ydc9QkAmcAmj0PHxtneVaLqJiJ3AFdj3afB6vk7zvVE1/oNcDmWsF4O3NuDOilDBDUNKQMW\nY8w2LKfxYuDPMburgDasRt1hHLDTfr0bq0F073PYgTUiKDbGFNh/+caYGXTOZcASrBHLMKzRCYDY\ndWoGJnkctyPOdoAGoh3hozzKhNME2/6ALwEXA8ONMQVAjV2Hzq71W2CJiMwBjgD+GqeckkKoECgD\nnauxzCIN7o3GmHbgCeC/RSTPtsHfRsSP8ARws4iUichw4E7XsbuBF4Afiki+iPhEZJKInNyF+uRh\niUg1VuP9bdd5Q8BDwI9EZIzttD1ORAJYfoRFInKxiKSJSJGIzLUPXQV8QkSyRWSyfc+d1SEI7AfS\nROTrWCMCh18C3xSRCrGYLSJFdh0rsfwLjwJ/MsY0deGelSGOCoEyoDHGbDLGvBtn901YvenNwJtY\nTs+H7H2/AJ4H3sNy6MaOKK4AMoC1WPb1J4HRXajSI1hmpp32sW/H7L8DeB+rsT0AfA/wGWO2Y41s\nbre3rwLm2Mf8GMvfsRfLdPM7EvM88A9gvV2XZqJNRz/CEsIXgFrgV0CWa/9vgFlYYqAoiDG6MI2i\npBIichLWyGm80QZAQUcEipJSiEg6cAvwSxUBxUGFQFFSBBE5AjiEZQL7ST9XRxlAqGlIURQlxdER\ngaIoSooz6CaUFRcXm/Ly8v6uhqIoyqBi+fLlVcaYEV77Bp0QlJeX8+678aIJFUVRFC9EZFu8fWoa\nUhRFSXFUCBRFUVIcFQJFUZQUZ9D5CLxoa2ujsrKS5ubm/q5Kn5GZmUlZWRnp6en9XRVFUQY5Q0II\nKisrycvLo7y8HFda4SGLMYbq6moqKyuZMGFCf1dHUZRBTtJMQyLykIjsE5EP4uwXEblPRDaKyGoR\nmdfdazU3N1NUVJQSIgAgIhQVFaXUCEhRlOSRTB/Br7FWlorHOVjL/VUA1wI/68nFUkUEHFLtfhVF\nSR5JMw0ZY14XkfIERZYAj9iJr94WkQIRGW3nileUhOw40MjG/fWcOnVkr5/7xbV7mV02jJJ8awng\n9ytrCIZCHDluOABV9S28s/kA5862slaHQoYnl1dy/twxBNJ8PLm8knNmjSY3kMbfVu3EGNhb28xV\nJ0wgIy3S91qx/SDpPh+zyoZ1WqdQyPDkikrOnzOGzHS/Z5kNe+vYX9/C8ZOKPfc7tAZD/HlFJRfN\nH8tbG6tYs6uWq04oj3tegKfe28WJk4sZnpMBQHvI8PBbWygbnsXZM63P4bn3d7PzUBNXnTABv8/q\nqBxoaOWtjVV8bM6YqPM1tbbzzOpd+H3CKVNH8uLaPZw0ZQRPLKukvDibopwACyuK2VrVwJbqhrjf\n8/q9dVTXt3J0+XAefmsrw7LT2VvTzPGTizlq/HBWbD/Iax/tA+Bjc8ZQUZIXPvYfH1hNzdjCbMqG\nZ/Pov7eyYEIRCyYUsnZXLQ2tQdqCIUbkBVi/t56jJwyntqmNZ1bv5oJ5ZYwtzA7fc0aaj6q6FipK\n8hiRF+DYiUVs2l/P7kPNLKywvo/a5jYe+ddWWoMhJo3MZcncUvbXtfDOlmqmluSxdnct26obOWnK\nCOaOLcAYwx+XV5IbSGPGmHzGF+Uk/F57Qn/6CEqJzqFeaW/rIAQici3WqIFx48bF7u53qqurOf30\n0wHYs2cPfr+fESOsCXxLly4lIyOj03NcddVV3HnnnUydOjWpdR0qPPj6Zv62aier7zqrV8/b1h7i\nPx95l0kjcnj59lMA+NhP3wRg63fPBeAzDy1lza5aFk4+k2HZ6Ty9ehdf+tNq9tY2c8zEIr745GpW\nbD/E506exC2PR9annzO2gGMnFoXff+J//xV13kQs336QLz25mrxAGufM8l424Ywfv96l8/3stU38\n+KX1ZAfSuO0PqwiGDEeMzuOUOI3tuj113PzYSs6dPZoHLrMsuGt21fCtv38IwKZvLwbgc79bAcDs\nsgIWTCgE4M4/reaFtXuZWTqMCcWRhux7//iIX/9rKwDpfqGt3XDatJG8YjfaAFu+s5jF971BY2s7\nm769OCwubu59aQPLth7g/z59FP/97Ifh7S99uJe/3biQ//77hyzfdhCAykNN/Ohiay2gmsY2rv/t\ninD5H1w0hx+8sJ4JxTm8escpLL7vjQ7XuuHUSVQebOJvq3ZxqLGNu86fEb7nWLZ+91xO/+E/w68B\n/r56Nz94YT0APoHFs0Zz/W+Xh+vn8Pr6/Tz5ueN5Z8sBvvTkagAKstNZ9fUzPa/VGwyK8FFjzIPG\nmPnGmPlOAzuQKCoqYtWqVaxatYrrr7+eW2+9NfzeEQFjDKFQKO45Hn74YRWBw2B/XQv1LUF6O2li\nQ0sQgB0H4i/ctWZXLQDVDS0AbNpvLZ7W2NZO5cFGALZVN9AW833XNrWFX7e1x38WvFi3p846R3Nb\nJyXp9DNZt9eqf1swRDBk7PMG45bfvL8esHrxDvUtkfKVBxvZVh1ZQG793rrw6xr7nrdWRy0wx85D\nkc+3rd2qw0e7a6PKVNW30mhfc8eBRs+67a9rYV9dS9T5AIIha1H29Xvq+PSx45lTNoyq+tZIHffV\nRZWvqre+S/d3FMu6PfWs31sfvsfG1vifmRfr99aRneHnniUzCBk42NjKhzH3DLC5yvqsKg9G7ulQ\nY+ffe0/oTyHYSfSasmVE1psdEmzcuJHp06fzqU99ihkzZrB7926uvfZa5s+fz4wZM7jnnnvCZRcu\nXMiqVasIBoMUFBRw5513MmfOHI477jj27duX4CqpyYGGVkIGWg+zQe2MOrtBTPd37oM50GA1LE4j\nku73sWGf1VC0BkM0t7VHlXc3nttiGsbO2Gifty5Bg+3Q2NqecH+13SAebIw0jPUJzrvFrmtpQWSR\nM/e9bdgbaSDddQUYYx+z0bUfIosru9lVEx384IgfRIuLG0eM36+sidoebDfsqW2mriXIlJJcCnMy\nOGCXdersxvkum9rif3Yf7all035HCOrDn6NDcW5k5O/+rt3XnDwyl6KcQPiaXp/DgYZWqutboj7H\nrjyPPaE/TUNPATeKyOPAMUBNb/gH7n56DWt3dVTZnjB9TD7f+FhX1jXvyEcffcQjjzzC/PnzAfju\nd79LYWEhwWCQU089lQsvvJDp06dHHVNTU8PJJ5/Md7/7XW677TYeeugh7rzzTq/T94jn1+zhqVW7\neOBT3Q7YSshPXlqPX4SbTq/o8bm+9cxaxhZm8/r6/Xzm+HKq7B91U2s7gbSIbfutjVV846k1XLNw\nAv9Ys4eq+hZyA2lcs3AiD721hV995miyMqzyb2zYz49eXE+6z0dTWzuBNB8TR1jmizS/j+fe381L\nH0ZEuLE1yBPLItbMC3/+b5Z+5XS22COCgw2t7K6xenFbqhqietBgNQ7femYt/95czcfnloa3n/L9\nV/GJkO738f2LZjO7rCC878nllfz8n5vCjcK3/v4hf14R6S8V5WZw/6VHUpAdaYSq61vJCaSFr3nF\nr97hUFMbt50xhfNmj2G/LVyOaQegrrmNmqY2bvz9Cprb2rn2pEmcMb0EiDTsj769jZml+by+voph\n2ZH5K9c88i6fO2USABUjc/n1v7ayuvIQnzpmPGm2Oef+Vzbw+LLtFGRncM7MUV5fcQdueXxl+PV/\n/eV9fvjCen78yblUlORy3aPLufG0yVTbDfh7lYeijm1sC3L9o8sBmDwyj1U7anh13X5O+8FrAB1G\nEA++vtk6rrW9g4A7OD30qSV5rNtbx3/95f2o/ZNH5lJVfwCAo7/1Unj7WT9+HRH4aE8dF8wro8gW\njF2HmuIKz/k/favDqOknL63nC4umeJbvKUkTAhF5DDgFKBaRSuAbQDqAMebnwLNYa7huBBqBq5JV\nl/5k0qRJYREAeOyxx/jVr35FMBhk165drF27toMQZGVlcc455wBw1FFH8cYbHe2VvcF19g/l/pDB\n52F/7Sk/eWkDQK8IwS/f3BJ+/a9N1QTSrcFsY2s7BdmRcs+v2cPGffX8ecVOlm49EN7+9mbr9fJt\nB8POuysfXkZ7KNqM8q5tr033+zrYf6vrW3ljQ1XUtr+t3BVuWKsbWsI94+qG1rBZxKGuORi+j2FZ\nkYZ0a3UjH5szhmdW7+KVj/ZFCcGr6/ZF9QwB1saYE55evZvLFkR8Z9UNLYwrsj6UjfvqWbHdaiSf\neW83580eQ42HmaG+JchLa/eG72/Z1nfDtu39dZGe9C/e2BJVnykluazfW89fVuyktCCLLyyawg2/\nX8GK7YdYsf0QZ8+wGv2Tp47k5Q/3sml/A8u3HeS0ad7+iIWTi5kxJp+WYIjqhlYCaT5yA2lU1bfw\nzOrdvLZ+H1kZfl75aB/v7TgUNpm8tyN6RNDUGuLDGmsUMW98Aa+tswS9oTVIc1uIlmD8kWQ8M5TD\nLYsq+PzvVnR4FiYU54SfM3cDv841mikbnkWR7XBftvUgIQPHTixkfGEOw3MymDt2GNf/dkVYBCYU\n57DFNhX95KUNg08IjDGXdrLfADf09nW723NPFjk5EQfZhg0buPfee1m6dCkFBQVcfvnlnnMB3M5l\nv99PMHh4tsjDpaE1SF7m4JmhnJnu46DdAMT2qBwTwrYD3qaXkMt+nkj6MjyG4tUNrbS2h5gxJj/s\nJxg1LDNsVtl5sIkdBxspyQ+wt7aj3XqTqwHd7TKDjC/K5v5Lj2R15aEOJotEJhuH2qa2KDOPY+aw\nXluNeEl+IGwX9+qF1jUHw2aWWNxmjlhR+tHFcznv/jfZU9vMqVNHcO7s0dzw++hj540r4P5Lj+S8\n+9/gg53W57avznsOTNnwLL68+AjPfcu3vcyGvfWcOtWqf7XrPmPvqak1SMgYPn/KJAJp/nC004kV\nI9h+oJGlWw4QD0fMv3/hbBpagtz19FqOGj887NQ9ecoIbj5tMve9sjHquOyM6Ob0a+dN55vPrI3a\nVpSbQVGuZRp6e3M1AHefP5Opo6xopj0x5rGPzy2l3Rjue9nqVB1saA3fS28yKJzFQ4Xa2lry8vLI\nz89n9+7dPP/8831eh0ONrR22edkzvaiqbwk7QzvDy2HZHjLUNLXR3NYedsq6aWsPUefhDI09V6ur\nN9fU2s6BhlaMMRxoaA03VHtrvRs1d4OZyKXaFuq490BDCy1tIXIDkR/8ocZIz/+9yhqMIRwZtPNg\ntBA898Ge8GvHhARQaP+wK0ZaIYTbqyOfcVe+mw1769i8PyJ8a3bV0hoMUdvcxqZ91vZjJxaxeX8D\n1fUtnkKwuaqBFduizSsHGlpZt6eOgw0dnxmHCcU5ZNlhp1NcoZkOa3fXhjsZ4pJeRxAcnM+0MEEj\nV1GSx2vr9nWoT15mx/5sY1s7wZAh3W81cc4zU5STQb5HeTf/3mz19ItzAxTajfYZ00tI8wmlBVnk\nBNKiwlDjEUjr2LwW5mRQkJWOT2Dl9kP4fRIVTZUbU7dJI3OifisbYoS4t1Ah6EPmzZvH9OnTmTZt\nGldccQUnnHBCn15/deUh5t7zIn9bFe2T74oD0hjDMd9+mYXfe5Vdh+JH1Dg0eDgs7356DXPufoFz\n7n2DGd/oKII3/X4ls+56ocP25rboYbx7WL+1uoFjv/0y33nuI+Z988WoyBAvYh188XCbQxz21bbQ\n0h6Kmgvwtb+t6dCwOkLgjvrIz0yLKue+JydGfvroPLZUNXDS918NR5N0ZUSwYV89n/vt8vD7H724\nniUPvMXsu14Ih1QunGyZwz71y3eI1eji3ACvr9/PP9bsido+75svctZPXmdrdXzxz0r3M3lkLgBH\njM4H4KwZJeH9Bxpaw43bCZO95zdkpvuYX27N0Rg9LDPutaaPzudgYxvfeGpN1PYTPOZNOPfofFdj\nCy2n9bzxw6OE3I3TIP/27e2A1Wg7DvIjxxYwpSSPGWPyo+7VjXtbvPkeRTkBfD5hlD1HpWJkbtTz\nlB1zzKQRuVFCEc9p3lOGRK6hgcRdd90Vfj158mRWrYrEkYsIjz76qOdxb775Zvj1oUORntkll1zC\nJZdc0it1c8wZ/9pYzRKXs7IrQrC7pjlsT6+qbwlHg8TjgEeD+8d3KwHCNs9YnIaoPWSiYsbrWqJH\nCUFXb/3drQdpbQ/xp+WV4W3ZGf64kTMHEvRuO2PT/npagyECaX7+esMJfPyBt8L7Sguywqago8Zb\njZozevrT547ngp9ZcwYunl/GE/bncPykIv5r8RFMtxuQa0+eRNnwbL70p9W8X1nDEaPzqW8JsmTu\nGK47aVKH2Pbf/+cx/HXlzvD5Fk4uZsGEQn704voOYYn/cWQpP35xfVicbj69gv84spTWYIgL7bpd\nd9JELppfhjFw4+9XRtm24+HzCT//9FGs31MX9r385JNHsuNgI1/96wcs3XKAgN0rv+PMKZw5oyQ8\nf+ILiypYMreUkDHkZabxfmVNXLEAK47/obe2hHvFd54zjRlj8qmqbwk/Oy/ffjL/+GAP339+HRCJ\ntvn43FIqRuYxs3QYb2zYD8CSuWMYV5jN/a9sZFxhNk/ftJA7nngvfK7CnAzKhmfxzE0LmVk6jF98\nZn64lz95ZC6PX3ss+ZnpjMgL0B4ylOQHmDYqj4w0H+OLsnlhzd4O9+A4in/z2QVs2t/AEaOjRxZu\nX93/O3saR4zOZ2pJHnPHFrBpfz1Hlxd2+p10Bx0RpBBOLyk2O0VXzA/unkhn4YlAOKqnO8TWJ5FQ\nrdphiabbXpxoBmZ1HCEYk6An6rBhXz2tQSu6aNKI6GscOS7i4B2ZZ5kTnEZ3Zmmkp3j5sePDrwtz\nMphZOiz8488NpHHBUWUE0nzhz7u2uY3h2RlMH9OxBzqzdFhYdAA+dcw4LjiqzLPuaX4fZ88cHf5s\nywqymFCcw9RRedTZ25bMLWXyyDwqSvK4dMFYz/N4UVqQxanTRobNMFkZfqaU5PGpYywHtuNMT/P7\nmDcuUt/jJxUzoTiHSSNyGZmXyelHlCSc3ZyXmc5/uDow/3FkKSdWjAiHY4LVg3aHcWbYdRIRZpZa\nM7hzA5apanh2RriHP6Ukj9xAGme6RjNFuRlRx5UWZFGcG7nWsROLmD4mnxF5AUYNywyXnVKSRyDN\n73kvYTNgSR5nzxyV8Fk9ZqLV6Pt81nmXzC3ttAPWXXREMARpCbbzp+U7ueTosVE9DMdR+uLavdx4\nWmS4//bmarLS/eHZoF64nYSb9lsx1BOKc6htbgubQp56bxfzxw/ntXX7yc+KfrTer6zpYEL50Yvr\nOW3aSMYXZodnmYIlBMOy0nn1o33UNrd1cLq6WR0TNghQXpTNh7tr8QnEmvofW7qdBROG09ja3iFi\nKBETR+Tw2jqrJzm7rCAqZBXgyHHDeWa1Ff2cn5lOmk+obmjF75NwYwSEzShAVKPi4PcJk0fm8spH\n+ygvzqG+JehpAwfIzYi2VVeU5CUUtCJXA+mE0Mbeo8P4Yu8GSoQOpqV4TBph3evuGm/HcIXrs+gq\nFSWRY5zPxX1fQFQDnO5hp88NWPsz0nxhM6PT03f7KGKdv4eLl49geHbXHb2d+TJ6ExWCIcgvXt/M\nD15YT7pfuGh+pGfn/H6rG1p55N+R5Ut/9tomfvbapoSpCdz27q/8JTqh7NbvnsvBhlZufmwl5UXZ\nbK1u7GCHddI0uLnv5Q0s3VLN+XNKudeOigDLLm6M4apfL+v0Xr3acid0cmReJntqrUbo6PLhLNtq\nRX3c+of3ospfd/JEnl61K+41CnMyuPyY8dxjR4Bk+H0dJvhMGpFDeVE2n104AZ9PGJkXYFdNM9np\nfkSE606eyNubD5DpEhB3CKmb06aN5H9f28RX/2p9zs5nefsZU3hi+Y7wrGefT5g2Ko/SgiwCaT7K\ni7IREc6bPTosSgAXzLNGCUVRjVykHrecXsHza/ZENaBHji0gL5BGMGSiBPzM6SXUNLWFwyQTMXlk\nLjkZfr6wKDp8+KvnHsEflu3oVvSL45D2CWEntXtEYN1b5NlL93dsjNOcUQJwzASrE3PVCeWAtzh3\nF/fn+cWzpvLY0u2eaTLi4Yxc+gIVgiGI88ON7Ym5o29iw9Q6o7Pp9I7d1nEsOiaIzPTE1sdDjW3h\nmbkO9S1tnr3IZ28+ke889yFvbKgiI80XFT3kZlyhJQSjCyJC8Mfrj6ehJRjlpD5jegm/uMKa4+EI\nwc8vP4pn39/NU+/t4qvnHsE1J04Ml3/07W1sqWogI83XIftrXmY6r33x1PD7SSNz2VXTTKbd4H75\nnI4hkdkevXKA28+cynGTirjsF++Ezw3WfIybTq+g/M6/u86Rxlt3nhZ1/E8vm8fnTqnh3Pss8f3h\nxXOA6N5ulquRuvWMKdx6RnR8ekF2Bu/ffRY3/G4Ff38/Iiq3nzmVicU5TP7Kc551d5OZ7mfNPR0T\nEF9z4sSoz/VwcEYEuYG08HcwPCe6wXR/rhkeQuBm1LDMqA5Qoqilw8U9Irjh1MnccOrkwzo+NoIo\nmaiPYAji9CRibe3uIf22TibNxNLUFiIvTrQFxI9mCLabDg29m7rmINUx+2ubg57ny8tMC5tk3OkO\nYntZTq97zLBoe2psw1vk8aPPzvCH8wDFjmqcxjPD09wQXdbpuSYSwnhC4D4eutcgxPaSgXD8Onib\nhryIvdfcQFq4R90fjMrPJC+QFjXvJdZM5743rxGB8zvwsnD1phAk8nd0hdgIomSiQjCI2F/XzIa9\ndWzcVx81MSoWxwYa62R128S9ct3srW1myU/f9AwPbWoNUpjr/SO5++k13PP0Ws99wZDh6gQmnuqG\nlg4O3KseXsZtT7zXoWxuIC3csJbkRxq1WaXRaZydEdGEGDt3bC8+1rYMMUIQ0wA7DbeXEMSK0RS7\n59oWjP89ZSWwQbtNFIkEOB5Og5bjahSLumH/LsiO7m1n9WHj5IWIUFGSGzcEFKLr6JWjJ8t+hrzu\npaeNd/S5eta8JmO2fzzUNNQL9EYaaoCHHnqIxYsXM2qUdy4Wt7mkK9krY0cE7gRtXtkMH1u6nfcq\na3jw9c3cdX70DO3G1nYKczLY5hFT/vBbWz2vX5STQXVDK+/FJARz09wW8nQGL5xczOhhmfh9Qmsw\nRFaGn4Ls9HDvrygnwH8tnsbummYuPKqMZVsOUFGSR01TG6dNG8memmY+f+okZozJj2uLL/ToNWem\n+8PZMHNiGksnrUWsueGCeWUdoogWHVHCpQsORaWdjqWzRvV7F8xidWUNR5UPj9r+8JVHJ+wIgCVW\nd58/g+MmRa4/yuVI7mqDftsZU8gNpLFkbimvrdsXtuv/7FPzyI/zuSabW8+Y0mFC4v9+al5YtNwj\nLS9n8aXHjKOqvpXrTvY2T/3PBbPDM317QuxIpas8deMJfLQ7OfMF4qFC0As4aajBmkeQm5vLHXfc\ncdjneeihh5g3b56nEMTOrk3UDjiRELGzdFvaEotHvj3c9sq10tTWnrAXBjB//PBwrh6wkvU5+Vgu\nP3ZceKJOLLFpFQDuu/RIz7JOL6swJ4NrT5oU3j5jTPSo4I6zrJTe8XL3g3dUhntEEGtWSPPZQhDT\nuNxx1hSP0UaA73xidtxrO9dKxCePHscnj+64/dQ4eXpi+czx5VHv3b3drpqG8jLTuf1M67N0Rzwl\n+lyTzYkVHVPRL3bVx31vAQ/TUCDNH34+vLj46K6HziaiuyOC2WUFUfmm+gI1DSWZ3/zmNyxYsIC5\nc+fy+c9/nlAoRDAY5NOf/jSzZs1i5syZ3HffffzhD39g1apVfPKTn2Tu3Lm0trpSIRjTISOi4yit\nbwl2cOQ6QlDfHKSmqY2axjbW7Krp1OHr5IzfWt3A2l21UeWbWts7HTbPKhsW1Vt2N85Hjh3udUj4\nHnK62DA5dfAy6xwuPo/lPtP9PoL2iCDWrOCYf2LDArPTu9ef6mpjnAw6E6HBTFYn4aN9RXdHBP3B\n0BsRPHcn7Hm/83KHw6hZcM53D/uwDz74gL/85S/861//Ii0tjWuvvZbHH3+cSZMmUVVVxfvvW/U8\ndOgQBQUF3H///fz0pz9l7qIKIS0AACAASURBVNy5UeepPNgUlSMHrMY62NbOzG88z/DsdFa6Vi9y\ni8ScuyMpG7xC1/Iz08KLkjghpZv2N7D4vjeiVqRqbG3vtPE4ctxwVmw/xHs7DlGcmxGe1g8knKMA\ncPzkYl5ca83EnJZgWO40wl6O3q6wYEJhOOFYeXEkbenCimKeeNdaFvCo8uEs3XogypQC8YUgM6N7\njU1/2NtPrCjmjQ1VvWoLH2h0Fj7aVzjPSbxMqwOJoScEA4iXXnqJZcuWhdNQNzU1MXbsWM466yzW\nrVvHzTffzLnnnsuZZyZegu5QnFWTnAb/YIy93/EFxIqH1wSqkvxMapu9E1m513VoaosWgpF5AfbV\nRTJbPnzlAo4YnccxEwppaQshEsmuCNa6sC/ddjIZfh9rd9dy/W+X4/cJj/3nsTS0BFkwoZDKg01k\npvuiolticRowL/t+V3j4yqOpshOvTRsVma37zY/P5LqTJzE8J4Pbz5jCBfNKO8z6dHLrx5qGOgtR\njEd/9Mp/ccV8dtc0H1Y8+2DD75NweHGyF3RJhM8n/POLp4TXvh7IDD0h6EbPPVkYY/jsZz/LN7/5\nzQ77Vq9ezXPPPccDDzzAn/70Jx588MG45xG8Q93iPeKOQMTLwOkmUbjctuoGWoLWwi+xpqGy4Vlh\nIagYmRdOgeB+6Fdsj16L1bExO+kn/CJRI4WuOOi8ZoAeDjmBtPCiLdHn9Ydnwqb5fUwe2bEuvjhC\nEOsf6Cr9YRrKTPd3iKYaimSl+2kNhrot0r1FMhec702GnhAMIBYtWsSFF17ILbfcQnFxMdXV1TQ0\nNJCVlUVmZiYXXXQRFRUVXHPNNQDk5eVRVxeJFgiFTIdefTwONbbyyze2YDDhSVSd4RM8G8Xw9Q18\n429ryMtMo74lGNWDHT0sC7DSO7in/btxhuXx4vy70346YlTcCz6CwyWtl3vR/R2KOZTJzvBT09TW\nr6ahwYQKQRKZNWsW3/jGN1i0aBGhUIj09HR+/vOf4/f7ufrqqzHGICJ873vfA+Cqq67immuuISsr\ni6VLl7K/sb3DZCs37a7Qob+/v5ufvroxblkvcgNpng5Th+LcAH9btSscl5+dkcbF88s41NjG506Z\nxPNr9jA8JyOuDdT5EWbG9KCdMMxE147HzNJhzCzNp2x4dueFexlH0Bxn8nUnT+TtTdWJDklIT3PZ\nKPFxRlv96SweTOiT2Mu401ADXHbZZVx22WUdyq1cubLDtosvvpiLL744/L6tNvEC506DBFYIZobf\nd1iLuedlWgtkAJw7a3RUKoGinAze/eoiAL7w+Er+umoXmel+/ufCOeEyG7+9OOH5HftsIKbn6/Tq\nu9PBPmr8cJ656cTDP7AX8NvC5cTwe6WNOBx6OuFIiY8z2upPH8FgQp/EAUxnk4bcefnX763jiDH5\ncTNVxpKV7o8aEcTOIHXj9L5rumimcnBs6bFRNs777owI+pM0u1EJHkbW0kR017egdI5jxgz41fzW\nFVQIksyBhpa4C7F0RmfNjTsKaN2eOqaMzO1yWGXp8CzyMtPC5o7YdAruFAeTRloOr66sQ+DGcdTF\nCkG6PTGrN+YC9CXOhDun/srAxUnfkZ6mYtsVhoxpyLG3DzQqD3a+rGM8Eg0IjDEYl1RUN7RSUZLL\n5qqGhEsLOtx59jTS03z88d0dAFHpkb923nTOnB5ZoONjs8ew40ATnzmu/LDqH/YRxJiGhmWnc9fH\npnP6ESVehw1YbllUQXZGGv8xr7Tzwgl4+saFbK5KztqzioWTT0idxV1jSAhBZmYm1dXVFBUVDUgx\ngO4JVTzTUJpPMM31bDsUPX+goiQvnHO/MxbZDb2zxGPAZa++euGE6Ov5fdx8enRO+a7g1N5rgY4r\nT5jQYdtAJzsjjVsWHf7nEMussmHMKhvWeUGl2ziO+N6O9BqqDAkhKCsro7Kykv379/d3VTqw1x4R\nyKFA3PS9xliNvjvM0hjD7ppmz4VXfAL1QeH+d6Ib/SkleYc949a5ZGYSpsO32NFGg2mqvTI0yMrw\nk+HvuG6E4s2QEIL09HQmTBiYPcxzXIuIPHvziZ5rz9770gZ+/NJ63v7y6eG0Btc9+i7Peyx+DdZM\n3rNmjKK2JcS0UXl8tKeOnAw/Y4Zlhm37uYE0z7WI8wJp4TVqwYrC+euqXUwb3fNsi7EU22v3Hj85\nfgZORUkGI/MCHRasUeIzJIRgsLB82wFPIVhuz8D9YGdNWAhiReDi+WUsnjWaKx+2cvvfcdZUSwya\n2vjc71YwuSQPEQmvOxsrAlcvnMDlx45nZF6AWldW0suPHc/xk4uZmITZppNG5PLK7SdTPkhmVypD\nh2tPmsjF83sni2gqoJ6UPmRXnOUhy+01dhOtGlZenBOVViE/M50TJheH88NPsdM3uFe2cpNlpxbI\nCaTZs4ItRIRJI3KTNoSeOCK3TxfYUBSwfARjCrI6L6gAOiLoVZ5YtoNTpo2gur6VnQebOiQVe2tj\nFX9duZOPH1nK7pomXl+/n/qWSJ7/59fsobQgkxMmF3c4d1a633NlLOcaTpoHJ19OLGoqVRQlHioE\nvcS+2ma+9KfVzCkbRnlxDsu2HOgwAlhdWcMX/rCKM6aXcOVDy1hnr8vrRNUs3XKApVsO8JfPH9/h\n/Nm28yuW8YU5HDE6n5OmWIt1ZGX4mTO2gLNmlPDLN7ZQWpDF+zvjrxDmZkF5IcdOTJwuWlGUoYcK\nQS/h5P3ZXdNMbmZaOD+PFxv31bPflUPIWUjGwVmx6/kvnMRZP3kdsCbIOCMCd1TpsOx0nrslOuXC\n3244AYDPnzKZe1/awPs7axLOSXB44vrjOi+kKMqQQ30EvYST96c9ZKiub6U5wbKQ6/fWJcyB8tGe\nOgJpvrDjFyzT0FDOIa8oSv+hI4Je4KqHlzLKdsAGQ4bqhlZagvFHBF98cnXCRUk+2FnDpBG5pPt9\n+H1Ce8iQnRERgu7m4lcURfFChaAXeHVdZCJbe8hwsKHVcyKYm9i8PaUFWQRDIfbWtrDjYCNHjLbC\nTNP9lhBkZfgZmZfJPUtmsGiQpWZQFGVgo6ahHmJijO/1LcGE2SnjjQRyAn7uOHMqAHtrm8NZRB0H\nsZNW94rjyg8rLM6JFtKoIUVR4qFC0A12HGgMC0AiX4AX8dJEZ6T5wvlRQoZwSKnjIO6P9W0VRUkN\nVAgOkw176zjxf17lV29uAaCuxXth+XjkxlkaMsPvi2rsnbTQTvbE7q5vO902Mc3wmNGsKIoCSRYC\nETlbRNaJyEYRudNj/zgReVVEVorIahFJvOTVAGC3PTfAWc2rvrljPp9Yzps9mp9ffhQAuZne+U8y\n0nxR6ZrzAjFC0M31bRdNL+G1O07h7Jmju3W8oihDn6QJgYj4gQeAc4DpwKUiMj2m2FeBJ4wxRwKX\nAP+brPr0FnV2w3+gwVqtyyuxWyzFuYHwSCAr3ee5RGNGmj96RBAWAqtwT9a3LU9CHiFFUYYOyRwR\nLAA2GmM2G2NagceBJTFlDODYLIYBu5JYn27x2NLt7DoUWVzmQIM1Eay63hKCui6MCNzrCgjiaR7q\naBqyV8Py+8hI8+kcAkVRkkYyhaAU2OF6X2lvc3MXcLmIVALPAjd5nUhErhWRd0Xk3b5cc2B/XQtf\n/vP7XPfo8vC2ansk4MwT6IoQBEOG2WOHUZwb4NYzppDnYR4KxJqGMiPO4u6ahRRFUbpCfzuLLwV+\nbYwpAxYDj4pIhzoZYx40xsw3xswfMWJEn1Wupqmj+ccxCQVDBmNMl0xD7e2G/Mx03v3qIhZMKAw3\n8hcdVcZxE61c/VbUkLePQCOGFEVJJskUgp2AOyF4mb3NzdXAEwDGmH8DmUDH1Jv9xIEGKyLIbcpx\nTELGQGt7iPrmjlFDsT349pi5Bs75AumRRt4yDUWuE4kakm5HDCmKonSFZArBMqBCRCaISAaWM/ip\nmDLbgdMBROQILCEYMOtNOv6AvMw0jDGce98b4WghgEONbdz19NoOx42wV+ZyiPUJOI18ZpqfTLuR\nD6T7otb2DYtFjBNZURSlt0laigljTFBEbgSeB/zAQ8aYNSJyD/CuMeYp4HbgFyJyK5bj+EoTO1W3\nH3H8AbmBNBpb21mzqzZq/8Z99R2OueK48cwvL+Tmx1YC8MWzpnLl8eVRZZyZwYF0H6X2a79P8PmE\nby6ZQXVDa3hVr5tOm5wwk6miKEpPSWquIWPMs1hOYPe2r7terwVOSGYdeoJjBsrNTAu/Bsux2xIM\nsdOOJjqxopg3NlQBcM+SmWE/AsANp07ucF5nWcjapiCzy4YBVloJgE8fVx5Vdn65rg+gKEpy6W9n\ncb8QbA+xw2NZyL21zTS2Bmm1G/nX11tWKmOguiGyfoDTo397UzVAuFfvEPBYSczNuEJracrtBxqZ\nbC8xubUq/jKViqIoySQls49+//l1/N/rm3n7y6eHF4sHOObbLzOrdBjji7J5ZnXEF9AaDEX18scU\nZLKlqoE/r9xpv48WAicM9OwZozyvP7PUGgXMHVvAJFsIFkzQnr+iKP1DSgrBmxstM87+upawEATb\nreRx7++s6bC0Y0swFGUaGjMsuuEflZ8Z9d7vE97+8ulx1w0YU5DFv+48jZF5AdL8voRlFUVRkk1K\nCkGaPUs3GIpkDj3Y6J08LivdT2t7KOw4BhgdMwLIDnSM6nGPNLxwjyI6K6soipJMUtJH4KRruP+V\njdS3BHlzQxV/WxU7xcEiLzONuuY2fvzi+si2mHDQQJqGdyqKMnhJ0RGBpX+vfLSPu59awx+XV8Yt\nm5+Vzsrth8LvJxbnMG/88PD7qxdOYEpJLmMLs1g4ue9mPSuKovQWKSkEPtc46MM9tfELEr2QzIqv\nnUFhTgZbqxrC2752npVQ9Y0vnda7lVQURekjUtI0lOZSgsqDTQlKQr6dIK44NyPs0A2kp+THpijK\nECUlWzR3SudDcZzEDvlZlhA48f5gpYZQFEUZKqSkEKQdRm7/THtyWGlBdmSbpoVWFGUIkZJC4DsM\nIXAWjy/KjcT5dzZzWFEUZTCRki1avBFBkcekrmC7lQPPPeHrcIREURRloJOSQhBv2cdPHj22wzZn\n4RkvkTh+UlHvVkxRFKUfSMnwUS8huOm0ydxw6mT+97VNUdvrHCHIjRaCFV87Q9cJUBRlSJCSQhDy\nWPFgQnGOp+2/zl6BLHadYc0NpCjKUCElTUPtrhxDDtkZfkQ6jhTq7cXpY1cZUxRFGSqkpBC0tXcc\nEmRleDf0dy+ZwfTR+UwckZPsaimKovQLKdnNdVJOu4ldcN7h+EnFPHvLicmukqIoSr+RkiOCoIeT\nQB2/iqKkKqkpBB6mIRUCRVFSldQ0DYVCiMBfP38C6/fWUVXfSnlRtA/g11cdrQvGKIqSEqSkELS1\nGxZOLmbO2ALmjC3wLHPK1JF9XCtFUZT+ITVNQ6EQ6f6UvHVFUZQOpGRrGGw3cdNMeKWSUBRFGcqk\npGkoGDKk+72F4M3/dxrtxmPqsaIoyhAlNYWgPRS1SpmbLI0eUhQlxUgpIXj6vV2MGpZJW7s5rMVp\nFEVRhjIpJQQ3PbYSgFH5maTFMQ0piqKkGqnpLA6FSNOoIUVRFKALQiAiN4nI8L6oTF/R1m5IV9OQ\noigK0LURQQmwTESeEJGzxStX8yAj2B7CH8dZrCiKkmp02hoaY74KVAC/Aq4ENojIt0VkUpLrljQS\nhY8qiqKkGl3qFhtjDLDH/gsCw4EnReR/kli3pBEMGXUWK4qi2HQaNSQitwBXAFXAL4EvGmPaRMQH\nbAC+lNwq9j7tIRN3HoGiKEqq0ZXw0ULgE8aYbe6NxpiQiJyXnGoln8w4C9EoiqKkGl3pFj8HHHDe\niEi+iBwDYIz5MNGBtnN5nYhsFJE745S5WETWisgaEfn94VS+J0wo1qUnFUVRoGtC8DOg3vW+3t6W\nEBHxAw8A5wDTgUtFZHpMmQrgy8AJxpgZwBe6WO8eM6Ukt68upSiKMqDpimlIbGcxEDYJdeW4BcBG\nY8xmABF5HFgCrHWV+U/gAWPMQfvc+7pc8x6Q4fcxrjC7Ly7V+1RthNe/D7MvgqIKeO07MO08OGLQ\nWukUZWDRUA0vfR3amnp2nvRsOPObkDXwp2F1pUHfLCI3ExkFfB7Y3IXjSoEdrveVwDExZaYAiMhb\ngB+4yxjzj9gTici1wLUA48aN68KlEzMyPzB4ZxZ/+BSsfhyaDkDFmfDeY7DnAxUCRekttr0JK38L\nw8ZBWjfT0gdboWY7TDsXpp7Tu/VLAl0RguuB+4CvAgZ4GbtR7qXrVwCnAGXA6yIyyxhzyF3IGPMg\n8CDA/Pnze5wjOjcwiFMstdS5Xtda/0PB/qmLogxFnN/YVX+Hgm52PKs3wf3zon+vA5hOW0TbXHNJ\nN869Exjrel9mb3NTCbxjjGkDtojIeixhWNaN6yXEZd0a3AvVOw9WsCXyur2l/+qjKEONZruDFcjr\n/jmcY53O2gCnK/MIMoGrgRlAeDV3Y8xnOzl0GVAhIhOwBOAS4LKYMn8FLgUeFpFiLFNRV8xOh03I\nNY7IGdQjAvvBam+NPLCDpNehKIMC5/eU0QtC0Dw4hKArhvJHgVHAWcA/sXr2nbY8xpggcCPwPPAh\n8IQxZo2I3CMi59vFngeqRWQt8CrWZLXqw7+Nzml3KcGQMA25RwQqBIrSe7TUWo5efw/aibRM8KUN\nmt9mV+50sjHmIhFZYoz5jR3r/0ZXTm6MeRZ4Nmbb112vDXCb/ZdUQi7T0OAeETjmoFaXKDRbzqnu\nOrYURYnQUguB/J6dQ8Q6xyARgq6MCNrs/4dEZCYwDBiZvColhyghGNQ+AnuoGWyOfsha673LK4py\neLTU9cw/4BDIG1JC8KC9HsFXgaew5gF8L6m1SgJu09ApUwedjkUIjwJaox1Rg8QppSgDnl4TgsEz\nIkhoI7ETy9XaE75eByb2Sa2SQChk/f/CogpOnTaIhcBxPrW3WI1/WhYEmwaNU0pRBjy9OiIYHL/L\nhCMCY0yIQZhd1It22zRUkJXezzXpIbHO4vwx0dsVRekZzbUpJwRd8Zq+JCJ3AH8AGpyNxpgD8Q8Z\neDimIb9P4I0fWTP+Rkzt51odJsGWyJyB9lZoC0LJDDiwCV6+B3JHQloATvsaDB/fd/Va9kvY/M/o\nbeKD42+2nGZv3Qsm5H1sejac9W3IKfLev/55a5YnWJN7anfBibfBqFnR5Rqq4PmvQKgNTv0KFA3a\ndZOSwxs/gl0ro7dNOhXmf9b67pb9MrJdfHDs52H9c7DgOsgf3Xv1CLbAs1+EpoNW6oXFP4gOcoj3\nLB13gzWLvqGq9+oSj0PboHRez8+TmQ/b3oI/fLpr5X1+yBsDNa6EDNOXwKwLe16XTuiKEHzS/n+D\na5thkJmJnAllGaEmePluePtn8MUN/Vyrw6TFdggH8iM9jTHzoL0Nmg5BYzVUb4Bxx8HRV/ddvd66\nF5prrIfYoWod5I22Hu4Pn4JiD9ENNsPBLZYoTz+/436A5b+GTa9EygMUTugoBNveslJvAIw5Eo6/\nqUe3NOT45/9ARjbk2GbR2l2wZ7UlBCt/C+v/AYW2eFatszoXe96HvWvgU3/svXrs/whW/AYyC6D5\nkPWcjp4T2f/mvdDi8Sy11MGmlyG/rHd664kYXg6TF/X8PBVnWelfqrrYzuy3kzkH8iG/FA5th7o9\nA0MIjDETkl6LPsAxDWW0N1obBqMpxWn8s4sir4eVwRl32/vr4TulfR9B1FIHsz8Ji78f2fbDI6C1\nzurN5ZbADW93PO7gVrh3TuL6ttRB6VHWiGL7v+1tHuWjUm9oBFUU7W2WH+nE2+Bk29L7zK2w9inr\ndUsdjJgG19tR4T+eCY0Hrdetjb1bF+d7OvoaeOMHHb+rllrvZ6l2l/X6Y/dCRS800n3B7Iusv67y\n7TLrN3PE+fDxB+APl1upKvqArswsvsJruzHmkd6vTvJwTEOZ7c6D1+OURX2P0/jnFFs9aYjuHWXk\nANK3jmNjvG2qgTxru/ji9+CcWO1E9W2usfwgbtOSl921WSOo4uI0vu7vwW2/jo2bD+RZvVGg138n\nzvcU9m25vitjvB21gTyo3Rl5PVQJ5FlC4NxjIL/PfstdMQ0d7XqdCZwOrAAGlRA4UUMZ7Q2JCw5k\nnB90dnFkm/uH0R+TWNqawLR7/3hb6joRAicfS4L6Og1DlBB4lHe25YxUIYjF+TyihCDf8jMF7eiz\n/DLXvrzkjSqd72lYWfR7gLbG+M9S1brI66FKINfK2RAWgr6bh9AV01CUsVVECoDHk1ajJOGYhgJh\nIRiEi9eHG7s4QgCWg6ovhSDc24yZiZmZ7xoRxJml6U+3wl8TNdwtddbxnY0InLQA2YWD0+yXTLy+\nI+d1S531l+mxD+j134nz3eWXRr+PV0+IrltmD2f8DmTEnujq3KPjCzTG6uQlke4k5W8ABp3fwDEN\nDYkRQZQQxPww+jpkLd6P1+nNdBaT3VmvxznefY54IwKnnApBNPFMQ2A9K7HfUTJ73U5dvMKeEz1L\nfVG3gYJ7RICB1uS3WV3xETxNxFDow1p28olkVioZhEysEAxmH8GIyLZ4Jpm+rlNC01CCXlyi+jrh\nsl01DQXyVQi88GpgM2NGBHEb217+nbTUgS/dCh0Vv/f6Gl7PkkNGCiwxGyUE2N9Pcu+7Kz6CH7he\nB4FtxpjKJNUnaThCkB4cxBEljuMou5MRQWNSErh6E/fHaw9rE/kInOPijWDcDVibq1fk5UBrqY2M\nCGpil71Icbzy6zuvG/ZbvoJ4QtDT5Rpjcb4nkUhAQaJ6QuQZz8i1wpGHLLboOvcbtaZBL87l8KAr\nQrAd2G2MaQYQkSwRKTfGbE1qzXqZsGmobRALQUudldo2c1hkm1fv6eDWvq1TvHo4DsfumobcIuMW\nAjUNHR6ezmL7tSOaXv4D6P3P0j36iA1sSPQsgR0VlwK4Px/ok+e5Kz6CPwLuaaHt9rZBhRM1lO6Y\nhoLNEGrvvwp1B8f84Z6JmZ4ZXaavo4aca8U68bzMEF5kDksgBO5zu5xlwSYrNj62bCAPAgnOl6p4\nfUfO9+PE58f7vpIhBM75YwMbOnuWZCiPBiD8jDvmr7D5Lvk+v66MCNKMMa3OG2NMq4gMusT37V6m\noZY6yCropxolINgKf781MqnHYfd7VmPnD8Q/NpBnTcN/LHYxuC4SyIUF11qzhUPtkFcCjQesSWG1\nO60IBjeHttnHddPBF8iDA5u969t0oOPxvnQrjcTjl1mvHQ5utWYUO7HY3b3/oUjVestEl54d2eZ8\nX+89Zr+P83019uBZ8mLHO9bkNec6O96JnL+zZynJkTMDBrH75859v/ItWGqnAJn/2aRMqOuKEOwX\nkfONMU8BiMgSoA8SfvQu4VxD7vV9B6oQVG+wpv0XjLN6uA5Zw6HiDOuHNO746Kn5DpNPhy2vuyYE\nHQZtDVaj3LDfSuuQVRhpjMHqkY2cHnOQwLTzrJQBbsYdC6XzAQNjj4l/zSlnw94P4td33PEwcgaU\nzIStb8Ix18Or/w21u6PLFU2CijOtfEvr/9G9+x+qpGXCnMuiG9LsQph6rvU5jT0m+lkae4z13QVy\nrU5Ab36WeWOsmbMA0z9uPefh8yd6lo6yyg9lPvGgNdu6uMJ6P3wCTDg5+jtoTc5oV0xsDy+2gMgk\n4HeAk/yjErjCGLMxKTXqhPnz55t33333sI9btvUAF/383yyd+hgjtz1tbfzcv6EktmEbAGz7Nzx8\nNnz6LzDptL677u7V8H8nWkJTtd5KGvfWTyL7C8bDF1b3XX0URek1RGS5MWa+176uTCjbBBwrIrn2\n+0HpbQ3ZIwKfcfkFBuoM1Hjx1MnG7UAM5CW2+yuKMmTo1FksIt8WkQJjTL0xpl5EhovIt/qicr2J\n4yMQ3EIwQJ2K4SiPPm54nWik1jrLJJVohqeiKEOGrkQNnWOMOeS8sVcrW5y8KiUHJ2rIZ9rBb/u6\nB/yIoI9nUbon6wTyEjuAFUUZMnRFCPwiEg5TEZEsIEHYysAkPCIwIcvpCgN4RNBPQpCWYTkWnWvH\nXt8/6ILFFEXpAl2JGvod8LKIPIwV6Hol8JtkVioZRHwEQSsqoX7vwF3nt6UWkP6ZQBPIs+ZYeAnB\nYEzLoShKp3TFWfw9EXkPWITVEjwP9OE6iL2DEz4qJmTbwmVgjwgC+f0TNx3Is8JHPYVAUZShSFez\nj+7FEoGLgNOAD5NWoyQRCpuG2q30xwM5FUFsWuC+JOCa9dmhDikyoUdRUoy4IwIRmQJcav9VYS1e\nL8aYU/uobr2KIwQ+EwRf1gAXAo8Vv/oKd+ZDDRdVlJQgkWnoI+AN4Dxn8piI3NontUoC7XbUkJiQ\nNUM2kAcbX4TffxJOvB3GLuh4kDHw3Jd6lsRt9icPf/HpznL4J5P0LOu/k9JZUZQhTyIh+ARwCfCq\niPwDa1WyQWsbiEQNBa0MnrMugo+egQ0vWFO6vYSg+RAsfdBaxi93RMf9nVG1wXK8Hq4QNNdaKQD6\ng5kXQNNBmHgKpAWsRcanLoYVj8CZ3+yfOimKklTiCoEx5q/AX0UkB1gCfAEYKSI/A/5ijHmhj+rY\nK4TczmKfH066w/r77ngryZsXjunolDth3qcP/6K/vaB7awO01MHwfvLHz7nE+nM494fW/8mn9099\nFEVJOp06i40xDcaY3xtjPgaUASuB/5f0mvUy4aihULs1InBIC1i9di/ipcXtKt1NCe1EDSmKovQB\nh7VmsTHmoDHmQWPMoOseRkUNieu2/QFrhSYv4q2Y1FW665DuTx+BoigpR3cWrx+UOEKAiR0RZFhr\n43rR0+RvsUvxdYX2oJUOWkcEiqL0ESkjBOGooVAwRggy448I4q3H21UC+d6raSWitZ/SSyiKkrKk\njhC4TUPuBbD9iUYEvWAagsMzD/XUL6EoinKYpIwQOFFDxApBWgDak2QaCq852g0h0BGBoih9RFKF\nQETOFpF1IrJRRO5McP1NXAAADIBJREFUUO4CETEi4rl6Tm8QFTUksSOCROGjPUj+1pMRgQqBoih9\nRNKEQET8wAPAOcB04FIR6bAupIjkAbcA7ySrLpDIWZxgRNBc27Pkb2EhOAyHcXM/LUqjKErK0pU0\n1N1lAbDRGLMZQEQex5qYtjam3DeB7wFfTGJdIuGjIS8fgWtEEGqHp26Gul2w76Oe9cydxvwfd0J2\nkfU6q9Cat9DW6H1M/X77WB0RKIrSNyRTCEqBHa73lcAx7gIiMg8Ya4z5u4jEFQIRuRa4FmDcuHHd\nqszIvEyOHFcANbFRQzETymp3warfwvAJMKy0Z4vHj5gGk8+wUlW01Fnnrt1p7SuZBemZHY9Jz7RS\nOgwv7/51FUVRDoNkCkFCRMQH/AhroZuEGGMeBB4EmD9/frdWR/n4kaV8/MhS+O9OJpQ5NvpFd8GM\nj3fnUhECuXD5k5H3/34Anv8v6/Wlj0HB2J6dX1EUpRdIprN4J+Bu6crsbQ55wEzgNRHZChwLPJVM\nhzFgmX4STShLprPWfU41/SiKMkBIphAsAypEZIKIZGBlMn3K2WmMqTHGFBtjyo0x5cDbwPnGmHeT\nWCeInVDmj3EWtyTRWatCoCjKACRpQmCMCQI3Yi1t+SHwhDFmjYjcIyLnJ+u6nVTKex6B21nc00lk\niXCf010HRVGUfiSpPgJjzLPAszHbvh6n7CnJrIt1ETvPRKLw0WTO7A0M6/1zKoqi9JCUmVkMWP4B\n6OgsNiEr2Rv0nY9AURRlgJBiQmA39rHOYoiMCpzZxOndnE2cCBUCRVEGICkqBO4JZQHrvxM51Gwv\nHO9LwkejQqAoygAktYTA2KYhzxGB7TBO5qIwGbnJOa+iKEoP6LcJZf1C2EfgMSLY9Aq89zjsWwvZ\nxcm5fjJGGYqiKD0kNYXAbRrKyLb+r34Ctr4JY4+BaYuTV4dTvwKlRyXv/IqiKIdJigmBh7PYMQPV\n7oLcEvjsc8mtw8lfSu75FUVRDpPUslUYjxGBM4O4dqc6cxVFSUlSSwg8RwS2ELTWqxAoipKSpJgQ\neDiL3Y2/rhOsKEoKkppC4IsjBDoiUBQlBUkxIfCYUOaO7VchUBQlBUktIfCaUObzQYYtALpOsKIo\nKUhqCYEzIpCYFNAZdl4hHREoipKCpJgQeKShhkg2Uh0RKIqSgqSYEDg+gpjbdoRBRwSKoqQgKSoE\nMSOCk26HyWdA+cK+r5OiKEo/k2IpJtqs/7706O1HXWn9KYqipCCpNSJwViHzpycupyiKkkKklhCE\nRwSpNRBSFEVJRIoJQRwfgaIoSgqTWkLQbo8I1DSkKIoSJrWEQEcEiqIoHUgtIdARgaIoSgdSSwh0\nRKAoitKBFBUCHREoiqI4pJYQhE1DOiJQFEVxSC0h0BGBoihKB1JMCHRCmaIoSiypJQSaYkJRFKUD\nqSUEoTZAopeqVBRFSXFSTAiCahZSFEWJIbWEoL1NzUKKoigxpJYQhIIaMaQoihJDaglBe5vOIVAU\nRYkhqUIgImeLyDoR2Sgid3rsv01E1orIahF5WUTGJ7M+6iNQFEXpSNKEQET8wAPAOcB04FIRmR5T\nbCUw3xgzG3gS+J9k1QdQ05CiKIoHyRwRLAA2GmM2G2NagceBJe4CxphXjTGN9tu3gbIk1kdNQ4qi\nKB4kUwhKgR2u95X2tnhcDTzntUNErhWRd0Xk3f3793e/RqE2HREoiqLEMCCcxSJyOTAf+L7XfmPM\ng8aY+caY+SNGjOj+hdRHoCiK0oFktoo7gbGu92X2tihEZBHwFeBkY0xLEutjpZhQ05CiKEoUyRwR\nLAMqRGSCiGQAlwBPuQuIyJHA/wHnG2P2JbEuFmoaUhRF6UDShMAYEwRuBJ4HPgSeMMasEZF7ROR8\nu9j3gVzgjyKySkSeinO63kFnFiuKonQgqXYSY8yzwLMx277uer0omdfvQKhdfQSKoigxDAhncZ8R\nalMhUBRFiSG1hEBNQ4qiKB1ILSHQ8FFFUZQOqBAoiqKkOKklBGoaUhRF6UBqCUFbE6Rn93ctFEVR\nBhSpJQQtdRDI6+9aKIqiDChSRwiMgZZaFQJFUZQYUkcIWhsAA4H8/q6JoijKgCJ1hKCl1vqvIwJF\nUZQoUkgI6qz/KgSKoihRpKAQqGlIURTFTQoJgW0aylQhUBRFcZNCQqCmIUVRFC9UCBRFUVKc1BGC\nZo0aUhRF8SJ1hGD4eJh2HmSoECiKorhJnVSc0861/hRFUZQoUmdEoCiKoniiQqAoipLiqBAoiqKk\nOCoEiqIoKY4KgaIoSoqjQqAoipLiqBAoiqKkOCoEiqIoKY4YY/q7DoeFiOwHtnXz8GKgqherMxjQ\ne04N9J5Tg57c83hjzAivHYNOCHqCiLxrjJnf3/XoS/SeUwO959QgWfespiFFUZQUR4VAURQlxUk1\nIXiwvyvQD+g9pwZ6z6lBUu45pXwEiqIoSkdSbUSgKIqixKBCoCiKkuKkjBCIyNkisk5ENorInf1d\nn95CRB4SkX0i8oFrW6GIvCgiG+z/w+3tIiL32Z/BahGZ13817z4iMlZEXhWRtSKyRkRusbcP2fsW\nkUwRWSoi79n3fLe9fYKIvGPf2x9EJMPeHrDfb7T3l/dn/buLiPhFZKWIPGO/H9L3CyAiW0XkfRFZ\nJSLv2tuS+mynhBCIiB94ADgHmA5cKiLT+7dWvcavgbNjtt0JvGyMqQBett+Ddf8V9t+1wM/6qI69\nTRC43RgzHTgWuMH+PofyfbcApxlj5gBzgbNF5Fjge8CPjTGTgYPA1Xb5q4GD9vYf2+UGI7cAH7re\nD/X7dTjVGDPXNWcguc+2MWbI/wHHAc+73n8Z+HJ/16sX768c+MD1fh0w2n49Glhnv/4/4FKvcoP5\nD/gbcEaq3DeQDawAjsGaZZpmbw8/58DzwHH26zS7nPR33Q/zPsvsRu804BlAhvL9uu57K1Acsy2p\nz3ZKjAiAUmCH632lvW2oUmKM2W2/3gOU2K+H3OdgmwCOBN5hiN+3bSZZBewDXgQ2AYeMMUG7iPu+\nwvds768Bivq2xj3mJ8CXgJD9voihfb8OBnhBRJaLyLX2tqQ+26mzeH2KYowxIjIkY4RFJBf4E/AF\nY0ytiIT3DcX7Nsa0A3NFpAD4CzCtn6uUNETkPGCfMWa5iJzS3/XpYxYaY3aKyEjgRRH5yL0zGc92\nqowIdgJjXe/L7G1Dlb0iMhrA/r/P3j5kPgcRSccSgd8ZY/5sbx7y9w1gjDkEvIplGikQEadD576v\n8D3b+4cB1X1c1Z5wAnC+iGwFHscyD93L0L3fMMaYnfb/fViCv4AkP9upIgTLgAo74iADuAR4qp/r\nlEyeAj5jv/4Mlg3d2X6FHWlwLFDjGm4OGsTq+v8K+NAY8yPXriF73yIywh4JICJZWD6RD7EE4UK7\nWOw9O5/FhcArxjYiDwaMMV82xpQZY8qxfq+vGGM+xRC9XwcRyRGRPOc1cCbwAcl+tvvbMdKHDpjF\nwHosu+pX+rs+vXhfjwG7gTYs++DVWLbRl4ENwEtAoV1WsKKnNgHvA/P7u/7dvOeFWHbU1cAq+2/x\nUL5vYDaw0r7nD4Cv29snAkuBjcAfgYC9PdN+v9HeP7G/76EH934K8Ewq3K99f+/Zf2uctirZz7am\nmFAURUlxUsU0pCiKosRBhUBRFCXFUSFQFEVJcVQIFEVRUhwVAkVRlBRHhUBRYhCRdjvzo/PXa9lq\nRf5/e3fsUlUYxnH89yMahCDCwCXiDm5RSDT5bzhINEWTQzhF/0BTo+ligzg4u0phEEFBW/0B0Vag\nQ4EgEvJreB/j4LXwQnqF8/0s9+U5cHjP9Lzvee95Hg/cqRQLXASUmACG7SeZGfckgPPCjgA4paoT\n/7xqxX+0PV3xge03VQ9+2/bNik/Z3qweAp9sz9atLtl+WX0FXtWXwsDYkAiAYRPHXg3Nd679THJb\n0rJadUxJeiFpPckdSRuSliq+JOltWg+Bu2pfikqtdvxKkluSfkiaO+PnAf6JL4uBY2zvJblyQvyr\nWnOYL1X07nuSSdu7ajXgf1X8W5Lrtnck3Uhy0LnHQNLrtAYjsv1U0uUkz87+yYCTsSMARpO/jEdx\n0BkfirM6jBmJABjNfOf3Q43fq1XIlKQHkt7VeFvSgvSnqczV85okMApWIsCwieoEdmQrydFfSK/Z\n/qy2qr9fsceS1mw/kbQj6WHFFyWt2n6ktvJfUKsUC1wonBEAp1RnBPeS7I57LsD/xKshAOg5dgQA\n0HPsCACg50gEANBzJAIA6DkSAQD0HIkAAHruNyf0YhBeNeO2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 1.3705 - acc: 0.5500\n",
            "test loss, test acc: [1.3704636931652203, 0.55]\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "Filtering of Training Data Finished\n",
            "EEG_Deep/Data2A/parsed_P010E.mat\n",
            "Filtering of Testing Data Finished\n",
            "(1, 2)\n",
            "Finding labels in training data\n",
            "Finding labels in testing data\n",
            "[1 1 2 1 1 1 2 2 2 1 1 1 1 2 2 2 2 1 1 1]\n",
            "(60, 12, 1536)\n",
            "(60,)\n",
            "(20, 12, 1536)\n",
            "(20,)\n",
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "X_train shape: (60, 1, 12, 1536)\n",
            "60 train samples\n",
            "20 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "Train on 60 samples, validate on 20 samples\n",
            "Epoch 1/500\n",
            "60/60 [==============================] - 0s 5ms/sample - loss: 1.4430 - acc: 0.2333 - val_loss: 1.3863 - val_acc: 0.3000\n",
            "Epoch 2/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 1.2236 - acc: 0.6167 - val_loss: 1.3838 - val_acc: 0.3000\n",
            "Epoch 3/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 1.0970 - acc: 0.6833 - val_loss: 1.3785 - val_acc: 0.4500\n",
            "Epoch 4/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 1.0054 - acc: 0.6000 - val_loss: 1.3705 - val_acc: 0.5500\n",
            "Epoch 5/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.9427 - acc: 0.5833 - val_loss: 1.3605 - val_acc: 0.4500\n",
            "Epoch 6/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.8734 - acc: 0.6167 - val_loss: 1.3494 - val_acc: 0.4500\n",
            "Epoch 7/500\n",
            "60/60 [==============================] - 0s 749us/sample - loss: 0.8353 - acc: 0.6667 - val_loss: 1.3369 - val_acc: 0.4500\n",
            "Epoch 8/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.8021 - acc: 0.6333 - val_loss: 1.3241 - val_acc: 0.4500\n",
            "Epoch 9/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.7606 - acc: 0.6833 - val_loss: 1.3118 - val_acc: 0.4500\n",
            "Epoch 10/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.7476 - acc: 0.7167 - val_loss: 1.2994 - val_acc: 0.4500\n",
            "Epoch 11/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.7394 - acc: 0.7667 - val_loss: 1.2872 - val_acc: 0.5500\n",
            "Epoch 12/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.7110 - acc: 0.8000 - val_loss: 1.2752 - val_acc: 0.6000\n",
            "Epoch 13/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.6895 - acc: 0.8333 - val_loss: 1.2633 - val_acc: 0.6000\n",
            "Epoch 14/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.6842 - acc: 0.8333 - val_loss: 1.2511 - val_acc: 0.6500\n",
            "Epoch 15/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.6568 - acc: 0.8667 - val_loss: 1.2389 - val_acc: 0.7000\n",
            "Epoch 16/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.6450 - acc: 0.9167 - val_loss: 1.2269 - val_acc: 0.7000\n",
            "Epoch 17/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.6373 - acc: 0.8833 - val_loss: 1.2153 - val_acc: 0.7000\n",
            "Epoch 18/500\n",
            "60/60 [==============================] - 0s 783us/sample - loss: 0.6172 - acc: 0.9667 - val_loss: 1.2044 - val_acc: 0.7000\n",
            "Epoch 19/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.5996 - acc: 0.9333 - val_loss: 1.1936 - val_acc: 0.7000\n",
            "Epoch 20/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.6010 - acc: 0.9500 - val_loss: 1.1826 - val_acc: 0.7000\n",
            "Epoch 21/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.5863 - acc: 0.9667 - val_loss: 1.1717 - val_acc: 0.7500\n",
            "Epoch 22/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.5629 - acc: 0.9333 - val_loss: 1.1606 - val_acc: 0.7500\n",
            "Epoch 23/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.5732 - acc: 0.9500 - val_loss: 1.1493 - val_acc: 0.7500\n",
            "Epoch 24/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.5469 - acc: 0.9833 - val_loss: 1.1373 - val_acc: 0.7500\n",
            "Epoch 25/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.5290 - acc: 0.9333 - val_loss: 1.1249 - val_acc: 0.7500\n",
            "Epoch 26/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.5192 - acc: 0.9500 - val_loss: 1.1123 - val_acc: 0.7500\n",
            "Epoch 27/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.5217 - acc: 0.9500 - val_loss: 1.1002 - val_acc: 0.8000\n",
            "Epoch 28/500\n",
            "60/60 [==============================] - 0s 693us/sample - loss: 0.5149 - acc: 0.9500 - val_loss: 1.0882 - val_acc: 0.8000\n",
            "Epoch 29/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.5324 - acc: 0.9000 - val_loss: 1.0764 - val_acc: 0.8000\n",
            "Epoch 30/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.5009 - acc: 0.8667 - val_loss: 1.0650 - val_acc: 0.8000\n",
            "Epoch 31/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.4970 - acc: 0.9167 - val_loss: 1.0537 - val_acc: 0.8000\n",
            "Epoch 32/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.4637 - acc: 0.9667 - val_loss: 1.0420 - val_acc: 0.8500\n",
            "Epoch 33/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.4991 - acc: 0.9333 - val_loss: 1.0303 - val_acc: 0.8500\n",
            "Epoch 34/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.4694 - acc: 0.9500 - val_loss: 1.0183 - val_acc: 0.8500\n",
            "Epoch 35/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.4563 - acc: 0.9500 - val_loss: 1.0057 - val_acc: 0.8500\n",
            "Epoch 36/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.4589 - acc: 0.9167 - val_loss: 0.9938 - val_acc: 0.8500\n",
            "Epoch 37/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.4597 - acc: 0.9500 - val_loss: 0.9822 - val_acc: 0.8500\n",
            "Epoch 38/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.4465 - acc: 0.9333 - val_loss: 0.9707 - val_acc: 0.8500\n",
            "Epoch 39/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.4306 - acc: 0.9167 - val_loss: 0.9585 - val_acc: 0.8500\n",
            "Epoch 40/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.4186 - acc: 0.9667 - val_loss: 0.9459 - val_acc: 0.8500\n",
            "Epoch 41/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.4330 - acc: 0.9000 - val_loss: 0.9339 - val_acc: 0.8500\n",
            "Epoch 42/500\n",
            "60/60 [==============================] - 0s 682us/sample - loss: 0.4257 - acc: 0.9333 - val_loss: 0.9219 - val_acc: 0.8500\n",
            "Epoch 43/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.4336 - acc: 0.9167 - val_loss: 0.9100 - val_acc: 0.8500\n",
            "Epoch 44/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.4237 - acc: 0.9333 - val_loss: 0.8958 - val_acc: 0.8500\n",
            "Epoch 45/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.4121 - acc: 0.9667 - val_loss: 0.8832 - val_acc: 0.8500\n",
            "Epoch 46/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.4249 - acc: 0.9667 - val_loss: 0.8697 - val_acc: 0.8500\n",
            "Epoch 47/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.3990 - acc: 0.9167 - val_loss: 0.8577 - val_acc: 0.8000\n",
            "Epoch 48/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.4087 - acc: 0.9667 - val_loss: 0.8452 - val_acc: 0.8000\n",
            "Epoch 49/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.4034 - acc: 0.9333 - val_loss: 0.8345 - val_acc: 0.8000\n",
            "Epoch 50/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.3791 - acc: 1.0000 - val_loss: 0.8228 - val_acc: 0.8000\n",
            "Epoch 51/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.3919 - acc: 0.9500 - val_loss: 0.8108 - val_acc: 0.8000\n",
            "Epoch 52/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.3920 - acc: 0.9500 - val_loss: 0.7998 - val_acc: 0.8500\n",
            "Epoch 53/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.4169 - acc: 0.9000 - val_loss: 0.7882 - val_acc: 0.8000\n",
            "Epoch 54/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.3708 - acc: 0.9667 - val_loss: 0.7792 - val_acc: 0.8000\n",
            "Epoch 55/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.3784 - acc: 0.9333 - val_loss: 0.7687 - val_acc: 0.8000\n",
            "Epoch 56/500\n",
            "60/60 [==============================] - 0s 696us/sample - loss: 0.3719 - acc: 0.9667 - val_loss: 0.7574 - val_acc: 0.8000\n",
            "Epoch 57/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.3481 - acc: 0.9500 - val_loss: 0.7463 - val_acc: 0.8000\n",
            "Epoch 58/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.3810 - acc: 0.9667 - val_loss: 0.7351 - val_acc: 0.7500\n",
            "Epoch 59/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.3534 - acc: 0.9333 - val_loss: 0.7268 - val_acc: 0.7500\n",
            "Epoch 60/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.3693 - acc: 0.9500 - val_loss: 0.7167 - val_acc: 0.7500\n",
            "Epoch 61/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3426 - acc: 0.9833 - val_loss: 0.7081 - val_acc: 0.7500\n",
            "Epoch 62/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.3293 - acc: 0.9833 - val_loss: 0.6988 - val_acc: 0.7500\n",
            "Epoch 63/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.3577 - acc: 0.9167 - val_loss: 0.6884 - val_acc: 0.7500\n",
            "Epoch 64/500\n",
            "60/60 [==============================] - 0s 685us/sample - loss: 0.3559 - acc: 0.9667 - val_loss: 0.6798 - val_acc: 0.7500\n",
            "Epoch 65/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.3240 - acc: 0.9667 - val_loss: 0.6725 - val_acc: 0.7500\n",
            "Epoch 66/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.3842 - acc: 0.9333 - val_loss: 0.6652 - val_acc: 0.7500\n",
            "Epoch 67/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.3103 - acc: 1.0000 - val_loss: 0.6574 - val_acc: 0.7500\n",
            "Epoch 68/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.3564 - acc: 0.9667 - val_loss: 0.6488 - val_acc: 0.7500\n",
            "Epoch 69/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.3343 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.7500\n",
            "Epoch 70/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.3368 - acc: 0.9833 - val_loss: 0.6312 - val_acc: 0.7500\n",
            "Epoch 71/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.3436 - acc: 0.9167 - val_loss: 0.6234 - val_acc: 0.7500\n",
            "Epoch 72/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.3394 - acc: 0.9500 - val_loss: 0.6164 - val_acc: 0.7500\n",
            "Epoch 73/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3303 - acc: 0.9833 - val_loss: 0.6090 - val_acc: 0.7500\n",
            "Epoch 74/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.3172 - acc: 0.9833 - val_loss: 0.6034 - val_acc: 0.7500\n",
            "Epoch 75/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.3292 - acc: 0.9667 - val_loss: 0.5981 - val_acc: 0.7500\n",
            "Epoch 76/500\n",
            "60/60 [==============================] - 0s 686us/sample - loss: 0.3172 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.7500\n",
            "Epoch 77/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.3383 - acc: 0.9167 - val_loss: 0.5841 - val_acc: 0.7500\n",
            "Epoch 78/500\n",
            "60/60 [==============================] - 0s 662us/sample - loss: 0.3142 - acc: 0.9500 - val_loss: 0.5791 - val_acc: 0.7500\n",
            "Epoch 79/500\n",
            "60/60 [==============================] - 0s 674us/sample - loss: 0.3062 - acc: 0.9667 - val_loss: 0.5749 - val_acc: 0.7500\n",
            "Epoch 80/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.3193 - acc: 0.9667 - val_loss: 0.5712 - val_acc: 0.7500\n",
            "Epoch 81/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.3243 - acc: 0.9500 - val_loss: 0.5693 - val_acc: 0.7500\n",
            "Epoch 82/500\n",
            "60/60 [==============================] - 0s 679us/sample - loss: 0.3154 - acc: 0.9667 - val_loss: 0.5672 - val_acc: 0.7500\n",
            "Epoch 83/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.3272 - acc: 0.9333 - val_loss: 0.5645 - val_acc: 0.7500\n",
            "Epoch 84/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.2897 - acc: 0.9500 - val_loss: 0.5609 - val_acc: 0.7500\n",
            "Epoch 85/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.3108 - acc: 1.0000 - val_loss: 0.5586 - val_acc: 0.7500\n",
            "Epoch 86/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3200 - acc: 0.9500 - val_loss: 0.5566 - val_acc: 0.7500\n",
            "Epoch 87/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.2848 - acc: 0.9500 - val_loss: 0.5554 - val_acc: 0.7500\n",
            "Epoch 88/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.2998 - acc: 0.9667 - val_loss: 0.5554 - val_acc: 0.7500\n",
            "Epoch 89/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.3104 - acc: 0.9833 - val_loss: 0.5552 - val_acc: 0.7500\n",
            "Epoch 90/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2827 - acc: 1.0000 - val_loss: 0.5563 - val_acc: 0.7500\n",
            "Epoch 91/500\n",
            "60/60 [==============================] - 0s 702us/sample - loss: 0.2885 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.7500\n",
            "Epoch 92/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.3018 - acc: 0.9833 - val_loss: 0.5615 - val_acc: 0.7500\n",
            "Epoch 93/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.2805 - acc: 0.9833 - val_loss: 0.5604 - val_acc: 0.7500\n",
            "Epoch 94/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.2840 - acc: 0.9667 - val_loss: 0.5602 - val_acc: 0.7500\n",
            "Epoch 95/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2919 - acc: 0.9667 - val_loss: 0.5661 - val_acc: 0.7500\n",
            "Epoch 96/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.2675 - acc: 0.9500 - val_loss: 0.5708 - val_acc: 0.7500\n",
            "Epoch 97/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2631 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.6500\n",
            "Epoch 98/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.2731 - acc: 0.9667 - val_loss: 0.5889 - val_acc: 0.6500\n",
            "Epoch 99/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2871 - acc: 0.9667 - val_loss: 0.5981 - val_acc: 0.6500\n",
            "Epoch 100/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.2670 - acc: 0.9333 - val_loss: 0.5972 - val_acc: 0.6500\n",
            "Epoch 101/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.2410 - acc: 0.9833 - val_loss: 0.6021 - val_acc: 0.6500\n",
            "Epoch 102/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2335 - acc: 0.9833 - val_loss: 0.6105 - val_acc: 0.6500\n",
            "Epoch 103/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.2626 - acc: 0.9833 - val_loss: 0.6229 - val_acc: 0.7000\n",
            "Epoch 104/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.2582 - acc: 0.9833 - val_loss: 0.6386 - val_acc: 0.6500\n",
            "Epoch 105/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.2829 - acc: 0.9667 - val_loss: 0.6522 - val_acc: 0.6500\n",
            "Epoch 106/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.2642 - acc: 0.9833 - val_loss: 0.6641 - val_acc: 0.6500\n",
            "Epoch 107/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2646 - acc: 0.9833 - val_loss: 0.6662 - val_acc: 0.6500\n",
            "Epoch 108/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2326 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.6500\n",
            "Epoch 109/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.2441 - acc: 0.9667 - val_loss: 0.6743 - val_acc: 0.6500\n",
            "Epoch 110/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2593 - acc: 0.9667 - val_loss: 0.6781 - val_acc: 0.6500\n",
            "Epoch 111/500\n",
            "60/60 [==============================] - 0s 738us/sample - loss: 0.2513 - acc: 0.9833 - val_loss: 0.6802 - val_acc: 0.6500\n",
            "Epoch 112/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2786 - acc: 0.9667 - val_loss: 0.6681 - val_acc: 0.6500\n",
            "Epoch 113/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.2360 - acc: 0.9833 - val_loss: 0.6700 - val_acc: 0.6500\n",
            "Epoch 114/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.2560 - acc: 0.9500 - val_loss: 0.6875 - val_acc: 0.6500\n",
            "Epoch 115/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.2439 - acc: 0.9667 - val_loss: 0.7091 - val_acc: 0.6000\n",
            "Epoch 116/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.2427 - acc: 0.9667 - val_loss: 0.7230 - val_acc: 0.6000\n",
            "Epoch 117/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2210 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.6000\n",
            "Epoch 118/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.2544 - acc: 0.9667 - val_loss: 0.7399 - val_acc: 0.6000\n",
            "Epoch 119/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2511 - acc: 0.9667 - val_loss: 0.7268 - val_acc: 0.6000\n",
            "Epoch 120/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2320 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.6000\n",
            "Epoch 121/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2337 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.6000\n",
            "Epoch 122/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.2224 - acc: 0.9833 - val_loss: 0.6968 - val_acc: 0.6500\n",
            "Epoch 123/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.2386 - acc: 1.0000 - val_loss: 0.6828 - val_acc: 0.6500\n",
            "Epoch 124/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.2257 - acc: 0.9667 - val_loss: 0.6689 - val_acc: 0.6500\n",
            "Epoch 125/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.2196 - acc: 0.9833 - val_loss: 0.6513 - val_acc: 0.6000\n",
            "Epoch 126/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.2068 - acc: 0.9833 - val_loss: 0.6457 - val_acc: 0.6000\n",
            "Epoch 127/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.2396 - acc: 0.9833 - val_loss: 0.6478 - val_acc: 0.6000\n",
            "Epoch 128/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.2008 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.6000\n",
            "Epoch 129/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.2393 - acc: 0.9833 - val_loss: 0.6937 - val_acc: 0.6500\n",
            "Epoch 130/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2508 - acc: 0.9667 - val_loss: 0.7336 - val_acc: 0.6000\n",
            "Epoch 131/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.2114 - acc: 0.9833 - val_loss: 0.7359 - val_acc: 0.6000\n",
            "Epoch 132/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.2160 - acc: 1.0000 - val_loss: 0.7276 - val_acc: 0.6000\n",
            "Epoch 133/500\n",
            "60/60 [==============================] - 0s 703us/sample - loss: 0.2345 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 0.6000\n",
            "Epoch 134/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2472 - acc: 0.9833 - val_loss: 0.7148 - val_acc: 0.6500\n",
            "Epoch 135/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.2373 - acc: 0.9500 - val_loss: 0.6941 - val_acc: 0.6500\n",
            "Epoch 136/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.2587 - acc: 0.9667 - val_loss: 0.6635 - val_acc: 0.6000\n",
            "Epoch 137/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1989 - acc: 0.9833 - val_loss: 0.6503 - val_acc: 0.6000\n",
            "Epoch 138/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.2042 - acc: 0.9833 - val_loss: 0.6408 - val_acc: 0.6000\n",
            "Epoch 139/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.2013 - acc: 1.0000 - val_loss: 0.6368 - val_acc: 0.6500\n",
            "Epoch 140/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1979 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.6500\n",
            "Epoch 141/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.1952 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 0.6500\n",
            "Epoch 142/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.2096 - acc: 0.9833 - val_loss: 0.6419 - val_acc: 0.6500\n",
            "Epoch 143/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.1847 - acc: 0.9833 - val_loss: 0.6504 - val_acc: 0.6000\n",
            "Epoch 144/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1993 - acc: 0.9833 - val_loss: 0.6523 - val_acc: 0.6000\n",
            "Epoch 145/500\n",
            "60/60 [==============================] - 0s 718us/sample - loss: 0.1850 - acc: 0.9833 - val_loss: 0.6579 - val_acc: 0.6000\n",
            "Epoch 146/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.2020 - acc: 0.9833 - val_loss: 0.6662 - val_acc: 0.6000\n",
            "Epoch 147/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1895 - acc: 0.9833 - val_loss: 0.6768 - val_acc: 0.6000\n",
            "Epoch 148/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.1745 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 0.6000\n",
            "Epoch 149/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1979 - acc: 1.0000 - val_loss: 0.6936 - val_acc: 0.5500\n",
            "Epoch 150/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.2075 - acc: 0.9667 - val_loss: 0.6860 - val_acc: 0.6000\n",
            "Epoch 151/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1676 - acc: 0.9833 - val_loss: 0.6812 - val_acc: 0.6000\n",
            "Epoch 152/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.2292 - acc: 0.9833 - val_loss: 0.6673 - val_acc: 0.6000\n",
            "Epoch 153/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.2007 - acc: 0.9667 - val_loss: 0.6491 - val_acc: 0.6000\n",
            "Epoch 154/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.1767 - acc: 0.9833 - val_loss: 0.6275 - val_acc: 0.6500\n",
            "Epoch 155/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.2357 - acc: 0.9000 - val_loss: 0.6053 - val_acc: 0.7000\n",
            "Epoch 156/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.1755 - acc: 0.9833 - val_loss: 0.5970 - val_acc: 0.7000\n",
            "Epoch 157/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.1985 - acc: 0.9833 - val_loss: 0.5869 - val_acc: 0.7000\n",
            "Epoch 158/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1630 - acc: 0.9833 - val_loss: 0.5831 - val_acc: 0.7000\n",
            "Epoch 159/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.2020 - acc: 0.9833 - val_loss: 0.5740 - val_acc: 0.7000\n",
            "Epoch 160/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.2260 - acc: 0.9667 - val_loss: 0.5771 - val_acc: 0.7000\n",
            "Epoch 161/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.2151 - acc: 0.9500 - val_loss: 0.5622 - val_acc: 0.7000\n",
            "Epoch 162/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1628 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.7000\n",
            "Epoch 163/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1679 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.7000\n",
            "Epoch 164/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1806 - acc: 1.0000 - val_loss: 0.5620 - val_acc: 0.7000\n",
            "Epoch 165/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.1727 - acc: 0.9833 - val_loss: 0.5620 - val_acc: 0.7000\n",
            "Epoch 166/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.1727 - acc: 0.9833 - val_loss: 0.5713 - val_acc: 0.7000\n",
            "Epoch 167/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.1757 - acc: 0.9833 - val_loss: 0.5889 - val_acc: 0.7000\n",
            "Epoch 168/500\n",
            "60/60 [==============================] - 0s 716us/sample - loss: 0.1480 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.7000\n",
            "Epoch 169/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.2130 - acc: 0.9500 - val_loss: 0.5961 - val_acc: 0.7000\n",
            "Epoch 170/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1717 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.7000\n",
            "Epoch 171/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1709 - acc: 0.9833 - val_loss: 0.5909 - val_acc: 0.7000\n",
            "Epoch 172/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1774 - acc: 0.9667 - val_loss: 0.5852 - val_acc: 0.7000\n",
            "Epoch 173/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1738 - acc: 1.0000 - val_loss: 0.5938 - val_acc: 0.6500\n",
            "Epoch 174/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1732 - acc: 1.0000 - val_loss: 0.6001 - val_acc: 0.6500\n",
            "Epoch 175/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.1850 - acc: 0.9667 - val_loss: 0.5979 - val_acc: 0.6500\n",
            "Epoch 176/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1465 - acc: 1.0000 - val_loss: 0.6052 - val_acc: 0.6500\n",
            "Epoch 177/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1574 - acc: 1.0000 - val_loss: 0.6067 - val_acc: 0.6500\n",
            "Epoch 178/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.1726 - acc: 0.9667 - val_loss: 0.6005 - val_acc: 0.7000\n",
            "Epoch 179/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1687 - acc: 0.9833 - val_loss: 0.5962 - val_acc: 0.7000\n",
            "Epoch 180/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.1533 - acc: 0.9833 - val_loss: 0.5949 - val_acc: 0.7000\n",
            "Epoch 181/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.1614 - acc: 0.9833 - val_loss: 0.5940 - val_acc: 0.7000\n",
            "Epoch 182/500\n",
            "60/60 [==============================] - 0s 698us/sample - loss: 0.1717 - acc: 0.9833 - val_loss: 0.5950 - val_acc: 0.7000\n",
            "Epoch 183/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1868 - acc: 0.9500 - val_loss: 0.5716 - val_acc: 0.7000\n",
            "Epoch 184/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1294 - acc: 1.0000 - val_loss: 0.5605 - val_acc: 0.7000\n",
            "Epoch 185/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.1667 - acc: 0.9833 - val_loss: 0.5435 - val_acc: 0.7000\n",
            "Epoch 186/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1603 - acc: 0.9667 - val_loss: 0.5264 - val_acc: 0.7000\n",
            "Epoch 187/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1393 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.7000\n",
            "Epoch 188/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.1776 - acc: 0.9667 - val_loss: 0.4817 - val_acc: 0.7000\n",
            "Epoch 189/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.1242 - acc: 1.0000 - val_loss: 0.4603 - val_acc: 0.8000\n",
            "Epoch 190/500\n",
            "60/60 [==============================] - 0s 683us/sample - loss: 0.1493 - acc: 1.0000 - val_loss: 0.4483 - val_acc: 0.8000\n",
            "Epoch 191/500\n",
            "60/60 [==============================] - 0s 687us/sample - loss: 0.1616 - acc: 1.0000 - val_loss: 0.4419 - val_acc: 0.8000\n",
            "Epoch 192/500\n",
            "60/60 [==============================] - 0s 735us/sample - loss: 0.1487 - acc: 1.0000 - val_loss: 0.4379 - val_acc: 0.8000\n",
            "Epoch 193/500\n",
            "60/60 [==============================] - 0s 676us/sample - loss: 0.1477 - acc: 0.9667 - val_loss: 0.4413 - val_acc: 0.8000\n",
            "Epoch 194/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1328 - acc: 1.0000 - val_loss: 0.4437 - val_acc: 0.8000\n",
            "Epoch 195/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1465 - acc: 0.9833 - val_loss: 0.4490 - val_acc: 0.8000\n",
            "Epoch 196/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1415 - acc: 0.9667 - val_loss: 0.4530 - val_acc: 0.8000\n",
            "Epoch 197/500\n",
            "60/60 [==============================] - 0s 675us/sample - loss: 0.1572 - acc: 0.9833 - val_loss: 0.4623 - val_acc: 0.7500\n",
            "Epoch 198/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1702 - acc: 1.0000 - val_loss: 0.4707 - val_acc: 0.7500\n",
            "Epoch 199/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1236 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.7000\n",
            "Epoch 200/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1588 - acc: 0.9500 - val_loss: 0.5023 - val_acc: 0.7000\n",
            "Epoch 201/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.1683 - acc: 0.9667 - val_loss: 0.5023 - val_acc: 0.7000\n",
            "Epoch 202/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.1897 - acc: 0.9167 - val_loss: 0.5044 - val_acc: 0.7000\n",
            "Epoch 203/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.1219 - acc: 1.0000 - val_loss: 0.5141 - val_acc: 0.7000\n",
            "Epoch 204/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1518 - acc: 0.9667 - val_loss: 0.5108 - val_acc: 0.7000\n",
            "Epoch 205/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.1485 - acc: 1.0000 - val_loss: 0.4846 - val_acc: 0.7000\n",
            "Epoch 206/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.7000\n",
            "Epoch 207/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.1279 - acc: 0.9833 - val_loss: 0.4620 - val_acc: 0.7000\n",
            "Epoch 208/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.1269 - acc: 0.9667 - val_loss: 0.4544 - val_acc: 0.7500\n",
            "Epoch 209/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1322 - acc: 1.0000 - val_loss: 0.4483 - val_acc: 0.7500\n",
            "Epoch 210/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1356 - acc: 1.0000 - val_loss: 0.4409 - val_acc: 0.7500\n",
            "Epoch 211/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.1385 - acc: 1.0000 - val_loss: 0.4380 - val_acc: 0.7500\n",
            "Epoch 212/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.2142 - acc: 0.9500 - val_loss: 0.4467 - val_acc: 0.7000\n",
            "Epoch 213/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1018 - acc: 1.0000 - val_loss: 0.4497 - val_acc: 0.7000\n",
            "Epoch 214/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.1289 - acc: 1.0000 - val_loss: 0.4528 - val_acc: 0.7000\n",
            "Epoch 215/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.1297 - acc: 1.0000 - val_loss: 0.4554 - val_acc: 0.7500\n",
            "Epoch 216/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1515 - acc: 1.0000 - val_loss: 0.4504 - val_acc: 0.7500\n",
            "Epoch 217/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1214 - acc: 0.9833 - val_loss: 0.4470 - val_acc: 0.7500\n",
            "Epoch 218/500\n",
            "60/60 [==============================] - 0s 680us/sample - loss: 0.1646 - acc: 0.9667 - val_loss: 0.4405 - val_acc: 0.8000\n",
            "Epoch 219/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1287 - acc: 0.9833 - val_loss: 0.4333 - val_acc: 0.8000\n",
            "Epoch 220/500\n",
            "60/60 [==============================] - 0s 596us/sample - loss: 0.1319 - acc: 1.0000 - val_loss: 0.4268 - val_acc: 0.8500\n",
            "Epoch 221/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1103 - acc: 1.0000 - val_loss: 0.4220 - val_acc: 0.8500\n",
            "Epoch 222/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1038 - acc: 0.9833 - val_loss: 0.4193 - val_acc: 0.8500\n",
            "Epoch 223/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.1159 - acc: 1.0000 - val_loss: 0.4179 - val_acc: 0.8500\n",
            "Epoch 224/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.1103 - acc: 1.0000 - val_loss: 0.4166 - val_acc: 0.8500\n",
            "Epoch 225/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.1212 - acc: 0.9833 - val_loss: 0.4164 - val_acc: 0.8500\n",
            "Epoch 226/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1141 - acc: 1.0000 - val_loss: 0.4157 - val_acc: 0.8500\n",
            "Epoch 227/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1018 - acc: 1.0000 - val_loss: 0.4167 - val_acc: 0.8500\n",
            "Epoch 228/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.1213 - acc: 1.0000 - val_loss: 0.4184 - val_acc: 0.8500\n",
            "Epoch 229/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.1140 - acc: 0.9833 - val_loss: 0.4175 - val_acc: 0.8500\n",
            "Epoch 230/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0844 - acc: 1.0000 - val_loss: 0.4190 - val_acc: 0.8500\n",
            "Epoch 231/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1003 - acc: 1.0000 - val_loss: 0.4217 - val_acc: 0.8500\n",
            "Epoch 232/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.1302 - acc: 1.0000 - val_loss: 0.4216 - val_acc: 0.8500\n",
            "Epoch 233/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1139 - acc: 0.9667 - val_loss: 0.4251 - val_acc: 0.8500\n",
            "Epoch 234/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.1098 - acc: 1.0000 - val_loss: 0.4305 - val_acc: 0.8000\n",
            "Epoch 235/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.1043 - acc: 1.0000 - val_loss: 0.4424 - val_acc: 0.7500\n",
            "Epoch 236/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.1207 - acc: 1.0000 - val_loss: 0.4542 - val_acc: 0.7500\n",
            "Epoch 237/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0998 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.7000\n",
            "Epoch 238/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.1095 - acc: 1.0000 - val_loss: 0.4589 - val_acc: 0.7000\n",
            "Epoch 239/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1027 - acc: 1.0000 - val_loss: 0.4542 - val_acc: 0.7500\n",
            "Epoch 240/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.1345 - acc: 0.9500 - val_loss: 0.4503 - val_acc: 0.8000\n",
            "Epoch 241/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1208 - acc: 0.9667 - val_loss: 0.4479 - val_acc: 0.8000\n",
            "Epoch 242/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.1318 - acc: 1.0000 - val_loss: 0.4374 - val_acc: 0.8000\n",
            "Epoch 243/500\n",
            "60/60 [==============================] - 0s 714us/sample - loss: 0.1394 - acc: 0.9833 - val_loss: 0.4222 - val_acc: 0.8000\n",
            "Epoch 244/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.1056 - acc: 1.0000 - val_loss: 0.4063 - val_acc: 0.8500\n",
            "Epoch 245/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0962 - acc: 0.9833 - val_loss: 0.3974 - val_acc: 0.9000\n",
            "Epoch 246/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0898 - acc: 1.0000 - val_loss: 0.3915 - val_acc: 0.9000\n",
            "Epoch 247/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0754 - acc: 1.0000 - val_loss: 0.3916 - val_acc: 0.9000\n",
            "Epoch 248/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1087 - acc: 1.0000 - val_loss: 0.3912 - val_acc: 0.9000\n",
            "Epoch 249/500\n",
            "60/60 [==============================] - 0s 720us/sample - loss: 0.0990 - acc: 0.9833 - val_loss: 0.3892 - val_acc: 0.9000\n",
            "Epoch 250/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.1016 - acc: 1.0000 - val_loss: 0.3892 - val_acc: 0.9000\n",
            "Epoch 251/500\n",
            "60/60 [==============================] - 0s 646us/sample - loss: 0.1037 - acc: 1.0000 - val_loss: 0.3887 - val_acc: 0.9000\n",
            "Epoch 252/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0915 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 0.9000\n",
            "Epoch 253/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0928 - acc: 1.0000 - val_loss: 0.3896 - val_acc: 0.9000\n",
            "Epoch 254/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1080 - acc: 1.0000 - val_loss: 0.3931 - val_acc: 0.9000\n",
            "Epoch 255/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.1195 - acc: 1.0000 - val_loss: 0.3949 - val_acc: 0.9000\n",
            "Epoch 256/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.1049 - acc: 1.0000 - val_loss: 0.3915 - val_acc: 0.9000\n",
            "Epoch 257/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0968 - acc: 1.0000 - val_loss: 0.3888 - val_acc: 0.8500\n",
            "Epoch 258/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.1181 - acc: 0.9833 - val_loss: 0.3869 - val_acc: 0.8500\n",
            "Epoch 259/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.1319 - acc: 0.9833 - val_loss: 0.3862 - val_acc: 0.8000\n",
            "Epoch 260/500\n",
            "60/60 [==============================] - 0s 694us/sample - loss: 0.1051 - acc: 0.9833 - val_loss: 0.3858 - val_acc: 0.8000\n",
            "Epoch 261/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0841 - acc: 1.0000 - val_loss: 0.3853 - val_acc: 0.8000\n",
            "Epoch 262/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.3854 - val_acc: 0.8500\n",
            "Epoch 263/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.1109 - acc: 1.0000 - val_loss: 0.3814 - val_acc: 0.8500\n",
            "Epoch 264/500\n",
            "60/60 [==============================] - 0s 608us/sample - loss: 0.0997 - acc: 1.0000 - val_loss: 0.3815 - val_acc: 0.9000\n",
            "Epoch 265/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0781 - acc: 1.0000 - val_loss: 0.3864 - val_acc: 0.9000\n",
            "Epoch 266/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0803 - acc: 1.0000 - val_loss: 0.3937 - val_acc: 0.9000\n",
            "Epoch 267/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0852 - acc: 1.0000 - val_loss: 0.4020 - val_acc: 0.9000\n",
            "Epoch 268/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0860 - acc: 1.0000 - val_loss: 0.4055 - val_acc: 0.9000\n",
            "Epoch 269/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.1058 - acc: 0.9833 - val_loss: 0.4081 - val_acc: 0.9000\n",
            "Epoch 270/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0817 - acc: 1.0000 - val_loss: 0.4083 - val_acc: 0.9000\n",
            "Epoch 271/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0858 - acc: 1.0000 - val_loss: 0.4130 - val_acc: 0.8500\n",
            "Epoch 272/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.1263 - acc: 0.9667 - val_loss: 0.4199 - val_acc: 0.8000\n",
            "Epoch 273/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.1008 - acc: 1.0000 - val_loss: 0.4384 - val_acc: 0.8000\n",
            "Epoch 274/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0825 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.8000\n",
            "Epoch 275/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0793 - acc: 1.0000 - val_loss: 0.4756 - val_acc: 0.8000\n",
            "Epoch 276/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0947 - acc: 0.9833 - val_loss: 0.4917 - val_acc: 0.7500\n",
            "Epoch 277/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0904 - acc: 1.0000 - val_loss: 0.4992 - val_acc: 0.7500\n",
            "Epoch 278/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.1058 - acc: 0.9833 - val_loss: 0.4881 - val_acc: 0.8000\n",
            "Epoch 279/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.4742 - val_acc: 0.8000\n",
            "Epoch 280/500\n",
            "60/60 [==============================] - 0s 643us/sample - loss: 0.0973 - acc: 1.0000 - val_loss: 0.4575 - val_acc: 0.8000\n",
            "Epoch 281/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0905 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.8000\n",
            "Epoch 282/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0795 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 0.8000\n",
            "Epoch 283/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0899 - acc: 1.0000 - val_loss: 0.4568 - val_acc: 0.8000\n",
            "Epoch 284/500\n",
            "60/60 [==============================] - 0s 661us/sample - loss: 0.1058 - acc: 0.9833 - val_loss: 0.4614 - val_acc: 0.8000\n",
            "Epoch 285/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.1175 - acc: 1.0000 - val_loss: 0.4617 - val_acc: 0.8000\n",
            "Epoch 286/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.1015 - acc: 1.0000 - val_loss: 0.4596 - val_acc: 0.8000\n",
            "Epoch 287/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0958 - acc: 0.9833 - val_loss: 0.4598 - val_acc: 0.8000\n",
            "Epoch 288/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.4477 - val_acc: 0.8000\n",
            "Epoch 289/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0775 - acc: 0.9833 - val_loss: 0.4332 - val_acc: 0.8000\n",
            "Epoch 290/500\n",
            "60/60 [==============================] - 0s 605us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.4215 - val_acc: 0.8000\n",
            "Epoch 291/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0892 - acc: 1.0000 - val_loss: 0.4120 - val_acc: 0.9000\n",
            "Epoch 292/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0875 - acc: 1.0000 - val_loss: 0.4065 - val_acc: 0.9000\n",
            "Epoch 293/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.4047 - val_acc: 0.9000\n",
            "Epoch 294/500\n",
            "60/60 [==============================] - 0s 670us/sample - loss: 0.0669 - acc: 1.0000 - val_loss: 0.4037 - val_acc: 0.9000\n",
            "Epoch 295/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0902 - acc: 1.0000 - val_loss: 0.4093 - val_acc: 0.9000\n",
            "Epoch 296/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0846 - acc: 0.9833 - val_loss: 0.4156 - val_acc: 0.9000\n",
            "Epoch 297/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0914 - acc: 0.9833 - val_loss: 0.4144 - val_acc: 0.9000\n",
            "Epoch 298/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.9000\n",
            "Epoch 299/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0687 - acc: 1.0000 - val_loss: 0.4007 - val_acc: 0.9000\n",
            "Epoch 300/500\n",
            "60/60 [==============================] - 0s 665us/sample - loss: 0.0730 - acc: 1.0000 - val_loss: 0.3969 - val_acc: 0.9000\n",
            "Epoch 301/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.1002 - acc: 0.9833 - val_loss: 0.3877 - val_acc: 0.9000\n",
            "Epoch 302/500\n",
            "60/60 [==============================] - 0s 697us/sample - loss: 0.0736 - acc: 1.0000 - val_loss: 0.3810 - val_acc: 0.9000\n",
            "Epoch 303/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0699 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.9000\n",
            "Epoch 304/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.3894 - val_acc: 0.9000\n",
            "Epoch 305/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0899 - acc: 0.9833 - val_loss: 0.3940 - val_acc: 0.9000\n",
            "Epoch 306/500\n",
            "60/60 [==============================] - 0s 629us/sample - loss: 0.1123 - acc: 0.9833 - val_loss: 0.4047 - val_acc: 0.9000\n",
            "Epoch 307/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0704 - acc: 1.0000 - val_loss: 0.4109 - val_acc: 0.9000\n",
            "Epoch 308/500\n",
            "60/60 [==============================] - 0s 695us/sample - loss: 0.0671 - acc: 1.0000 - val_loss: 0.4139 - val_acc: 0.9000\n",
            "Epoch 309/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0959 - acc: 0.9667 - val_loss: 0.4103 - val_acc: 0.9000\n",
            "Epoch 310/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0777 - acc: 0.9833 - val_loss: 0.4105 - val_acc: 0.9000\n",
            "Epoch 311/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0675 - acc: 1.0000 - val_loss: 0.4128 - val_acc: 0.9000\n",
            "Epoch 312/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.4097 - val_acc: 0.9000\n",
            "Epoch 313/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0833 - acc: 0.9833 - val_loss: 0.4062 - val_acc: 0.9000\n",
            "Epoch 314/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.0599 - acc: 1.0000 - val_loss: 0.4009 - val_acc: 0.9000\n",
            "Epoch 315/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.3905 - val_acc: 0.9000\n",
            "Epoch 316/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0707 - acc: 1.0000 - val_loss: 0.3820 - val_acc: 0.9000\n",
            "Epoch 317/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0554 - acc: 1.0000 - val_loss: 0.3714 - val_acc: 0.9000\n",
            "Epoch 318/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0866 - acc: 0.9833 - val_loss: 0.3695 - val_acc: 0.9000\n",
            "Epoch 319/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0741 - acc: 1.0000 - val_loss: 0.3761 - val_acc: 0.9000\n",
            "Epoch 320/500\n",
            "60/60 [==============================] - 0s 678us/sample - loss: 0.0814 - acc: 0.9833 - val_loss: 0.3906 - val_acc: 0.9000\n",
            "Epoch 321/500\n",
            "60/60 [==============================] - 0s 692us/sample - loss: 0.0794 - acc: 0.9833 - val_loss: 0.4146 - val_acc: 0.9000\n",
            "Epoch 322/500\n",
            "60/60 [==============================] - 0s 611us/sample - loss: 0.0983 - acc: 0.9833 - val_loss: 0.4219 - val_acc: 0.9000\n",
            "Epoch 323/500\n",
            "60/60 [==============================] - 0s 668us/sample - loss: 0.0659 - acc: 0.9833 - val_loss: 0.4266 - val_acc: 0.9000\n",
            "Epoch 324/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0608 - acc: 1.0000 - val_loss: 0.4274 - val_acc: 0.9000\n",
            "Epoch 325/500\n",
            "60/60 [==============================] - 0s 672us/sample - loss: 0.0807 - acc: 1.0000 - val_loss: 0.4259 - val_acc: 0.8500\n",
            "Epoch 326/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.4249 - val_acc: 0.8500\n",
            "Epoch 327/500\n",
            "60/60 [==============================] - 0s 618us/sample - loss: 0.0581 - acc: 1.0000 - val_loss: 0.4213 - val_acc: 0.8500\n",
            "Epoch 328/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0788 - acc: 1.0000 - val_loss: 0.4201 - val_acc: 0.9000\n",
            "Epoch 329/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0612 - acc: 1.0000 - val_loss: 0.4168 - val_acc: 0.9000\n",
            "Epoch 330/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.4114 - val_acc: 0.9000\n",
            "Epoch 331/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0598 - acc: 1.0000 - val_loss: 0.4039 - val_acc: 0.9000\n",
            "Epoch 332/500\n",
            "60/60 [==============================] - 0s 715us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.9000\n",
            "Epoch 333/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.0625 - acc: 0.9833 - val_loss: 0.3867 - val_acc: 0.9000\n",
            "Epoch 334/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0584 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 0.9000\n",
            "Epoch 335/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.3997 - val_acc: 0.9000\n",
            "Epoch 336/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.4077 - val_acc: 0.9000\n",
            "Epoch 337/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0855 - acc: 1.0000 - val_loss: 0.4140 - val_acc: 0.9000\n",
            "Epoch 338/500\n",
            "60/60 [==============================] - 0s 610us/sample - loss: 0.0678 - acc: 1.0000 - val_loss: 0.4294 - val_acc: 0.9000\n",
            "Epoch 339/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.4348 - val_acc: 0.9000\n",
            "Epoch 340/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.4366 - val_acc: 0.9000\n",
            "Epoch 341/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0742 - acc: 1.0000 - val_loss: 0.4414 - val_acc: 0.9000\n",
            "Epoch 342/500\n",
            "60/60 [==============================] - 0s 684us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.4461 - val_acc: 0.9000\n",
            "Epoch 343/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.1128 - acc: 0.9833 - val_loss: 0.4535 - val_acc: 0.9000\n",
            "Epoch 344/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0622 - acc: 1.0000 - val_loss: 0.4554 - val_acc: 0.9000\n",
            "Epoch 345/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0699 - acc: 0.9833 - val_loss: 0.4582 - val_acc: 0.9000\n",
            "Epoch 346/500\n",
            "60/60 [==============================] - 0s 667us/sample - loss: 0.0902 - acc: 0.9833 - val_loss: 0.4647 - val_acc: 0.9000\n",
            "Epoch 347/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0696 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.8500\n",
            "Epoch 348/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0682 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.8500\n",
            "Epoch 349/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0844 - acc: 0.9833 - val_loss: 0.4846 - val_acc: 0.9000\n",
            "Epoch 350/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.4794 - val_acc: 0.9000\n",
            "Epoch 351/500\n",
            "60/60 [==============================] - 0s 688us/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8500\n",
            "Epoch 352/500\n",
            "60/60 [==============================] - 0s 619us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.4684 - val_acc: 0.8500\n",
            "Epoch 353/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0472 - acc: 1.0000 - val_loss: 0.4597 - val_acc: 0.8500\n",
            "Epoch 354/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.4432 - val_acc: 0.8500\n",
            "Epoch 355/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0706 - acc: 1.0000 - val_loss: 0.4318 - val_acc: 0.8500\n",
            "Epoch 356/500\n",
            "60/60 [==============================] - 0s 664us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.4245 - val_acc: 0.8500\n",
            "Epoch 357/500\n",
            "60/60 [==============================] - 0s 746us/sample - loss: 0.0798 - acc: 0.9833 - val_loss: 0.4258 - val_acc: 0.8500\n",
            "Epoch 358/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.4278 - val_acc: 0.8500\n",
            "Epoch 359/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0597 - acc: 1.0000 - val_loss: 0.4314 - val_acc: 0.9000\n",
            "Epoch 360/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.4340 - val_acc: 0.9000\n",
            "Epoch 361/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0641 - acc: 1.0000 - val_loss: 0.4314 - val_acc: 0.9000\n",
            "Epoch 362/500\n",
            "60/60 [==============================] - 0s 593us/sample - loss: 0.0655 - acc: 1.0000 - val_loss: 0.4293 - val_acc: 0.9000\n",
            "Epoch 363/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.1318 - acc: 0.9500 - val_loss: 0.4237 - val_acc: 0.9000\n",
            "Epoch 364/500\n",
            "60/60 [==============================] - 0s 606us/sample - loss: 0.0681 - acc: 0.9833 - val_loss: 0.4170 - val_acc: 0.9000\n",
            "Epoch 365/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0792 - acc: 0.9833 - val_loss: 0.4157 - val_acc: 0.8500\n",
            "Epoch 366/500\n",
            "60/60 [==============================] - 0s 658us/sample - loss: 0.0726 - acc: 1.0000 - val_loss: 0.4075 - val_acc: 0.8000\n",
            "Epoch 367/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.4050 - val_acc: 0.8000\n",
            "Epoch 368/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.4085 - val_acc: 0.8000\n",
            "Epoch 369/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.0611 - acc: 1.0000 - val_loss: 0.4064 - val_acc: 0.8500\n",
            "Epoch 370/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0659 - acc: 0.9833 - val_loss: 0.4060 - val_acc: 0.8500\n",
            "Epoch 371/500\n",
            "60/60 [==============================] - 0s 640us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.4105 - val_acc: 0.8500\n",
            "Epoch 372/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.4185 - val_acc: 0.9000\n",
            "Epoch 373/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.4221 - val_acc: 0.9000\n",
            "Epoch 374/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.4204 - val_acc: 0.8500\n",
            "Epoch 375/500\n",
            "60/60 [==============================] - 0s 588us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.4200 - val_acc: 0.8500\n",
            "Epoch 376/500\n",
            "60/60 [==============================] - 0s 623us/sample - loss: 0.0686 - acc: 0.9833 - val_loss: 0.4204 - val_acc: 0.8500\n",
            "Epoch 377/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.4190 - val_acc: 0.8500\n",
            "Epoch 378/500\n",
            "60/60 [==============================] - 0s 604us/sample - loss: 0.0680 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.9000\n",
            "Epoch 379/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0570 - acc: 1.0000 - val_loss: 0.4160 - val_acc: 0.9000\n",
            "Epoch 380/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0519 - acc: 1.0000 - val_loss: 0.4133 - val_acc: 0.9000\n",
            "Epoch 381/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0536 - acc: 1.0000 - val_loss: 0.4110 - val_acc: 0.9000\n",
            "Epoch 382/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.4064 - val_acc: 0.9000\n",
            "Epoch 383/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.4030 - val_acc: 0.9000\n",
            "Epoch 384/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.3979 - val_acc: 0.9000\n",
            "Epoch 385/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0709 - acc: 1.0000 - val_loss: 0.3930 - val_acc: 0.9000\n",
            "Epoch 386/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0805 - acc: 0.9667 - val_loss: 0.3958 - val_acc: 0.9000\n",
            "Epoch 387/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0546 - acc: 1.0000 - val_loss: 0.3979 - val_acc: 0.9000\n",
            "Epoch 388/500\n",
            "60/60 [==============================] - 0s 585us/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 0.4030 - val_acc: 0.9000\n",
            "Epoch 389/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0598 - acc: 0.9833 - val_loss: 0.4048 - val_acc: 0.9000\n",
            "Epoch 390/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0786 - acc: 0.9833 - val_loss: 0.4068 - val_acc: 0.9000\n",
            "Epoch 391/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.8500\n",
            "Epoch 392/500\n",
            "60/60 [==============================] - 0s 603us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.4232 - val_acc: 0.9000\n",
            "Epoch 393/500\n",
            "60/60 [==============================] - 0s 648us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.4387 - val_acc: 0.8500\n",
            "Epoch 394/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.4594 - val_acc: 0.8500\n",
            "Epoch 395/500\n",
            "60/60 [==============================] - 0s 590us/sample - loss: 0.0421 - acc: 1.0000 - val_loss: 0.4823 - val_acc: 0.8500\n",
            "Epoch 396/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8500\n",
            "Epoch 397/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0601 - acc: 0.9833 - val_loss: 0.5009 - val_acc: 0.9000\n",
            "Epoch 398/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0804 - acc: 0.9833 - val_loss: 0.5164 - val_acc: 0.9000\n",
            "Epoch 399/500\n",
            "60/60 [==============================] - 0s 653us/sample - loss: 0.0560 - acc: 0.9833 - val_loss: 0.5129 - val_acc: 0.9000\n",
            "Epoch 400/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0615 - acc: 0.9833 - val_loss: 0.5117 - val_acc: 0.9000\n",
            "Epoch 401/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0510 - acc: 1.0000 - val_loss: 0.4921 - val_acc: 0.9000\n",
            "Epoch 402/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0845 - acc: 0.9833 - val_loss: 0.4630 - val_acc: 0.9000\n",
            "Epoch 403/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.4463 - val_acc: 0.9000\n",
            "Epoch 404/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.4496 - val_acc: 0.9000\n",
            "Epoch 405/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.4604 - val_acc: 0.9000\n",
            "Epoch 406/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.4739 - val_acc: 0.9000\n",
            "Epoch 407/500\n",
            "60/60 [==============================] - 0s 652us/sample - loss: 0.0547 - acc: 0.9833 - val_loss: 0.4952 - val_acc: 0.9000\n",
            "Epoch 408/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.5098 - val_acc: 0.9000\n",
            "Epoch 409/500\n",
            "60/60 [==============================] - 0s 631us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.5194 - val_acc: 0.9000\n",
            "Epoch 410/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 0.5383 - val_acc: 0.8500\n",
            "Epoch 411/500\n",
            "60/60 [==============================] - 0s 616us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.8500\n",
            "Epoch 412/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.5640 - val_acc: 0.8500\n",
            "Epoch 413/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.5527 - val_acc: 0.8500\n",
            "Epoch 414/500\n",
            "60/60 [==============================] - 0s 601us/sample - loss: 0.0565 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.8500\n",
            "Epoch 415/500\n",
            "60/60 [==============================] - 0s 650us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.8500\n",
            "Epoch 416/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.5011 - val_acc: 0.8500\n",
            "Epoch 417/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8500\n",
            "Epoch 418/500\n",
            "60/60 [==============================] - 0s 589us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.4690 - val_acc: 0.8500\n",
            "Epoch 419/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.4519 - val_acc: 0.8500\n",
            "Epoch 420/500\n",
            "60/60 [==============================] - 0s 657us/sample - loss: 0.0527 - acc: 1.0000 - val_loss: 0.4368 - val_acc: 0.8500\n",
            "Epoch 421/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.4394 - val_acc: 0.8500\n",
            "Epoch 422/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.4509 - val_acc: 0.8500\n",
            "Epoch 423/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0608 - acc: 1.0000 - val_loss: 0.4553 - val_acc: 0.8500\n",
            "Epoch 424/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.4587 - val_acc: 0.8500\n",
            "Epoch 425/500\n",
            "60/60 [==============================] - 0s 598us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.4499 - val_acc: 0.9000\n",
            "Epoch 426/500\n",
            "60/60 [==============================] - 0s 607us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.4281 - val_acc: 0.9000\n",
            "Epoch 427/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0659 - acc: 0.9667 - val_loss: 0.4098 - val_acc: 0.9000\n",
            "Epoch 428/500\n",
            "60/60 [==============================] - 0s 594us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.3869 - val_acc: 0.8500\n",
            "Epoch 429/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.3696 - val_acc: 0.9000\n",
            "Epoch 430/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0458 - acc: 1.0000 - val_loss: 0.3635 - val_acc: 0.9000\n",
            "Epoch 431/500\n",
            "60/60 [==============================] - 0s 690us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.3648 - val_acc: 0.9000\n",
            "Epoch 432/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.3634 - val_acc: 0.9000\n",
            "Epoch 433/500\n",
            "60/60 [==============================] - 0s 612us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.3659 - val_acc: 0.9000\n",
            "Epoch 434/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0578 - acc: 1.0000 - val_loss: 0.3674 - val_acc: 0.9000\n",
            "Epoch 435/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0839 - acc: 0.9833 - val_loss: 0.3776 - val_acc: 0.9000\n",
            "Epoch 436/500\n",
            "60/60 [==============================] - 0s 663us/sample - loss: 0.0582 - acc: 1.0000 - val_loss: 0.3829 - val_acc: 0.9000\n",
            "Epoch 437/500\n",
            "60/60 [==============================] - 0s 659us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.9000\n",
            "Epoch 438/500\n",
            "60/60 [==============================] - 0s 595us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.4034 - val_acc: 0.9000\n",
            "Epoch 439/500\n",
            "60/60 [==============================] - 0s 660us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.4090 - val_acc: 0.9000\n",
            "Epoch 440/500\n",
            "60/60 [==============================] - 0s 645us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.4074 - val_acc: 0.9000\n",
            "Epoch 441/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.4050 - val_acc: 0.9000\n",
            "Epoch 442/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.4043 - val_acc: 0.9000\n",
            "Epoch 443/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.4076 - val_acc: 0.8500\n",
            "Epoch 444/500\n",
            "60/60 [==============================] - 0s 638us/sample - loss: 0.0548 - acc: 1.0000 - val_loss: 0.4105 - val_acc: 0.8500\n",
            "Epoch 445/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0728 - acc: 0.9833 - val_loss: 0.4289 - val_acc: 0.8500\n",
            "Epoch 446/500\n",
            "60/60 [==============================] - 0s 651us/sample - loss: 0.0564 - acc: 1.0000 - val_loss: 0.4468 - val_acc: 0.8500\n",
            "Epoch 447/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0510 - acc: 0.9833 - val_loss: 0.4648 - val_acc: 0.8500\n",
            "Epoch 448/500\n",
            "60/60 [==============================] - 0s 591us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.9000\n",
            "Epoch 449/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0632 - acc: 1.0000 - val_loss: 0.5049 - val_acc: 0.9000\n",
            "Epoch 450/500\n",
            "60/60 [==============================] - 0s 586us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.5224 - val_acc: 0.9000\n",
            "Epoch 451/500\n",
            "60/60 [==============================] - 0s 630us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.5459 - val_acc: 0.9000\n",
            "Epoch 452/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.8500\n",
            "Epoch 453/500\n",
            "60/60 [==============================] - 0s 620us/sample - loss: 0.0411 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.8500\n",
            "Epoch 454/500\n",
            "60/60 [==============================] - 0s 627us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.5631 - val_acc: 0.8500\n",
            "Epoch 455/500\n",
            "60/60 [==============================] - 0s 666us/sample - loss: 0.0839 - acc: 0.9667 - val_loss: 0.5491 - val_acc: 0.8500\n",
            "Epoch 456/500\n",
            "60/60 [==============================] - 0s 669us/sample - loss: 0.0764 - acc: 0.9667 - val_loss: 0.5249 - val_acc: 0.9000\n",
            "Epoch 457/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.5053 - val_acc: 0.9000\n",
            "Epoch 458/500\n",
            "60/60 [==============================] - 0s 600us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.4941 - val_acc: 0.9000\n",
            "Epoch 459/500\n",
            "60/60 [==============================] - 0s 644us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.9000\n",
            "Epoch 460/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.4585 - val_acc: 0.9000\n",
            "Epoch 461/500\n",
            "60/60 [==============================] - 0s 622us/sample - loss: 0.0621 - acc: 0.9833 - val_loss: 0.4547 - val_acc: 0.9000\n",
            "Epoch 462/500\n",
            "60/60 [==============================] - 0s 642us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.4542 - val_acc: 0.9000\n",
            "Epoch 463/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.4556 - val_acc: 0.9000\n",
            "Epoch 464/500\n",
            "60/60 [==============================] - 0s 836us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.4502 - val_acc: 0.9000\n",
            "Epoch 465/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0480 - acc: 1.0000 - val_loss: 0.4454 - val_acc: 0.9000\n",
            "Epoch 466/500\n",
            "60/60 [==============================] - 0s 725us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.4440 - val_acc: 0.9000\n",
            "Epoch 467/500\n",
            "60/60 [==============================] - 0s 649us/sample - loss: 0.0381 - acc: 1.0000 - val_loss: 0.4546 - val_acc: 0.9000\n",
            "Epoch 468/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.9000\n",
            "Epoch 469/500\n",
            "60/60 [==============================] - 0s 635us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.4602 - val_acc: 0.9000\n",
            "Epoch 470/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.4523 - val_acc: 0.9000\n",
            "Epoch 471/500\n",
            "60/60 [==============================] - 0s 632us/sample - loss: 0.0451 - acc: 0.9833 - val_loss: 0.4456 - val_acc: 0.8500\n",
            "Epoch 472/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0541 - acc: 0.9833 - val_loss: 0.4357 - val_acc: 0.8500\n",
            "Epoch 473/500\n",
            "60/60 [==============================] - 0s 639us/sample - loss: 0.0713 - acc: 1.0000 - val_loss: 0.4219 - val_acc: 0.8500\n",
            "Epoch 474/500\n",
            "60/60 [==============================] - 0s 624us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.4164 - val_acc: 0.8500\n",
            "Epoch 475/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.4067 - val_acc: 0.8500\n",
            "Epoch 476/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.3991 - val_acc: 0.8500\n",
            "Epoch 477/500\n",
            "60/60 [==============================] - 0s 656us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.4006 - val_acc: 0.8500\n",
            "Epoch 478/500\n",
            "60/60 [==============================] - 0s 615us/sample - loss: 0.0587 - acc: 1.0000 - val_loss: 0.4108 - val_acc: 0.8500\n",
            "Epoch 479/500\n",
            "60/60 [==============================] - 0s 636us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.4174 - val_acc: 0.8500\n",
            "Epoch 480/500\n",
            "60/60 [==============================] - 0s 634us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.4258 - val_acc: 0.8000\n",
            "Epoch 481/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.4334 - val_acc: 0.8000\n",
            "Epoch 482/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0414 - acc: 1.0000 - val_loss: 0.4291 - val_acc: 0.8000\n",
            "Epoch 483/500\n",
            "60/60 [==============================] - 0s 609us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.4200 - val_acc: 0.8000\n",
            "Epoch 484/500\n",
            "60/60 [==============================] - 0s 617us/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 0.4129 - val_acc: 0.8500\n",
            "Epoch 485/500\n",
            "60/60 [==============================] - 0s 655us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.4123 - val_acc: 0.8500\n",
            "Epoch 486/500\n",
            "60/60 [==============================] - 0s 628us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.4203 - val_acc: 0.9000\n",
            "Epoch 487/500\n",
            "60/60 [==============================] - 0s 621us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.4303 - val_acc: 0.9000\n",
            "Epoch 488/500\n",
            "60/60 [==============================] - 0s 633us/sample - loss: 0.0697 - acc: 1.0000 - val_loss: 0.4363 - val_acc: 0.9000\n",
            "Epoch 489/500\n",
            "60/60 [==============================] - 0s 647us/sample - loss: 0.0564 - acc: 0.9833 - val_loss: 0.4440 - val_acc: 0.8500\n",
            "Epoch 490/500\n",
            "60/60 [==============================] - 0s 614us/sample - loss: 0.0581 - acc: 1.0000 - val_loss: 0.4543 - val_acc: 0.8500\n",
            "Epoch 491/500\n",
            "60/60 [==============================] - 0s 637us/sample - loss: 0.0514 - acc: 1.0000 - val_loss: 0.4543 - val_acc: 0.8500\n",
            "Epoch 492/500\n",
            "60/60 [==============================] - 0s 602us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.4554 - val_acc: 0.9000\n",
            "Epoch 493/500\n",
            "60/60 [==============================] - 0s 597us/sample - loss: 0.0368 - acc: 1.0000 - val_loss: 0.4552 - val_acc: 0.9000\n",
            "Epoch 494/500\n",
            "60/60 [==============================] - 0s 625us/sample - loss: 0.0586 - acc: 1.0000 - val_loss: 0.4816 - val_acc: 0.9000\n",
            "Epoch 495/500\n",
            "60/60 [==============================] - 0s 641us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.5256 - val_acc: 0.8500\n",
            "Epoch 496/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0480 - acc: 1.0000 - val_loss: 0.5533 - val_acc: 0.8500\n",
            "Epoch 497/500\n",
            "60/60 [==============================] - 0s 654us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.5541 - val_acc: 0.8000\n",
            "Epoch 498/500\n",
            "60/60 [==============================] - 0s 626us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.8000\n",
            "Epoch 499/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0791 - acc: 1.0000 - val_loss: 0.5090 - val_acc: 0.9000\n",
            "Epoch 500/500\n",
            "60/60 [==============================] - 0s 613us/sample - loss: 0.0329 - acc: 1.0000 - val_loss: 0.4753 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 2ms/sample - loss: 0.4057 - acc: 0.8750\n",
            "test loss, test acc: [0.40566048201580995, 0.875]\n",
            "[[0.59516541]\n",
            " [0.71589082]\n",
            " [0.90259089]\n",
            " [0.48166139]\n",
            " [0.73912647]\n",
            " [0.77220641]\n",
            " [0.4743671 ]\n",
            " [1.3608703 ]\n",
            " [1.37046369]\n",
            " [0.40566048]]\n",
            "[[0.75      ]\n",
            " [0.67500001]\n",
            " [0.60000002]\n",
            " [0.77499998]\n",
            " [0.64999998]\n",
            " [0.75      ]\n",
            " [0.75      ]\n",
            " [0.40000001]\n",
            " [0.55000001]\n",
            " [0.875     ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd6FTGs7vBI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_accl_all = pd.DataFrame({'Class1vs2': acc_all[:, 0]})\n",
        "df_accl_all.to_csv (r'EEG_Deep/df_accl_allPatient_8_24_2560:4096.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}