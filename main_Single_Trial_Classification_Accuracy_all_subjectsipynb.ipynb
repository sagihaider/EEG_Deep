{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_Single_Trial_Classification_Accuracy_all_subjectsipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/EEG_Deep/blob/master/main_Single_Trial_Classification_Accuracy_all_subjectsipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X110PE9MjrlE",
        "colab_type": "code",
        "outputId": "ce13526a-a681-476d-eb75-c05e3154fd5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/sagihaider/EEG_Deep.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEG_Deep'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 56 (delta 0), reused 0 (delta 0), pack-reused 53\n",
            "Unpacking objects: 100% (56/56), done.\n",
            "Checking out files: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLzMoiS60Qf",
        "colab_type": "code",
        "outputId": "5a75ce87-8742-4a6d-f800-5e0d646917a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "from importlib.machinery import SourceFileLoader\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEG_Deep.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjtnE_6RSpum",
        "colab_type": "code",
        "outputId": "5c4cb9ad-4efd-4afb-ec2e-98f40243a340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x= 1         \n",
        "fName = 'EEG_Deep/Data2A/Data_A0' + str(x) + 'T.mat'  # Load Data\n",
        "print(fName)\n",
        "mat = spio.loadmat(fName)\n",
        "X_tr = mat['cleanRawEEGData']\n",
        "y_tr = mat['cleanClassLabels']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_Deep/Data2A/Data_A01T.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c11RQCoS80S",
        "colab_type": "code",
        "outputId": "7266b940-bd63-4589-b1cb-0eb0edef3ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.shape(X_tr))\n",
        "print(np.shape(y_tr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 22, 1875)\n",
            "(288, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgWnQSY5T4op",
        "colab_type": "code",
        "outputId": "445bac61-c88f-4245-9aa7-4328e71235b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "# take 50/25/25 percent of the data to train/validate/test\n",
        "X_train      = X_tr[0:240,:,500:1250]\n",
        "Y_train      = y_tr[0:240]\n",
        "#X_validate   = X[151:200,:,500:1250]\n",
        "#Y_validate   = y[151:200]\n",
        "X_val       = X_tr[241:,:,500:1250]\n",
        "Y_val       = y_tr[241:]\n",
        "\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(Y_train))\n",
        "# print(np.shape(X_validate))\n",
        "# print(np.shape(Y_validate))\n",
        "print(np.shape(X_val))\n",
        "print(np.shape(Y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 22, 750)\n",
            "(240, 1)\n",
            "(47, 22, 750)\n",
            "(47, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfC8z4I-UnF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# convert labels to one-hot encodings.\n",
        "Y_train      = np_utils.to_categorical(Y_train-1)\n",
        "# Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
        "Y_val       = np_utils.to_categorical(Y_val-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqmsOU1BXOZJ",
        "colab_type": "code",
        "outputId": "d92bf080-aa77-41b7-c08e-fb3a118de882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "kernels, chans, samples = 1, 22, 750\n",
        "# convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "# contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "X_val       = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "   \n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_val.shape[0], 'val samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (240, 1, 22, 750)\n",
            "240 train samples\n",
            "47 val samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvVfScxP1juN",
        "colab_type": "code",
        "outputId": "cde697cc-b5e8-49ec-fcc7-4110e85d67ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load test data\n",
        "x= 1         \n",
        "fName = 'EEG_Deep/Data2A/Data_A0' + str(x) + 'E.mat'  # Load Data\n",
        "print(fName)\n",
        "mat = spio.loadmat(fName)\n",
        "X_ts = mat['cleanRawEEGData']\n",
        "y_ts = mat['cleanClassLabels']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_Deep/Data2A/Data_A01E.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdP4eTcM1wN3",
        "colab_type": "code",
        "outputId": "fb93c32d-f8f8-4e02-a4ac-e90886ad805e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(np.shape(X_ts))\n",
        "print(np.shape(y_ts))\n",
        "\n",
        "# take 50/25/25 percent of the data to train/validate/test\n",
        "X_test      = X_ts[:,:,500:1250]\n",
        "Y_test      = y_ts[:]\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 22, 1875)\n",
            "(288, 1)\n",
            "(288, 22, 750)\n",
            "(288, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vVDMLZp2uX6",
        "colab_type": "code",
        "outputId": "83df3448-c8d2-46f7-9dac-676e84903d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "#convert labels to one-hot encodings.\n",
        "Y_test      = np_utils.to_categorical(Y_test-1)\n",
        "\n",
        "kernels, chans, samples = 1, 22, 750\n",
        "# convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "# contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "X_test      = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "\n",
        "   \n",
        "print('X_train shape:', X_test.shape)\n",
        "print(X_test.shape[0], 'train samples')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (288, 1, 22, 750)\n",
            "288 train samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUlJdZk_X1OY",
        "colab_type": "code",
        "outputId": "38cf5a74-48e8-4408-fa1c-7fb34f4d4955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "# model configurations may do better, but this is a good starting point)\n",
        "model = EEGNet(nb_classes = 4, Chans = 22, Samples = 750, \n",
        "             dropoutRate = 0.5, kernLength = 25, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "\n",
        "# compile the model and set the optimizers\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# count number of parameters in the model\n",
        "numParams    = model.count_params() \n",
        "\n",
        "# set a valid path for your system to record model checkpoints\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
        "                               save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwvCZhYUfIx9",
        "colab_type": "code",
        "outputId": "55accb34-c3a8-4390-c718-b6d10e501513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "# the weights all to be 1\n",
        "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
        "\n",
        "################################################################################\n",
        "# fit the model. Due to very small sample sizes this can get\n",
        "# pretty noisy run-to-run, but most runs should be comparable to xDAWN + \n",
        "# Riemannian geometry classification (below)\n",
        "################################################################################\n",
        "history = model.fit(X_train, Y_train, batch_size = 16, epochs = 100, \n",
        "                        verbose = 2, validation_data=(X_val, Y_val),\n",
        "                        callbacks=[checkpointer], class_weight = class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 240 samples, validate on 47 samples\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.37567, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 5s - loss: 1.4322 - acc: 0.2375 - val_loss: 1.3757 - val_acc: 0.3404\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.37567 to 1.36957, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.3504 - acc: 0.3208 - val_loss: 1.3696 - val_acc: 0.3830\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.36957 to 1.35374, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.2907 - acc: 0.4750 - val_loss: 1.3537 - val_acc: 0.4468\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.35374 to 1.34386, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.2535 - acc: 0.4708 - val_loss: 1.3439 - val_acc: 0.4043\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.34386 to 1.33690, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.2103 - acc: 0.4958 - val_loss: 1.3369 - val_acc: 0.3830\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.33690 to 1.31874, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.1797 - acc: 0.5333 - val_loss: 1.3187 - val_acc: 0.3617\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.31874 to 1.31318, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.1598 - acc: 0.5167 - val_loss: 1.3132 - val_acc: 0.3617\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.31318 to 1.30840, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.1314 - acc: 0.5417 - val_loss: 1.3084 - val_acc: 0.3830\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.30840 to 1.29177, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.1107 - acc: 0.5417 - val_loss: 1.2918 - val_acc: 0.3617\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.29177 to 1.28187, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.0812 - acc: 0.6208 - val_loss: 1.2819 - val_acc: 0.3830\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.28187 to 1.26865, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.0522 - acc: 0.6542 - val_loss: 1.2686 - val_acc: 0.4255\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.26865 to 1.25139, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.0160 - acc: 0.6292 - val_loss: 1.2514 - val_acc: 0.4681\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.25139 to 1.22193, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 1.0251 - acc: 0.6500 - val_loss: 1.2219 - val_acc: 0.5106\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.22193 to 1.21616, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9784 - acc: 0.6750 - val_loss: 1.2162 - val_acc: 0.5106\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.21616 to 1.21246, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9961 - acc: 0.7000 - val_loss: 1.2125 - val_acc: 0.4681\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.21246 to 1.19091, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9615 - acc: 0.6792 - val_loss: 1.1909 - val_acc: 0.4894\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.19091 to 1.18805, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9536 - acc: 0.6833 - val_loss: 1.1881 - val_acc: 0.5319\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.18805 to 1.17791, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9083 - acc: 0.7542 - val_loss: 1.1779 - val_acc: 0.4468\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.17791 to 1.15547, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9242 - acc: 0.6792 - val_loss: 1.1555 - val_acc: 0.5319\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.15547 to 1.14322, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.9317 - acc: 0.7042 - val_loss: 1.1432 - val_acc: 0.4681\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.14322\n",
            "240/240 - 0s - loss: 0.9235 - acc: 0.7083 - val_loss: 1.1600 - val_acc: 0.5532\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.14322 to 1.11550, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8958 - acc: 0.7125 - val_loss: 1.1155 - val_acc: 0.5319\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.11550\n",
            "240/240 - 0s - loss: 0.8930 - acc: 0.7125 - val_loss: 1.1317 - val_acc: 0.5106\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.11550 to 1.10503, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8946 - acc: 0.6958 - val_loss: 1.1050 - val_acc: 0.5319\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.10503\n",
            "240/240 - 0s - loss: 0.8799 - acc: 0.7375 - val_loss: 1.1057 - val_acc: 0.5532\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.10503 to 1.08799, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8435 - acc: 0.7333 - val_loss: 1.0880 - val_acc: 0.5745\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.08799 to 1.06803, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8288 - acc: 0.7833 - val_loss: 1.0680 - val_acc: 0.6170\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.06803 to 1.04929, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8515 - acc: 0.7500 - val_loss: 1.0493 - val_acc: 0.6170\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.04929 to 1.04804, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8231 - acc: 0.7667 - val_loss: 1.0480 - val_acc: 0.5532\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.04804 to 1.02144, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.8108 - acc: 0.7500 - val_loss: 1.0214 - val_acc: 0.5319\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.02144 to 0.96055, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.7833 - acc: 0.8125 - val_loss: 0.9606 - val_acc: 0.6383\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.96055 to 0.92860, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.7402 - acc: 0.7833 - val_loss: 0.9286 - val_acc: 0.6383\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.92860 to 0.89491, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.7139 - acc: 0.8250 - val_loss: 0.8949 - val_acc: 0.6596\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.89491 to 0.87116, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.6772 - acc: 0.8125 - val_loss: 0.8712 - val_acc: 0.6596\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.87116 to 0.84791, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.7360 - acc: 0.7667 - val_loss: 0.8479 - val_acc: 0.7021\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.84791\n",
            "240/240 - 0s - loss: 0.6590 - acc: 0.8292 - val_loss: 0.8605 - val_acc: 0.6170\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.84791 to 0.80658, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.6522 - acc: 0.8292 - val_loss: 0.8066 - val_acc: 0.6383\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.80658\n",
            "240/240 - 0s - loss: 0.6334 - acc: 0.8125 - val_loss: 0.8134 - val_acc: 0.5957\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.80658 to 0.78915, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.6545 - acc: 0.8208 - val_loss: 0.7892 - val_acc: 0.5957\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.78915\n",
            "240/240 - 0s - loss: 0.6370 - acc: 0.8250 - val_loss: 0.8068 - val_acc: 0.5957\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.78915 to 0.76272, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.6199 - acc: 0.8250 - val_loss: 0.7627 - val_acc: 0.6596\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.76272 to 0.75646, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.6369 - acc: 0.8000 - val_loss: 0.7565 - val_acc: 0.7234\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.75646\n",
            "240/240 - 0s - loss: 0.6220 - acc: 0.8250 - val_loss: 0.7720 - val_acc: 0.6596\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.75646\n",
            "240/240 - 0s - loss: 0.6351 - acc: 0.7833 - val_loss: 0.7571 - val_acc: 0.7234\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.75646\n",
            "240/240 - 0s - loss: 0.5909 - acc: 0.8292 - val_loss: 0.8143 - val_acc: 0.6383\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.75646\n",
            "240/240 - 0s - loss: 0.6412 - acc: 0.7958 - val_loss: 0.7695 - val_acc: 0.6383\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.75646 to 0.73297, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.5974 - acc: 0.8250 - val_loss: 0.7330 - val_acc: 0.7234\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5845 - acc: 0.8375 - val_loss: 0.7989 - val_acc: 0.5957\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5725 - acc: 0.8292 - val_loss: 0.7862 - val_acc: 0.6170\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5835 - acc: 0.8250 - val_loss: 0.7932 - val_acc: 0.6170\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5744 - acc: 0.8208 - val_loss: 0.7511 - val_acc: 0.7021\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5650 - acc: 0.8125 - val_loss: 0.7622 - val_acc: 0.6170\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5780 - acc: 0.8458 - val_loss: 0.7592 - val_acc: 0.6596\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5402 - acc: 0.8375 - val_loss: 0.7628 - val_acc: 0.6596\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.73297\n",
            "240/240 - 0s - loss: 0.5376 - acc: 0.8458 - val_loss: 0.7576 - val_acc: 0.6596\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.73297 to 0.69721, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.5490 - acc: 0.8375 - val_loss: 0.6972 - val_acc: 0.8085\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.69721\n",
            "240/240 - 0s - loss: 0.5395 - acc: 0.8542 - val_loss: 0.7332 - val_acc: 0.6809\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.69721\n",
            "240/240 - 0s - loss: 0.5392 - acc: 0.8583 - val_loss: 0.7485 - val_acc: 0.6596\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.69721 to 0.68353, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.5126 - acc: 0.8708 - val_loss: 0.6835 - val_acc: 0.7660\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.68353\n",
            "240/240 - 0s - loss: 0.5307 - acc: 0.8500 - val_loss: 0.7363 - val_acc: 0.7021\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.68353\n",
            "240/240 - 0s - loss: 0.4964 - acc: 0.8792 - val_loss: 0.6941 - val_acc: 0.7447\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.68353\n",
            "240/240 - 0s - loss: 0.5364 - acc: 0.8375 - val_loss: 0.7596 - val_acc: 0.6383\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.68353\n",
            "240/240 - 0s - loss: 0.4837 - acc: 0.8625 - val_loss: 0.7269 - val_acc: 0.6809\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.68353 to 0.66873, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.4755 - acc: 0.8875 - val_loss: 0.6687 - val_acc: 0.8085\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5163 - acc: 0.8542 - val_loss: 0.7298 - val_acc: 0.7447\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5390 - acc: 0.8500 - val_loss: 0.7051 - val_acc: 0.7447\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5151 - acc: 0.8542 - val_loss: 0.7122 - val_acc: 0.7021\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5570 - acc: 0.8333 - val_loss: 0.7037 - val_acc: 0.8085\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4714 - acc: 0.8750 - val_loss: 0.7122 - val_acc: 0.7234\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4675 - acc: 0.8917 - val_loss: 0.7220 - val_acc: 0.7021\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5061 - acc: 0.8458 - val_loss: 0.7470 - val_acc: 0.6596\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4936 - acc: 0.8625 - val_loss: 0.6794 - val_acc: 0.7872\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4779 - acc: 0.8708 - val_loss: 0.7384 - val_acc: 0.6383\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4844 - acc: 0.8750 - val_loss: 0.6788 - val_acc: 0.8298\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4578 - acc: 0.8458 - val_loss: 0.7547 - val_acc: 0.6809\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4570 - acc: 0.8750 - val_loss: 0.7323 - val_acc: 0.7234\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.5118 - acc: 0.8500 - val_loss: 0.7080 - val_acc: 0.7234\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4624 - acc: 0.8750 - val_loss: 0.7360 - val_acc: 0.7021\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4838 - acc: 0.8417 - val_loss: 0.6797 - val_acc: 0.7660\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4552 - acc: 0.8792 - val_loss: 0.6936 - val_acc: 0.7660\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4738 - acc: 0.9000 - val_loss: 0.6797 - val_acc: 0.7660\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.66873\n",
            "240/240 - 0s - loss: 0.4472 - acc: 0.8875 - val_loss: 0.6876 - val_acc: 0.7234\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.66873 to 0.66508, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.4670 - acc: 0.8667 - val_loss: 0.6651 - val_acc: 0.7660\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.66508 to 0.60702, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.4211 - acc: 0.8792 - val_loss: 0.6070 - val_acc: 0.8511\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4165 - acc: 0.9000 - val_loss: 0.6332 - val_acc: 0.8085\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4472 - acc: 0.8958 - val_loss: 0.6543 - val_acc: 0.7872\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4416 - acc: 0.8667 - val_loss: 0.6414 - val_acc: 0.7660\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4562 - acc: 0.8917 - val_loss: 0.6938 - val_acc: 0.7021\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4130 - acc: 0.9167 - val_loss: 0.6491 - val_acc: 0.7447\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4183 - acc: 0.8875 - val_loss: 0.7017 - val_acc: 0.7234\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4405 - acc: 0.9083 - val_loss: 0.6403 - val_acc: 0.7021\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4439 - acc: 0.8792 - val_loss: 0.6941 - val_acc: 0.7660\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.60702\n",
            "240/240 - 0s - loss: 0.4435 - acc: 0.8625 - val_loss: 0.6965 - val_acc: 0.7021\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.60702 to 0.60042, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.3944 - acc: 0.9208 - val_loss: 0.6004 - val_acc: 0.8298\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.60042\n",
            "240/240 - 0s - loss: 0.4293 - acc: 0.9000 - val_loss: 0.6368 - val_acc: 0.7234\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.60042\n",
            "240/240 - 0s - loss: 0.4242 - acc: 0.8958 - val_loss: 0.6316 - val_acc: 0.7660\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.60042\n",
            "240/240 - 0s - loss: 0.3904 - acc: 0.8917 - val_loss: 0.6717 - val_acc: 0.7447\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.60042 to 0.57170, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.4008 - acc: 0.8833 - val_loss: 0.5717 - val_acc: 0.8085\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.57170\n",
            "240/240 - 0s - loss: 0.3892 - acc: 0.8958 - val_loss: 0.6466 - val_acc: 0.7447\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.57170 to 0.57008, saving model to /tmp/checkpoint.h5\n",
            "240/240 - 0s - loss: 0.3994 - acc: 0.8917 - val_loss: 0.5701 - val_acc: 0.8723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4aC5kY7lhys",
        "colab_type": "code",
        "outputId": "6b883517-f380-4b85-866d-e7c1ee413d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQIRkcApEIiIBE6BQEQkcAoEIiKB+39vtJFN6eYzQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P8YE0iV2XwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ynew = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfAoIy2p3lWB",
        "colab_type": "code",
        "outputId": "3b8aeb28-cd3e-44b5-87b4-20f92413e143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print('\\n# Evaluate on test data')\n",
        "results = model.evaluate(X_test, Y_test, batch_size=1)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "# Evaluate on test data\n",
            "288/288 [==============================] - 1s 2ms/sample - loss: 0.6215 - acc: 0.7222\n",
            "test loss, test acc: [0.6215209133159887, 0.7222222]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}