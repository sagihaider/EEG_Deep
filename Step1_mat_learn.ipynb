{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step1_mat_learn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/EEG_Deep/blob/master/Step1_mat_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLzMoiS60Qf",
        "colab_type": "code",
        "outputId": "e7ce539c-0d23-498b-b945-21a200f1eb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjtnE_6RSpum",
        "colab_type": "code",
        "outputId": "9c507cf6-9aae-42d2-d8fb-d2b9ec2808e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x= 1         \n",
        "fName = 'parsed_A0' + str(x) + 'T.mat'  # Load Data\n",
        "print(fName)\n",
        "mat = spio.loadmat(fName)\n",
        "X = mat['cleanRawEEGData']\n",
        "y = mat['cleanClassLabels']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parsed_A01T.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c11RQCoS80S",
        "colab_type": "code",
        "outputId": "5744241a-a4be-4dd0-90a8-ab5c072240ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(np.shape(X))\n",
        "print(np.shape(y))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(273, 22, 1500)\n",
            "(273, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgWnQSY5T4op",
        "colab_type": "code",
        "outputId": "f6948cb8-47e0-4043-df35-977db66eb718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# take 50/25/25 percent of the data to train/validate/test\n",
        "X_train      = X[0:150,:,500:1000]\n",
        "Y_train      = y[0:150]\n",
        "X_validate   = X[151:200,:,500:1000]\n",
        "Y_validate   = y[151:200]\n",
        "X_test       = X[201:,:,500:1000]\n",
        "Y_test       = y[201:]\n",
        "\n",
        "print(np.shape(X_train))\n",
        "print(np.shape(Y_train))\n",
        "print(np.shape(X_validate))\n",
        "print(np.shape(Y_validate))\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(Y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 22, 500)\n",
            "(150, 1)\n",
            "(49, 22, 500)\n",
            "(49, 1)\n",
            "(72, 22, 500)\n",
            "(72, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfC8z4I-UnF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# convert labels to one-hot encodings.\n",
        "Y_train      = np_utils.to_categorical(Y_train-1)\n",
        "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
        "Y_test       = np_utils.to_categorical(Y_test-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqmsOU1BXOZJ",
        "colab_type": "code",
        "outputId": "a9eebb98-2644-4f7c-9a3d-810e5387e320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "kernels, chans, samples = 1, 22, 500\n",
        "\n",
        "# convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "# contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "X_validate   = X_validate.reshape(X_validate.shape[0], kernels, chans, samples)\n",
        "X_test       = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "   \n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (150, 1, 22, 500)\n",
            "150 train samples\n",
            "72 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdmtgll0bpgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train= np.squeeze(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUlJdZk_X1OY",
        "colab_type": "code",
        "outputId": "1918f6a6-908a-4ce6-a324-a2a5fda0a019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "# model configurations may do better, but this is a good starting point)\n",
        "model = EEGNet(nb_classes = 4, Chans = 22, Samples = 500, \n",
        "             dropoutRate = 0.5, kernLength = 25, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXI2PnjRe77i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model and set the optimizers\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_PEYKWbfAA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count number of parameters in the model\n",
        "numParams    = model.count_params()    \n",
        "\n",
        "# set a valid path for your system to record model checkpoints\n",
        "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
        "                               save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwvCZhYUfIx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1df2fe6-6c53-4fb8-9074-061e74859ada"
      },
      "source": [
        "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "# the weights all to be 1\n",
        "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
        "\n",
        "################################################################################\n",
        "# fit the model. Due to very small sample sizes this can get\n",
        "# pretty noisy run-to-run, but most runs should be comparable to xDAWN + \n",
        "# Riemannian geometry classification (below)\n",
        "################################################################################\n",
        "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
        "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
        "                        callbacks=[checkpointer], class_weight = class_weights)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150 samples, validate on 49 samples\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38328, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 4s - loss: 1.4054 - acc: 0.2667 - val_loss: 1.3833 - val_acc: 0.2857\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38328 to 1.37705, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.3608 - acc: 0.3200 - val_loss: 1.3770 - val_acc: 0.2857\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.37705 to 1.37135, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.3249 - acc: 0.4600 - val_loss: 1.3713 - val_acc: 0.3265\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.37135 to 1.36256, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.2909 - acc: 0.4867 - val_loss: 1.3626 - val_acc: 0.3878\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.36256 to 1.35258, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.2492 - acc: 0.4800 - val_loss: 1.3526 - val_acc: 0.3878\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35258 to 1.34195, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.2169 - acc: 0.5533 - val_loss: 1.3420 - val_acc: 0.3878\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.34195 to 1.32997, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.1864 - acc: 0.5267 - val_loss: 1.3300 - val_acc: 0.4286\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.32997 to 1.32415, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.1527 - acc: 0.5600 - val_loss: 1.3241 - val_acc: 0.4490\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.32415 to 1.31883, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.1259 - acc: 0.6200 - val_loss: 1.3188 - val_acc: 0.4082\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.31883 to 1.30958, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.1041 - acc: 0.5600 - val_loss: 1.3096 - val_acc: 0.4082\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.30958 to 1.30146, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.0990 - acc: 0.5933 - val_loss: 1.3015 - val_acc: 0.4490\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.30146 to 1.29381, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.0604 - acc: 0.5933 - val_loss: 1.2938 - val_acc: 0.4490\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.29381 to 1.29235, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.0360 - acc: 0.6667 - val_loss: 1.2923 - val_acc: 0.4082\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.29235 to 1.29125, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.0499 - acc: 0.6467 - val_loss: 1.2912 - val_acc: 0.4082\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.29125\n",
            "150/150 - 0s - loss: 1.0306 - acc: 0.6067 - val_loss: 1.2944 - val_acc: 0.4082\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.29125\n",
            "150/150 - 0s - loss: 1.0330 - acc: 0.6067 - val_loss: 1.2994 - val_acc: 0.3878\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.29125\n",
            "150/150 - 0s - loss: 1.0038 - acc: 0.6600 - val_loss: 1.2930 - val_acc: 0.4082\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.29125 to 1.28709, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 1.0192 - acc: 0.6333 - val_loss: 1.2871 - val_acc: 0.4082\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.28709 to 1.27464, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.9716 - acc: 0.6933 - val_loss: 1.2746 - val_acc: 0.4286\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.27464 to 1.26778, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.9401 - acc: 0.7133 - val_loss: 1.2678 - val_acc: 0.4082\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.26778\n",
            "150/150 - 0s - loss: 0.9542 - acc: 0.6867 - val_loss: 1.2678 - val_acc: 0.4694\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.26778\n",
            "150/150 - 0s - loss: 0.9382 - acc: 0.6867 - val_loss: 1.2721 - val_acc: 0.4082\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.26778 to 1.26004, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.9389 - acc: 0.7133 - val_loss: 1.2600 - val_acc: 0.4490\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.26004 to 1.24691, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.9355 - acc: 0.7200 - val_loss: 1.2469 - val_acc: 0.4694\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.24691 to 1.23883, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8927 - acc: 0.7067 - val_loss: 1.2388 - val_acc: 0.5102\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.23883 to 1.23348, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.9001 - acc: 0.7067 - val_loss: 1.2335 - val_acc: 0.5306\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.23348 to 1.21616, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8938 - acc: 0.7200 - val_loss: 1.2162 - val_acc: 0.5306\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.21616\n",
            "150/150 - 0s - loss: 0.8970 - acc: 0.7000 - val_loss: 1.2179 - val_acc: 0.5510\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.21616\n",
            "150/150 - 0s - loss: 0.8931 - acc: 0.6933 - val_loss: 1.2264 - val_acc: 0.5510\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.21616 to 1.20551, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8590 - acc: 0.7533 - val_loss: 1.2055 - val_acc: 0.5306\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.20551\n",
            "150/150 - 0s - loss: 0.8862 - acc: 0.7400 - val_loss: 1.2102 - val_acc: 0.5714\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.20551\n",
            "150/150 - 0s - loss: 0.8468 - acc: 0.7333 - val_loss: 1.2079 - val_acc: 0.5306\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.20551\n",
            "150/150 - 0s - loss: 0.8496 - acc: 0.7267 - val_loss: 1.2100 - val_acc: 0.5306\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.20551\n",
            "150/150 - 0s - loss: 0.8703 - acc: 0.7067 - val_loss: 1.2076 - val_acc: 0.4898\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.20551 to 1.18547, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8570 - acc: 0.7533 - val_loss: 1.1855 - val_acc: 0.4898\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.18547\n",
            "150/150 - 0s - loss: 0.7999 - acc: 0.7867 - val_loss: 1.1971 - val_acc: 0.5714\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.18547\n",
            "150/150 - 0s - loss: 0.8312 - acc: 0.7400 - val_loss: 1.1890 - val_acc: 0.5510\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.18547\n",
            "150/150 - 0s - loss: 0.8453 - acc: 0.7400 - val_loss: 1.2058 - val_acc: 0.5306\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.18547 to 1.17753, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8464 - acc: 0.7067 - val_loss: 1.1775 - val_acc: 0.5102\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.17753 to 1.15952, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8016 - acc: 0.7600 - val_loss: 1.1595 - val_acc: 0.4898\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.15952 to 1.12821, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8105 - acc: 0.7333 - val_loss: 1.1282 - val_acc: 0.5714\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.12821 to 1.12491, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.8101 - acc: 0.7467 - val_loss: 1.1249 - val_acc: 0.5510\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.12491 to 1.08595, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7862 - acc: 0.7600 - val_loss: 1.0859 - val_acc: 0.5918\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.08595 to 1.07372, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7669 - acc: 0.7667 - val_loss: 1.0737 - val_acc: 0.5510\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.07372 to 1.02585, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7645 - acc: 0.7600 - val_loss: 1.0258 - val_acc: 0.6939\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.02585 to 1.01110, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7565 - acc: 0.8133 - val_loss: 1.0111 - val_acc: 0.7347\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.01110 to 1.00486, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7510 - acc: 0.8467 - val_loss: 1.0049 - val_acc: 0.6735\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 00048: val_loss improved from 1.00486 to 0.96850, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7412 - acc: 0.7667 - val_loss: 0.9685 - val_acc: 0.7143\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.96850 to 0.93377, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7688 - acc: 0.7733 - val_loss: 0.9338 - val_acc: 0.7551\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.93377 to 0.91712, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7184 - acc: 0.8267 - val_loss: 0.9171 - val_acc: 0.6939\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.91712 to 0.89075, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.7294 - acc: 0.8200 - val_loss: 0.8908 - val_acc: 0.7347\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.89075 to 0.85947, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6982 - acc: 0.8000 - val_loss: 0.8595 - val_acc: 0.7755\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.85947 to 0.85409, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6941 - acc: 0.7800 - val_loss: 0.8541 - val_acc: 0.7755\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.85409 to 0.82054, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6642 - acc: 0.8467 - val_loss: 0.8205 - val_acc: 0.7347\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.82054 to 0.80920, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6603 - acc: 0.7933 - val_loss: 0.8092 - val_acc: 0.7347\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.80920\n",
            "150/150 - 0s - loss: 0.6515 - acc: 0.8267 - val_loss: 0.8240 - val_acc: 0.7551\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.80920\n",
            "150/150 - 0s - loss: 0.6639 - acc: 0.8600 - val_loss: 0.8143 - val_acc: 0.6939\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.80920 to 0.79712, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6857 - acc: 0.8067 - val_loss: 0.7971 - val_acc: 0.7143\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.79712 to 0.78773, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6576 - acc: 0.7933 - val_loss: 0.7877 - val_acc: 0.6939\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.78773\n",
            "150/150 - 0s - loss: 0.6004 - acc: 0.8600 - val_loss: 0.7929 - val_acc: 0.7143\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.78773\n",
            "150/150 - 0s - loss: 0.6448 - acc: 0.8067 - val_loss: 0.7988 - val_acc: 0.7143\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.78773\n",
            "150/150 - 0s - loss: 0.6571 - acc: 0.7867 - val_loss: 0.8187 - val_acc: 0.7143\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.78773\n",
            "150/150 - 0s - loss: 0.6063 - acc: 0.8333 - val_loss: 0.8191 - val_acc: 0.6939\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.78773 to 0.76913, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6697 - acc: 0.7800 - val_loss: 0.7691 - val_acc: 0.7755\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.76913\n",
            "150/150 - 0s - loss: 0.6565 - acc: 0.8000 - val_loss: 0.8093 - val_acc: 0.7143\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.76913\n",
            "150/150 - 0s - loss: 0.5824 - acc: 0.8667 - val_loss: 0.7753 - val_acc: 0.7551\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.76913 to 0.76891, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.6064 - acc: 0.8267 - val_loss: 0.7689 - val_acc: 0.7755\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.76891\n",
            "150/150 - 0s - loss: 0.6260 - acc: 0.8133 - val_loss: 0.7768 - val_acc: 0.6327\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.76891 to 0.74903, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5764 - acc: 0.8667 - val_loss: 0.7490 - val_acc: 0.6939\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5977 - acc: 0.8133 - val_loss: 0.7560 - val_acc: 0.6735\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5980 - acc: 0.8333 - val_loss: 0.7547 - val_acc: 0.6735\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5595 - acc: 0.8667 - val_loss: 0.7806 - val_acc: 0.7347\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5621 - acc: 0.8267 - val_loss: 0.7720 - val_acc: 0.7551\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5782 - acc: 0.8067 - val_loss: 0.7783 - val_acc: 0.7551\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5971 - acc: 0.8067 - val_loss: 0.7788 - val_acc: 0.7143\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5629 - acc: 0.8333 - val_loss: 0.8023 - val_acc: 0.6939\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5793 - acc: 0.8400 - val_loss: 0.7648 - val_acc: 0.7959\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5869 - acc: 0.8667 - val_loss: 0.7887 - val_acc: 0.7143\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5701 - acc: 0.8400 - val_loss: 0.7599 - val_acc: 0.7551\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5469 - acc: 0.8533 - val_loss: 0.7593 - val_acc: 0.7143\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.74903\n",
            "150/150 - 0s - loss: 0.5646 - acc: 0.8467 - val_loss: 0.7504 - val_acc: 0.7347\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.74903 to 0.74454, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5662 - acc: 0.8267 - val_loss: 0.7445 - val_acc: 0.7959\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.74454\n",
            "150/150 - 0s - loss: 0.5924 - acc: 0.8467 - val_loss: 0.7818 - val_acc: 0.7143\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.74454\n",
            "150/150 - 0s - loss: 0.5937 - acc: 0.8133 - val_loss: 0.7971 - val_acc: 0.6735\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.74454 to 0.74185, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5393 - acc: 0.8800 - val_loss: 0.7419 - val_acc: 0.7551\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.74185 to 0.74051, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5432 - acc: 0.8933 - val_loss: 0.7405 - val_acc: 0.7347\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5566 - acc: 0.8533 - val_loss: 0.7668 - val_acc: 0.7143\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5465 - acc: 0.8733 - val_loss: 0.7716 - val_acc: 0.7347\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5661 - acc: 0.8467 - val_loss: 0.7543 - val_acc: 0.7551\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5029 - acc: 0.8867 - val_loss: 0.7477 - val_acc: 0.7755\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5378 - acc: 0.8667 - val_loss: 0.7641 - val_acc: 0.6735\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5055 - acc: 0.8600 - val_loss: 0.7547 - val_acc: 0.6735\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5586 - acc: 0.8400 - val_loss: 0.7618 - val_acc: 0.7347\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.5586 - acc: 0.8333 - val_loss: 0.7555 - val_acc: 0.6735\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.74051\n",
            "150/150 - 0s - loss: 0.4980 - acc: 0.9000 - val_loss: 0.7780 - val_acc: 0.6939\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.74051 to 0.72340, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5415 - acc: 0.8800 - val_loss: 0.7234 - val_acc: 0.7959\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.72340 to 0.71967, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.5066 - acc: 0.8733 - val_loss: 0.7197 - val_acc: 0.7551\n",
            "Epoch 98/300\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4967 - acc: 0.8867 - val_loss: 0.7288 - val_acc: 0.6939\n",
            "Epoch 99/300\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5003 - acc: 0.8600 - val_loss: 0.7324 - val_acc: 0.7143\n",
            "Epoch 100/300\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5330 - acc: 0.8533 - val_loss: 0.7365 - val_acc: 0.7143\n",
            "Epoch 101/300\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4957 - acc: 0.8333 - val_loss: 0.7227 - val_acc: 0.6531\n",
            "Epoch 102/300\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5230 - acc: 0.8600 - val_loss: 0.7199 - val_acc: 0.7143\n",
            "Epoch 103/300\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4636 - acc: 0.8733 - val_loss: 0.7250 - val_acc: 0.7143\n",
            "Epoch 104/300\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5056 - acc: 0.8667 - val_loss: 0.7400 - val_acc: 0.6939\n",
            "Epoch 105/300\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5061 - acc: 0.8333 - val_loss: 0.7591 - val_acc: 0.6735\n",
            "Epoch 106/300\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5035 - acc: 0.8733 - val_loss: 0.7615 - val_acc: 0.6939\n",
            "Epoch 107/300\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5116 - acc: 0.8867 - val_loss: 0.7588 - val_acc: 0.6531\n",
            "Epoch 108/300\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5073 - acc: 0.8533 - val_loss: 0.7490 - val_acc: 0.6531\n",
            "Epoch 109/300\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4807 - acc: 0.8533 - val_loss: 0.7746 - val_acc: 0.6939\n",
            "Epoch 110/300\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4715 - acc: 0.8800 - val_loss: 0.7793 - val_acc: 0.6735\n",
            "Epoch 111/300\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4896 - acc: 0.8933 - val_loss: 0.7913 - val_acc: 0.6735\n",
            "Epoch 112/300\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4859 - acc: 0.8533 - val_loss: 0.7836 - val_acc: 0.6939\n",
            "Epoch 113/300\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4359 - acc: 0.8933 - val_loss: 0.7674 - val_acc: 0.6939\n",
            "Epoch 114/300\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5093 - acc: 0.9000 - val_loss: 0.7568 - val_acc: 0.6939\n",
            "Epoch 115/300\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4375 - acc: 0.9200 - val_loss: 0.7517 - val_acc: 0.6939\n",
            "Epoch 116/300\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4851 - acc: 0.8867 - val_loss: 0.7506 - val_acc: 0.6735\n",
            "Epoch 117/300\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4409 - acc: 0.8933 - val_loss: 0.7291 - val_acc: 0.6939\n",
            "Epoch 118/300\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4572 - acc: 0.8733 - val_loss: 0.7608 - val_acc: 0.7143\n",
            "Epoch 119/300\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4872 - acc: 0.8600 - val_loss: 0.7706 - val_acc: 0.6735\n",
            "Epoch 120/300\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.5298 - acc: 0.8133 - val_loss: 0.7648 - val_acc: 0.6735\n",
            "Epoch 121/300\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4548 - acc: 0.9133 - val_loss: 0.7464 - val_acc: 0.6939\n",
            "Epoch 122/300\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4428 - acc: 0.8933 - val_loss: 0.7423 - val_acc: 0.7143\n",
            "Epoch 123/300\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4266 - acc: 0.9267 - val_loss: 0.7733 - val_acc: 0.6531\n",
            "Epoch 124/300\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4566 - acc: 0.9000 - val_loss: 0.7450 - val_acc: 0.6939\n",
            "Epoch 125/300\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4614 - acc: 0.8667 - val_loss: 0.7700 - val_acc: 0.6327\n",
            "Epoch 126/300\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4783 - acc: 0.8933 - val_loss: 0.7841 - val_acc: 0.6735\n",
            "Epoch 127/300\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4153 - acc: 0.9067 - val_loss: 0.7382 - val_acc: 0.6939\n",
            "Epoch 128/300\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4322 - acc: 0.9200 - val_loss: 0.7833 - val_acc: 0.6531\n",
            "Epoch 129/300\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4830 - acc: 0.8600 - val_loss: 0.7542 - val_acc: 0.6939\n",
            "Epoch 130/300\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4582 - acc: 0.8667 - val_loss: 0.7401 - val_acc: 0.6939\n",
            "Epoch 131/300\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.71967\n",
            "150/150 - 0s - loss: 0.4673 - acc: 0.9000 - val_loss: 0.7306 - val_acc: 0.7347\n",
            "Epoch 132/300\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.71967 to 0.71446, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.4463 - acc: 0.9000 - val_loss: 0.7145 - val_acc: 0.7347\n",
            "Epoch 133/300\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.71446\n",
            "150/150 - 0s - loss: 0.4047 - acc: 0.9133 - val_loss: 0.7516 - val_acc: 0.7143\n",
            "Epoch 134/300\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.71446\n",
            "150/150 - 0s - loss: 0.4252 - acc: 0.9133 - val_loss: 0.7654 - val_acc: 0.7347\n",
            "Epoch 135/300\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.71446\n",
            "150/150 - 0s - loss: 0.4449 - acc: 0.8933 - val_loss: 0.7413 - val_acc: 0.7143\n",
            "Epoch 136/300\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.71446\n",
            "150/150 - 0s - loss: 0.4058 - acc: 0.9067 - val_loss: 0.7290 - val_acc: 0.6939\n",
            "Epoch 137/300\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.71446\n",
            "150/150 - 0s - loss: 0.4236 - acc: 0.9067 - val_loss: 0.7250 - val_acc: 0.7347\n",
            "Epoch 138/300\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.71446 to 0.70668, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.3867 - acc: 0.9400 - val_loss: 0.7067 - val_acc: 0.7143\n",
            "Epoch 139/300\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4557 - acc: 0.8667 - val_loss: 0.7156 - val_acc: 0.6735\n",
            "Epoch 140/300\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4332 - acc: 0.9000 - val_loss: 0.7698 - val_acc: 0.6327\n",
            "Epoch 141/300\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4094 - acc: 0.9133 - val_loss: 0.7423 - val_acc: 0.6939\n",
            "Epoch 142/300\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4189 - acc: 0.9000 - val_loss: 0.7588 - val_acc: 0.6531\n",
            "Epoch 143/300\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.3964 - acc: 0.9267 - val_loss: 0.7677 - val_acc: 0.6122\n",
            "Epoch 144/300\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4012 - acc: 0.9133 - val_loss: 0.7581 - val_acc: 0.6939\n",
            "Epoch 145/300\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4109 - acc: 0.9000 - val_loss: 0.7464 - val_acc: 0.6939\n",
            "Epoch 146/300\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4276 - acc: 0.8733 - val_loss: 0.7574 - val_acc: 0.6939\n",
            "Epoch 147/300\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4417 - acc: 0.8867 - val_loss: 0.7868 - val_acc: 0.6531\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4274 - acc: 0.8800 - val_loss: 0.7288 - val_acc: 0.6531\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.3541 - acc: 0.9400 - val_loss: 0.7499 - val_acc: 0.6735\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.70668\n",
            "150/150 - 0s - loss: 0.4009 - acc: 0.9000 - val_loss: 0.7332 - val_acc: 0.6735\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.70668 to 0.68893, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.3882 - acc: 0.8933 - val_loss: 0.6889 - val_acc: 0.6939\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3775 - acc: 0.9000 - val_loss: 0.6913 - val_acc: 0.6735\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.4567 - acc: 0.8533 - val_loss: 0.6980 - val_acc: 0.6939\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3875 - acc: 0.9200 - val_loss: 0.7290 - val_acc: 0.7143\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3995 - acc: 0.8867 - val_loss: 0.7359 - val_acc: 0.6939\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3921 - acc: 0.9067 - val_loss: 0.7203 - val_acc: 0.6939\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.4009 - acc: 0.9200 - val_loss: 0.7228 - val_acc: 0.6735\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3553 - acc: 0.9400 - val_loss: 0.8142 - val_acc: 0.6327\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3582 - acc: 0.9667 - val_loss: 0.7593 - val_acc: 0.7347\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3951 - acc: 0.9000 - val_loss: 0.7273 - val_acc: 0.6735\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3850 - acc: 0.9400 - val_loss: 0.6996 - val_acc: 0.7143\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3711 - acc: 0.9133 - val_loss: 0.6966 - val_acc: 0.6735\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3498 - acc: 0.9467 - val_loss: 0.7145 - val_acc: 0.6531\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3841 - acc: 0.9000 - val_loss: 0.7246 - val_acc: 0.6735\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.4181 - acc: 0.8933 - val_loss: 0.7102 - val_acc: 0.6531\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3955 - acc: 0.9067 - val_loss: 0.7744 - val_acc: 0.6327\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3716 - acc: 0.9200 - val_loss: 0.7258 - val_acc: 0.7143\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3947 - acc: 0.8467 - val_loss: 0.7141 - val_acc: 0.6531\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3494 - acc: 0.9267 - val_loss: 0.7388 - val_acc: 0.6735\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3791 - acc: 0.9133 - val_loss: 0.7182 - val_acc: 0.6735\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3324 - acc: 0.9467 - val_loss: 0.7610 - val_acc: 0.6735\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3900 - acc: 0.8800 - val_loss: 0.7068 - val_acc: 0.6939\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3322 - acc: 0.9400 - val_loss: 0.7472 - val_acc: 0.6939\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3884 - acc: 0.8867 - val_loss: 0.7385 - val_acc: 0.6735\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3488 - acc: 0.9267 - val_loss: 0.7271 - val_acc: 0.6531\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3319 - acc: 0.9400 - val_loss: 0.7217 - val_acc: 0.6939\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3187 - acc: 0.9333 - val_loss: 0.7276 - val_acc: 0.6531\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3706 - acc: 0.9000 - val_loss: 0.7228 - val_acc: 0.7143\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3279 - acc: 0.9200 - val_loss: 0.6938 - val_acc: 0.7347\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3610 - acc: 0.9400 - val_loss: 0.7439 - val_acc: 0.6531\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3761 - acc: 0.9133 - val_loss: 0.7140 - val_acc: 0.6531\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3267 - acc: 0.9467 - val_loss: 0.7460 - val_acc: 0.6939\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3917 - acc: 0.8933 - val_loss: 0.7783 - val_acc: 0.6531\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3569 - acc: 0.9267 - val_loss: 0.7150 - val_acc: 0.6735\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3230 - acc: 0.9000 - val_loss: 0.7443 - val_acc: 0.6735\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3674 - acc: 0.9067 - val_loss: 0.6955 - val_acc: 0.6735\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3471 - acc: 0.9467 - val_loss: 0.6993 - val_acc: 0.6531\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3626 - acc: 0.9200 - val_loss: 0.7322 - val_acc: 0.6531\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3371 - acc: 0.9333 - val_loss: 0.7065 - val_acc: 0.6531\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3225 - acc: 0.9333 - val_loss: 0.7207 - val_acc: 0.6735\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3491 - acc: 0.9533 - val_loss: 0.6951 - val_acc: 0.6735\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3352 - acc: 0.9133 - val_loss: 0.7350 - val_acc: 0.6735\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3943 - acc: 0.9133 - val_loss: 0.7451 - val_acc: 0.6327\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3758 - acc: 0.8800 - val_loss: 0.7318 - val_acc: 0.6531\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3217 - acc: 0.9333 - val_loss: 0.7028 - val_acc: 0.6531\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.68893\n",
            "150/150 - 0s - loss: 0.3246 - acc: 0.9133 - val_loss: 0.7065 - val_acc: 0.6531\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 00197: val_loss improved from 0.68893 to 0.68537, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.3549 - acc: 0.9067 - val_loss: 0.6854 - val_acc: 0.6939\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.68537\n",
            "150/150 - 0s - loss: 0.3466 - acc: 0.8933 - val_loss: 0.7940 - val_acc: 0.6327\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.68537\n",
            "150/150 - 0s - loss: 0.3193 - acc: 0.9333 - val_loss: 0.7345 - val_acc: 0.6122\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.68537\n",
            "150/150 - 0s - loss: 0.3410 - acc: 0.9267 - val_loss: 0.7529 - val_acc: 0.6531\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 0.68537\n",
            "150/150 - 0s - loss: 0.3245 - acc: 0.9467 - val_loss: 0.7226 - val_acc: 0.7143\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 00202: val_loss improved from 0.68537 to 0.68134, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.3747 - acc: 0.8933 - val_loss: 0.6813 - val_acc: 0.6939\n",
            "Epoch 203/300\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3598 - acc: 0.9133 - val_loss: 0.7145 - val_acc: 0.6531\n",
            "Epoch 204/300\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.2815 - acc: 0.9667 - val_loss: 0.7022 - val_acc: 0.6735\n",
            "Epoch 205/300\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3296 - acc: 0.9333 - val_loss: 0.7080 - val_acc: 0.6327\n",
            "Epoch 206/300\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3147 - acc: 0.9200 - val_loss: 0.7222 - val_acc: 0.6531\n",
            "Epoch 207/300\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3023 - acc: 0.9667 - val_loss: 0.7293 - val_acc: 0.6531\n",
            "Epoch 208/300\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3272 - acc: 0.9267 - val_loss: 0.7366 - val_acc: 0.6531\n",
            "Epoch 209/300\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3373 - acc: 0.9267 - val_loss: 0.6882 - val_acc: 0.6939\n",
            "Epoch 210/300\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3247 - acc: 0.9400 - val_loss: 0.7301 - val_acc: 0.6531\n",
            "Epoch 211/300\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3143 - acc: 0.9333 - val_loss: 0.6900 - val_acc: 0.7143\n",
            "Epoch 212/300\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 0.68134\n",
            "150/150 - 0s - loss: 0.3275 - acc: 0.9267 - val_loss: 0.6830 - val_acc: 0.7347\n",
            "Epoch 213/300\n",
            "\n",
            "Epoch 00213: val_loss improved from 0.68134 to 0.67529, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.3197 - acc: 0.9133 - val_loss: 0.6753 - val_acc: 0.7143\n",
            "Epoch 214/300\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3099 - acc: 0.9133 - val_loss: 0.6969 - val_acc: 0.6939\n",
            "Epoch 215/300\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3450 - acc: 0.9000 - val_loss: 0.7054 - val_acc: 0.6735\n",
            "Epoch 216/300\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3249 - acc: 0.9200 - val_loss: 0.7767 - val_acc: 0.6327\n",
            "Epoch 217/300\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3584 - acc: 0.9067 - val_loss: 0.7120 - val_acc: 0.6939\n",
            "Epoch 218/300\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3165 - acc: 0.9533 - val_loss: 0.6980 - val_acc: 0.6939\n",
            "Epoch 219/300\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3273 - acc: 0.9267 - val_loss: 0.7099 - val_acc: 0.6939\n",
            "Epoch 220/300\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2608 - acc: 0.9533 - val_loss: 0.7285 - val_acc: 0.6735\n",
            "Epoch 221/300\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3159 - acc: 0.9200 - val_loss: 0.7126 - val_acc: 0.6531\n",
            "Epoch 222/300\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2616 - acc: 0.9733 - val_loss: 0.6813 - val_acc: 0.6939\n",
            "Epoch 223/300\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3371 - acc: 0.9133 - val_loss: 0.7281 - val_acc: 0.6531\n",
            "Epoch 224/300\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3314 - acc: 0.9133 - val_loss: 0.6887 - val_acc: 0.6735\n",
            "Epoch 225/300\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3329 - acc: 0.9133 - val_loss: 0.6890 - val_acc: 0.6939\n",
            "Epoch 226/300\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3225 - acc: 0.9533 - val_loss: 0.6971 - val_acc: 0.6735\n",
            "Epoch 227/300\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2616 - acc: 0.9667 - val_loss: 0.7276 - val_acc: 0.6735\n",
            "Epoch 228/300\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3315 - acc: 0.9133 - val_loss: 0.7047 - val_acc: 0.6939\n",
            "Epoch 229/300\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3112 - acc: 0.9400 - val_loss: 0.6958 - val_acc: 0.6735\n",
            "Epoch 230/300\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2975 - acc: 0.9533 - val_loss: 0.7391 - val_acc: 0.6735\n",
            "Epoch 231/300\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2834 - acc: 0.9533 - val_loss: 0.7583 - val_acc: 0.6327\n",
            "Epoch 232/300\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2888 - acc: 0.9533 - val_loss: 0.6969 - val_acc: 0.6939\n",
            "Epoch 233/300\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3027 - acc: 0.8867 - val_loss: 0.7018 - val_acc: 0.6939\n",
            "Epoch 234/300\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2866 - acc: 0.9400 - val_loss: 0.7082 - val_acc: 0.6939\n",
            "Epoch 235/300\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2536 - acc: 0.9600 - val_loss: 0.7445 - val_acc: 0.6735\n",
            "Epoch 236/300\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.2754 - acc: 0.9533 - val_loss: 0.7133 - val_acc: 0.6939\n",
            "Epoch 237/300\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 0.67529\n",
            "150/150 - 0s - loss: 0.3138 - acc: 0.9133 - val_loss: 0.6840 - val_acc: 0.7347\n",
            "Epoch 238/300\n",
            "\n",
            "Epoch 00238: val_loss improved from 0.67529 to 0.66114, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.2846 - acc: 0.9333 - val_loss: 0.6611 - val_acc: 0.7347\n",
            "Epoch 239/300\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.3237 - acc: 0.9267 - val_loss: 0.6899 - val_acc: 0.6735\n",
            "Epoch 240/300\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2718 - acc: 0.9600 - val_loss: 0.6911 - val_acc: 0.7143\n",
            "Epoch 241/300\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.3214 - acc: 0.9400 - val_loss: 0.7930 - val_acc: 0.6327\n",
            "Epoch 242/300\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2935 - acc: 0.9400 - val_loss: 0.7746 - val_acc: 0.6735\n",
            "Epoch 243/300\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.3163 - acc: 0.8933 - val_loss: 0.7530 - val_acc: 0.6939\n",
            "Epoch 244/300\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2748 - acc: 0.9533 - val_loss: 0.7496 - val_acc: 0.6327\n",
            "Epoch 245/300\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2844 - acc: 0.9400 - val_loss: 0.6765 - val_acc: 0.7347\n",
            "Epoch 246/300\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2823 - acc: 0.9400 - val_loss: 0.6934 - val_acc: 0.6327\n",
            "Epoch 247/300\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.3021 - acc: 0.9467 - val_loss: 0.6828 - val_acc: 0.6939\n",
            "Epoch 248/300\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 0.66114\n",
            "150/150 - 0s - loss: 0.2940 - acc: 0.9200 - val_loss: 0.6796 - val_acc: 0.7347\n",
            "Epoch 249/300\n",
            "\n",
            "Epoch 00249: val_loss improved from 0.66114 to 0.66015, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.2997 - acc: 0.9533 - val_loss: 0.6602 - val_acc: 0.6939\n",
            "Epoch 250/300\n",
            "\n",
            "Epoch 00250: val_loss improved from 0.66015 to 0.65406, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.2712 - acc: 0.9667 - val_loss: 0.6541 - val_acc: 0.7143\n",
            "Epoch 251/300\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2725 - acc: 0.9467 - val_loss: 0.6715 - val_acc: 0.6735\n",
            "Epoch 252/300\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2944 - acc: 0.9400 - val_loss: 0.6887 - val_acc: 0.6939\n",
            "Epoch 253/300\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3028 - acc: 0.9200 - val_loss: 0.7008 - val_acc: 0.7143\n",
            "Epoch 254/300\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2817 - acc: 0.9400 - val_loss: 0.7085 - val_acc: 0.6735\n",
            "Epoch 255/300\n",
            "\n",
            "Epoch 00255: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2857 - acc: 0.9133 - val_loss: 0.7256 - val_acc: 0.6735\n",
            "Epoch 256/300\n",
            "\n",
            "Epoch 00256: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2897 - acc: 0.9400 - val_loss: 0.7166 - val_acc: 0.6531\n",
            "Epoch 257/300\n",
            "\n",
            "Epoch 00257: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2923 - acc: 0.9333 - val_loss: 0.7252 - val_acc: 0.6531\n",
            "Epoch 258/300\n",
            "\n",
            "Epoch 00258: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3051 - acc: 0.9333 - val_loss: 0.7532 - val_acc: 0.6327\n",
            "Epoch 259/300\n",
            "\n",
            "Epoch 00259: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2955 - acc: 0.9067 - val_loss: 0.7077 - val_acc: 0.6531\n",
            "Epoch 260/300\n",
            "\n",
            "Epoch 00260: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2458 - acc: 0.9667 - val_loss: 0.7652 - val_acc: 0.6735\n",
            "Epoch 261/300\n",
            "\n",
            "Epoch 00261: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3080 - acc: 0.9133 - val_loss: 0.7152 - val_acc: 0.6531\n",
            "Epoch 262/300\n",
            "\n",
            "Epoch 00262: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2389 - acc: 0.9867 - val_loss: 0.7411 - val_acc: 0.6122\n",
            "Epoch 263/300\n",
            "\n",
            "Epoch 00263: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3134 - acc: 0.9200 - val_loss: 0.7202 - val_acc: 0.6531\n",
            "Epoch 264/300\n",
            "\n",
            "Epoch 00264: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3204 - acc: 0.9067 - val_loss: 0.7206 - val_acc: 0.6939\n",
            "Epoch 265/300\n",
            "\n",
            "Epoch 00265: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3082 - acc: 0.9000 - val_loss: 0.7583 - val_acc: 0.6327\n",
            "Epoch 266/300\n",
            "\n",
            "Epoch 00266: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2872 - acc: 0.9467 - val_loss: 0.6995 - val_acc: 0.7143\n",
            "Epoch 267/300\n",
            "\n",
            "Epoch 00267: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2654 - acc: 0.9467 - val_loss: 0.7067 - val_acc: 0.6735\n",
            "Epoch 268/300\n",
            "\n",
            "Epoch 00268: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2554 - acc: 0.9533 - val_loss: 0.7052 - val_acc: 0.6939\n",
            "Epoch 269/300\n",
            "\n",
            "Epoch 00269: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2576 - acc: 0.9467 - val_loss: 0.6992 - val_acc: 0.6531\n",
            "Epoch 270/300\n",
            "\n",
            "Epoch 00270: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2444 - acc: 0.9667 - val_loss: 0.7274 - val_acc: 0.6327\n",
            "Epoch 271/300\n",
            "\n",
            "Epoch 00271: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2392 - acc: 0.9600 - val_loss: 0.6730 - val_acc: 0.6531\n",
            "Epoch 272/300\n",
            "\n",
            "Epoch 00272: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2698 - acc: 0.9333 - val_loss: 0.6589 - val_acc: 0.7143\n",
            "Epoch 273/300\n",
            "\n",
            "Epoch 00273: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2714 - acc: 0.9267 - val_loss: 0.6941 - val_acc: 0.6735\n",
            "Epoch 274/300\n",
            "\n",
            "Epoch 00274: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2167 - acc: 0.9667 - val_loss: 0.7277 - val_acc: 0.6531\n",
            "Epoch 275/300\n",
            "\n",
            "Epoch 00275: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2963 - acc: 0.9600 - val_loss: 0.6865 - val_acc: 0.6939\n",
            "Epoch 276/300\n",
            "\n",
            "Epoch 00276: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2933 - acc: 0.9133 - val_loss: 0.6755 - val_acc: 0.6939\n",
            "Epoch 277/300\n",
            "\n",
            "Epoch 00277: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2471 - acc: 0.9667 - val_loss: 0.6978 - val_acc: 0.6735\n",
            "Epoch 278/300\n",
            "\n",
            "Epoch 00278: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2628 - acc: 0.9400 - val_loss: 0.7864 - val_acc: 0.6122\n",
            "Epoch 279/300\n",
            "\n",
            "Epoch 00279: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2366 - acc: 0.9600 - val_loss: 0.7278 - val_acc: 0.6939\n",
            "Epoch 280/300\n",
            "\n",
            "Epoch 00280: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2496 - acc: 0.9467 - val_loss: 0.7506 - val_acc: 0.6327\n",
            "Epoch 281/300\n",
            "\n",
            "Epoch 00281: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2340 - acc: 0.9600 - val_loss: 0.7037 - val_acc: 0.6939\n",
            "Epoch 282/300\n",
            "\n",
            "Epoch 00282: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2684 - acc: 0.9400 - val_loss: 0.7473 - val_acc: 0.6122\n",
            "Epoch 283/300\n",
            "\n",
            "Epoch 00283: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2605 - acc: 0.9400 - val_loss: 0.7217 - val_acc: 0.6327\n",
            "Epoch 284/300\n",
            "\n",
            "Epoch 00284: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2974 - acc: 0.9067 - val_loss: 0.8289 - val_acc: 0.5714\n",
            "Epoch 285/300\n",
            "\n",
            "Epoch 00285: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2840 - acc: 0.9400 - val_loss: 0.7137 - val_acc: 0.6939\n",
            "Epoch 286/300\n",
            "\n",
            "Epoch 00286: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3060 - acc: 0.9000 - val_loss: 0.7063 - val_acc: 0.6531\n",
            "Epoch 287/300\n",
            "\n",
            "Epoch 00287: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.2803 - acc: 0.9400 - val_loss: 0.7025 - val_acc: 0.6939\n",
            "Epoch 288/300\n",
            "\n",
            "Epoch 00288: val_loss did not improve from 0.65406\n",
            "150/150 - 0s - loss: 0.3029 - acc: 0.9133 - val_loss: 0.7103 - val_acc: 0.6531\n",
            "Epoch 289/300\n",
            "\n",
            "Epoch 00289: val_loss improved from 0.65406 to 0.63863, saving model to /tmp/checkpoint.h5\n",
            "150/150 - 0s - loss: 0.2905 - acc: 0.9267 - val_loss: 0.6386 - val_acc: 0.7143\n",
            "Epoch 290/300\n",
            "\n",
            "Epoch 00290: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2597 - acc: 0.9533 - val_loss: 0.6578 - val_acc: 0.7551\n",
            "Epoch 291/300\n",
            "\n",
            "Epoch 00291: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2489 - acc: 0.9533 - val_loss: 0.6875 - val_acc: 0.7143\n",
            "Epoch 292/300\n",
            "\n",
            "Epoch 00292: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2368 - acc: 0.9733 - val_loss: 0.7004 - val_acc: 0.6735\n",
            "Epoch 293/300\n",
            "\n",
            "Epoch 00293: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2815 - acc: 0.9267 - val_loss: 0.6985 - val_acc: 0.6939\n",
            "Epoch 294/300\n",
            "\n",
            "Epoch 00294: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2409 - acc: 0.9467 - val_loss: 0.7066 - val_acc: 0.6939\n",
            "Epoch 295/300\n",
            "\n",
            "Epoch 00295: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2132 - acc: 0.9667 - val_loss: 0.7311 - val_acc: 0.6327\n",
            "Epoch 296/300\n",
            "\n",
            "Epoch 00296: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2534 - acc: 0.9600 - val_loss: 0.7349 - val_acc: 0.6735\n",
            "Epoch 297/300\n",
            "\n",
            "Epoch 00297: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2362 - acc: 0.9667 - val_loss: 0.6871 - val_acc: 0.7143\n",
            "Epoch 298/300\n",
            "\n",
            "Epoch 00298: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2124 - acc: 0.9800 - val_loss: 0.6904 - val_acc: 0.7551\n",
            "Epoch 299/300\n",
            "\n",
            "Epoch 00299: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2392 - acc: 0.9467 - val_loss: 0.7474 - val_acc: 0.6327\n",
            "Epoch 300/300\n",
            "\n",
            "Epoch 00300: val_loss did not improve from 0.63863\n",
            "150/150 - 0s - loss: 0.2469 - acc: 0.9667 - val_loss: 0.6785 - val_acc: 0.7143\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}