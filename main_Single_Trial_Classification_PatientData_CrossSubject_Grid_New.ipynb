{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_Single_Trial_Classification_PatientData_CrossSubject_Grid_New",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/EEG_Deep/blob/master/main_Single_Trial_Classification_PatientData_CrossSubject_Grid_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X110PE9MjrlE",
        "colab_type": "code",
        "outputId": "9b8519bf-3e0a-4fce-a74d-8bc1f5327556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "!git clone https://github.com/sagihaider/EEG_Deep.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EEG_Deep'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 409 (delta 60), reused 0 (delta 0), pack-reused 313\u001b[K\n",
            "Receiving objects: 100% (409/409), 1.69 GiB | 36.67 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Checking out files: 100% (96/96), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioLzMoiS60Qf",
        "colab_type": "code",
        "outputId": "96cf8e00-dcce-4711-df57-89ac57e0e0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import scipy.io as spio\n",
        "import numpy as np\n",
        "from importlib.machinery import SourceFileLoader\n",
        "\n",
        "# EEGNet-specific imports\n",
        "from EEG_Deep.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# tools for plotting confusion matrices\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo80Jg_Pn5lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Band-pass Filter\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjtnE_6RSpum",
        "colab_type": "code",
        "outputId": "cb62299c-37f9-4b3f-9288-30ab17367fb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from numpy import zeros\n",
        "K.clear_session()\n",
        "cols = 1\n",
        "rows = 10\n",
        "\n",
        "h_cut = [24]\n",
        "drop_out = [0.25]\n",
        "k_len = [32, 64, 128]\n",
        "n_epochs = 10\n",
        "\n",
        "nsub = 10\n",
        "nfilt = len(h_cut)\n",
        "ndrop = len(drop_out)\n",
        "nkl = len(k_len)\n",
        "acc_sub = zeros([nsub, nfilt,ndrop,nkl])\n",
        "\n",
        "outfname = 'accuray_epochs' + str(n_epochs) + '_filter_' + str(h_cut) + '_drop_' + str(drop_out) + '_Cross_patient_data.npy'\n",
        "\n",
        "result=[]\n",
        "count = 0\n",
        "# data sample\n",
        "data = array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "# prepare cross validation\n",
        "kfold = KFold(10, True, 1)\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(data):\n",
        "  count = count + 1\n",
        "  # print('train: %s, test: %s' % (data[train], data[test]))\n",
        "  r_X_tr = np.empty([0, 12, 4096])\n",
        "  Y_tr = np.empty([0,1])\n",
        "  r_X_ts = np.empty([0, 12, 4096])\n",
        "  Y_ts = np.empty([0,1])\n",
        "  X_tr = np.empty([720, 12, 4096])\n",
        "  X_ts = np.empty([40, 12, 4096])\n",
        "  \n",
        "\n",
        "  for x in data[train]:\n",
        "    print(x)\n",
        "    fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'T.mat'  # Load Data\n",
        "    print(fName)\n",
        "    mat = spio.loadmat(fName)\n",
        "    x_tr = mat['RawEEGData']\n",
        "    y_tr = mat['Labels']\n",
        "    print(r_X_tr.shape)\n",
        "    r_X_tr=np.append(r_X_tr, x_tr, axis=0)\n",
        "    Y_tr=np.append(Y_tr, y_tr, axis=0)\n",
        "    print(r_X_tr.shape)\n",
        "    print(Y_tr.shape)\n",
        "\n",
        "\n",
        "  for x in data[test]:\n",
        "    print(x)\n",
        "    subid = x \n",
        "    fName = 'EEG_Deep/Data2A/parsed_P0' + str(x) + 'E.mat'  # Load Data\n",
        "    print(fName)\n",
        "    mat = spio.loadmat(fName)\n",
        "    x_ts = mat['RawEEGData']\n",
        "    y_ts = mat['Labels']\n",
        "    print(r_X_ts.shape)\n",
        "    r_X_ts=np.append(r_X_ts, x_ts, axis=0)\n",
        "    Y_ts=np.append(Y_ts, y_ts, axis=0)\n",
        "    print(r_X_ts.shape)\n",
        "    print(Y_ts.shape)\n",
        "\n",
        "    for h_indx, h in enumerate(h_cut):\n",
        "      ### Filter Training Data ###\n",
        "      print(\"Filtering of training data in progress\")\n",
        "      for t in range(r_X_tr.shape[0]):\n",
        "        tril = r_X_tr[t,:,:]\n",
        "        # tril = tril.transpose()\n",
        "        tril_filtered = butter_bandpass_filter(tril, lowcut=8,\n",
        "                                               highcut=h, fs=512,\n",
        "                                               order=4)\n",
        "        # tril_filtered = tril_filtered.transpose()\n",
        "        X_tr[t,:,:] = tril_filtered\n",
        "  \n",
        "      print(X_tr.shape)\n",
        "\n",
        "      ### Filter Test Data Data ###\n",
        "      print(\"Filtering of test data in progress\")\n",
        "      for t in range(r_X_ts.shape[0]):\n",
        "        tril = r_X_ts[t,:,:]\n",
        "        # tril = tril.transpose()\n",
        "        tril_filtered = butter_bandpass_filter(tril, lowcut=8, \n",
        "                                               highcut=h, fs=512,\n",
        "                                               order=4)\n",
        "        # tril_filtered = tril_filtered.transpose()\n",
        "        X_ts[t,:,:] = tril_filtered\n",
        "\n",
        "    print(X_ts.shape)\n",
        "\n",
        "    indices = np.arange(X_tr.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    X_tr = X_tr[indices]\n",
        "    Y_tr = Y_tr[indices]\n",
        "\n",
        "    # split data of each subject in training and validation\n",
        "    X_train = X_tr[0:620,:,2560:4096]\n",
        "    Y_train = Y_tr[0:620].ravel()\n",
        "    X_val   = X_tr[620:,:,2560:4096]\n",
        "    Y_val   = Y_tr[620:].ravel()\n",
        "    print(Y_val)\n",
        "    print(np.shape(X_train))\n",
        "    print(np.shape(Y_train))\n",
        "    print(np.shape(X_val))\n",
        "    print(np.shape(Y_val))\n",
        "\n",
        "    # convert labels to one-hot encodings.\n",
        "    Y_train      = np_utils.to_categorical(Y_train-1, num_classes=2)\n",
        "    Y_val       = np_utils.to_categorical(Y_val-1, num_classes=2)\n",
        "    print(Y_val)\n",
        "\n",
        "    kernels, chans, samples = 1, 12, 1536\n",
        "    # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "    # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "    X_train = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
        "    X_val   = X_val.reshape(X_val.shape[0], kernels, chans, samples)\n",
        "   \n",
        "    print('X_train shape:', X_train.shape)\n",
        "    print(X_train.shape[0], 'train samples')\n",
        "    print(X_val.shape[0], 'val samples')\n",
        "\n",
        "    X_test      = X_ts[:,:,2560:4096]\n",
        "    Y_test      = Y_ts[:]\n",
        "    print(np.shape(X_test))\n",
        "    print(np.shape(Y_test))\n",
        "\n",
        "    #convert labels to one-hot encodings.\n",
        "    Y_test      = np_utils.to_categorical(Y_test-1, num_classes=2)\n",
        "\n",
        "    # convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
        "    # contains 22 channels and 500 time-points. Set the number of kernels to 1.\n",
        "    X_test = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
        "    print('X_train shape:', X_test.shape)\n",
        "    print(X_test.shape[0], 'train samples')\n",
        "\n",
        "    for id_d, d in enumerate(drop_out):\n",
        "      for id_kl, kl in enumerate(k_len):\n",
        "        print(id_kl, id_d)\n",
        "        # configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
        "        # model configurations may do better, but this is a good starting point)\n",
        "        model = EEGNet(nb_classes = 2, Chans = 12, Samples = 1536,\n",
        "                       dropoutRate = d, kernLength = kl, F1 = 8, \n",
        "                       D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout')\n",
        "      \n",
        "        # compile the model and set the optimizers\n",
        "        model.compile(loss='categorical_crossentropy', \n",
        "                      optimizer='adam', metrics = ['accuracy'])\n",
        "        \n",
        "        # set a valid path for your system to record model checkpoints\n",
        "        checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "        # the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
        "        # the weights all to be 1\n",
        "        class_weights = {0:1, 1:1}\n",
        "\n",
        "        history = model.fit(X_train, Y_train, batch_size = 16, epochs = n_epochs, \n",
        "                            verbose = 2, validation_data=(X_val, Y_val),\n",
        "                            callbacks=[checkpointer], class_weight = class_weights)\n",
        "        \n",
        "        print('\\n# Evaluate on test data')\n",
        "        results = model.evaluate(X_test, Y_test, batch_size=1)\n",
        "        print('test loss, test acc:', results)\n",
        "\n",
        "        acc_sub[subid-1,h_indx,id_d, id_kl] = results[1]\n",
        "\n",
        "        from keras import backend as K \n",
        "        # Do some code, e.g. train and save model\n",
        "        K.clear_session()\n",
        "\n",
        "\n",
        "      \n",
        "np.save(outfname, acc_sub)\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[1. 1. 2. 1. 1. 2. 1. 2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 2. 2. 2. 1. 2.\n",
            " 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1.\n",
            " 1. 2. 1. 2. 1. 1. 2. 1. 2. 2. 1. 1. 1. 2. 1. 2. 2. 2. 1. 1. 2. 1. 2. 1.\n",
            " 1. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 1. 1.\n",
            " 2. 1. 2. 1.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68521, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6950 - acc: 0.5355 - val_loss: 0.6852 - val_acc: 0.4900\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.68521\n",
            "620/620 - 1s - loss: 0.6406 - acc: 0.6903 - val_loss: 0.6913 - val_acc: 0.4700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68521 to 0.68358, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6011 - acc: 0.7113 - val_loss: 0.6836 - val_acc: 0.4900\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.68358 to 0.64785, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5776 - acc: 0.7129 - val_loss: 0.6479 - val_acc: 0.6300\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.64785 to 0.60400, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5310 - acc: 0.7403 - val_loss: 0.6040 - val_acc: 0.7800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.60400 to 0.59200, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5304 - acc: 0.7306 - val_loss: 0.5920 - val_acc: 0.8500\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.59200 to 0.51396, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5122 - acc: 0.7613 - val_loss: 0.5140 - val_acc: 0.7600\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.51396\n",
            "620/620 - 1s - loss: 0.5034 - acc: 0.7597 - val_loss: 0.5205 - val_acc: 0.7400\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.51396 to 0.50454, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4940 - acc: 0.7516 - val_loss: 0.5045 - val_acc: 0.7500\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.50454\n",
            "620/620 - 1s - loss: 0.4922 - acc: 0.7629 - val_loss: 0.5366 - val_acc: 0.6900\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.9139 - acc: 0.4750\n",
            "test loss, test acc: [0.9138571282848715, 0.475]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69279, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6844 - acc: 0.5371 - val_loss: 0.6928 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69279 to 0.67711, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6236 - acc: 0.6984 - val_loss: 0.6771 - val_acc: 0.5700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.67711 to 0.64698, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5496 - acc: 0.7403 - val_loss: 0.6470 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.64698 to 0.60399, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5442 - acc: 0.7355 - val_loss: 0.6040 - val_acc: 0.7300\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.60399 to 0.55898, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5064 - acc: 0.7532 - val_loss: 0.5590 - val_acc: 0.7400\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.55898 to 0.50656, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4975 - acc: 0.7597 - val_loss: 0.5066 - val_acc: 0.8000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.50656 to 0.46900, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5062 - acc: 0.7371 - val_loss: 0.4690 - val_acc: 0.8200\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.46900 to 0.44238, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4894 - acc: 0.7645 - val_loss: 0.4424 - val_acc: 0.7900\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.44238\n",
            "620/620 - 1s - loss: 0.4877 - acc: 0.7677 - val_loss: 0.4458 - val_acc: 0.8100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.44238 to 0.43259, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4892 - acc: 0.7516 - val_loss: 0.4326 - val_acc: 0.8300\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.7941 - acc: 0.5250\n",
            "test loss, test acc: [0.7941494642291218, 0.525]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68708, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6612 - acc: 0.6145 - val_loss: 0.6871 - val_acc: 0.4700\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68708 to 0.66200, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5663 - acc: 0.7387 - val_loss: 0.6620 - val_acc: 0.5700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.66200 to 0.65491, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5203 - acc: 0.7419 - val_loss: 0.6549 - val_acc: 0.5800\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.65491 to 0.58888, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5006 - acc: 0.7435 - val_loss: 0.5889 - val_acc: 0.6600\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.58888 to 0.57853, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4895 - acc: 0.7548 - val_loss: 0.5785 - val_acc: 0.7100\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.57853 to 0.54184, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5052 - acc: 0.7629 - val_loss: 0.5418 - val_acc: 0.7600\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.54184 to 0.52180, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4979 - acc: 0.7629 - val_loss: 0.5218 - val_acc: 0.7900\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.52180 to 0.49947, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4786 - acc: 0.7484 - val_loss: 0.4995 - val_acc: 0.7800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.49947 to 0.48371, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4449 - acc: 0.7935 - val_loss: 0.4837 - val_acc: 0.8000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.48371\n",
            "620/620 - 1s - loss: 0.4545 - acc: 0.7952 - val_loss: 0.4877 - val_acc: 0.8100\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6629 - acc: 0.6500\n",
            "test loss, test acc: [0.6628919693175703, 0.65]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 1. 1. 1. 2. 2. 1. 1. 2. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 1.\n",
            " 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2. 1. 1. 2. 1. 2. 1.\n",
            " 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 2. 1. 2. 1. 2.\n",
            " 1. 1. 2. 1.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69326, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6973 - acc: 0.5242 - val_loss: 0.6933 - val_acc: 0.4700\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69326 to 0.69079, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6524 - acc: 0.6290 - val_loss: 0.6908 - val_acc: 0.5100\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.69079 to 0.69006, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6065 - acc: 0.7032 - val_loss: 0.6901 - val_acc: 0.5100\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.5505 - acc: 0.7500 - val_loss: 0.7097 - val_acc: 0.5300\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.5051 - acc: 0.7484 - val_loss: 0.7618 - val_acc: 0.5400\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.4882 - acc: 0.7806 - val_loss: 0.8585 - val_acc: 0.5300\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.4693 - acc: 0.7726 - val_loss: 0.8045 - val_acc: 0.5700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.4480 - acc: 0.7952 - val_loss: 0.8007 - val_acc: 0.5800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.4471 - acc: 0.8000 - val_loss: 0.8323 - val_acc: 0.5900\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.69006\n",
            "620/620 - 1s - loss: 0.4613 - acc: 0.7661 - val_loss: 0.7541 - val_acc: 0.6200\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.7330 - acc: 0.5000\n",
            "test loss, test acc: [0.7330304206348955, 0.5]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69135, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6972 - acc: 0.5129 - val_loss: 0.6914 - val_acc: 0.5200\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69135 to 0.68750, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6260 - acc: 0.6726 - val_loss: 0.6875 - val_acc: 0.5100\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.5547 - acc: 0.7274 - val_loss: 0.7175 - val_acc: 0.5100\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.5155 - acc: 0.7435 - val_loss: 0.7394 - val_acc: 0.5100\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.5025 - acc: 0.7758 - val_loss: 0.7473 - val_acc: 0.5400\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.4864 - acc: 0.7581 - val_loss: 0.7090 - val_acc: 0.5800\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.4869 - acc: 0.7726 - val_loss: 0.7530 - val_acc: 0.6000\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.4500 - acc: 0.7952 - val_loss: 0.7802 - val_acc: 0.6100\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.4712 - acc: 0.7629 - val_loss: 0.7249 - val_acc: 0.6300\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.68750\n",
            "620/620 - 1s - loss: 0.4641 - acc: 0.7903 - val_loss: 0.6967 - val_acc: 0.6300\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6635 - acc: 0.5250\n",
            "test loss, test acc: [0.6634825465269387, 0.525]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69101, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6956 - acc: 0.5419 - val_loss: 0.6910 - val_acc: 0.5300\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69101 to 0.68080, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6542 - acc: 0.6403 - val_loss: 0.6808 - val_acc: 0.5900\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68080 to 0.66307, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5811 - acc: 0.7194 - val_loss: 0.6631 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.66307 to 0.65315, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5144 - acc: 0.7500 - val_loss: 0.6532 - val_acc: 0.6400\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.65315 to 0.63810, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4943 - acc: 0.7645 - val_loss: 0.6381 - val_acc: 0.6800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.63810\n",
            "620/620 - 1s - loss: 0.4924 - acc: 0.7742 - val_loss: 0.6411 - val_acc: 0.6700\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.63810\n",
            "620/620 - 1s - loss: 0.4592 - acc: 0.7790 - val_loss: 0.6554 - val_acc: 0.6700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.63810\n",
            "620/620 - 1s - loss: 0.4595 - acc: 0.7887 - val_loss: 0.6798 - val_acc: 0.6600\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.63810\n",
            "620/620 - 1s - loss: 0.4626 - acc: 0.7790 - val_loss: 0.6659 - val_acc: 0.6600\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.63810\n",
            "620/620 - 1s - loss: 0.4448 - acc: 0.7919 - val_loss: 0.6948 - val_acc: 0.6700\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6218 - acc: 0.5750\n",
            "test loss, test acc: [0.6217766385525465, 0.575]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 2. 1. 2. 1. 2. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 2. 2. 2. 1. 1. 1. 2. 2.\n",
            " 1. 1. 1. 2. 2. 1. 2. 1. 1. 1. 2. 2. 1. 1. 1. 2. 2. 1. 2. 2. 1. 1. 1. 2.\n",
            " 2. 1. 2. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1.\n",
            " 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 2. 2. 2.\n",
            " 1. 1. 1. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69135, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6952 - acc: 0.5129 - val_loss: 0.6914 - val_acc: 0.4900\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69135 to 0.68876, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6608 - acc: 0.5952 - val_loss: 0.6888 - val_acc: 0.5300\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68876 to 0.68243, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6190 - acc: 0.7145 - val_loss: 0.6824 - val_acc: 0.4700\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68243\n",
            "620/620 - 1s - loss: 0.5569 - acc: 0.7613 - val_loss: 0.6953 - val_acc: 0.4800\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68243\n",
            "620/620 - 1s - loss: 0.5235 - acc: 0.7500 - val_loss: 0.6886 - val_acc: 0.4800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.68243 to 0.63323, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4931 - acc: 0.7645 - val_loss: 0.6332 - val_acc: 0.5700\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.63323\n",
            "620/620 - 1s - loss: 0.5047 - acc: 0.7435 - val_loss: 0.6396 - val_acc: 0.5600\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.63323 to 0.60764, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4855 - acc: 0.7774 - val_loss: 0.6076 - val_acc: 0.6300\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.60764 to 0.56158, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4610 - acc: 0.8113 - val_loss: 0.5616 - val_acc: 0.7200\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.56158 to 0.51144, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4786 - acc: 0.7839 - val_loss: 0.5114 - val_acc: 0.7800\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6162 - acc: 0.6000\n",
            "test loss, test acc: [0.6162309683859348, 0.6]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69136, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6893 - acc: 0.5274 - val_loss: 0.6914 - val_acc: 0.4900\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69136 to 0.68476, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6245 - acc: 0.7032 - val_loss: 0.6848 - val_acc: 0.4600\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68476\n",
            "620/620 - 1s - loss: 0.5648 - acc: 0.7339 - val_loss: 0.6894 - val_acc: 0.4600\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68476\n",
            "620/620 - 1s - loss: 0.5273 - acc: 0.7581 - val_loss: 0.7064 - val_acc: 0.4600\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68476\n",
            "620/620 - 1s - loss: 0.5184 - acc: 0.7565 - val_loss: 0.7215 - val_acc: 0.4800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68476\n",
            "620/620 - 1s - loss: 0.4928 - acc: 0.7742 - val_loss: 0.6889 - val_acc: 0.5100\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.68476 to 0.66243, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4986 - acc: 0.7774 - val_loss: 0.6624 - val_acc: 0.5700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.66243 to 0.61228, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4929 - acc: 0.7823 - val_loss: 0.6123 - val_acc: 0.6200\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.61228\n",
            "620/620 - 1s - loss: 0.4719 - acc: 0.7661 - val_loss: 0.6171 - val_acc: 0.6200\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.61228\n",
            "620/620 - 1s - loss: 0.4528 - acc: 0.7903 - val_loss: 0.6465 - val_acc: 0.6200\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.9117 - acc: 0.5000\n",
            "test loss, test acc: [0.9116830963641405, 0.5]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67738, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6804 - acc: 0.5694 - val_loss: 0.6774 - val_acc: 0.7200\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67738 to 0.67223, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5876 - acc: 0.7323 - val_loss: 0.6722 - val_acc: 0.5300\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.67223\n",
            "620/620 - 1s - loss: 0.5161 - acc: 0.7694 - val_loss: 0.6839 - val_acc: 0.5100\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.67223 to 0.64297, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5006 - acc: 0.7581 - val_loss: 0.6430 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.64297\n",
            "620/620 - 1s - loss: 0.4903 - acc: 0.7613 - val_loss: 0.6587 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.64297 to 0.62217, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4875 - acc: 0.7823 - val_loss: 0.6222 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.62217 to 0.57271, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4714 - acc: 0.7661 - val_loss: 0.5727 - val_acc: 0.6400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57271 to 0.55086, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4694 - acc: 0.7855 - val_loss: 0.5509 - val_acc: 0.6800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.55086\n",
            "620/620 - 1s - loss: 0.4600 - acc: 0.7935 - val_loss: 0.5524 - val_acc: 0.6800\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.55086 to 0.51197, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4571 - acc: 0.7790 - val_loss: 0.5120 - val_acc: 0.7200\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.7270 - acc: 0.5000\n",
            "test loss, test acc: [0.7269667251035571, 0.5]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 2. 1. 2. 1. 2. 2. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 1. 2. 1. 1. 2.\n",
            " 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 1. 1. 2. 1. 2. 2. 1. 2. 1. 1. 1. 1. 2. 1.\n",
            " 2. 1. 1. 2. 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 2.\n",
            " 1. 2. 2. 2. 1. 2. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
            " 2. 1. 2. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69410, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6907 - acc: 0.5258 - val_loss: 0.6941 - val_acc: 0.6000\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69410 to 0.67880, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6317 - acc: 0.6855 - val_loss: 0.6788 - val_acc: 0.5600\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.5631 - acc: 0.7161 - val_loss: 0.7356 - val_acc: 0.5600\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.5398 - acc: 0.7274 - val_loss: 0.8378 - val_acc: 0.5600\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.5180 - acc: 0.7355 - val_loss: 0.7600 - val_acc: 0.5800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.5114 - acc: 0.7484 - val_loss: 0.7259 - val_acc: 0.5900\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.4982 - acc: 0.7516 - val_loss: 0.7630 - val_acc: 0.5900\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.67880\n",
            "620/620 - 1s - loss: 0.4936 - acc: 0.7532 - val_loss: 0.6983 - val_acc: 0.6200\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.67880 to 0.65343, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4869 - acc: 0.7565 - val_loss: 0.6534 - val_acc: 0.6800\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.65343\n",
            "620/620 - 1s - loss: 0.4766 - acc: 0.7806 - val_loss: 0.6792 - val_acc: 0.6800\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.4315 - acc: 0.8000\n",
            "test loss, test acc: [0.43149581030011175, 0.8]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69401, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6971 - acc: 0.5194 - val_loss: 0.6940 - val_acc: 0.5800\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69401 to 0.67764, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6370 - acc: 0.6855 - val_loss: 0.6776 - val_acc: 0.6300\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.67764 to 0.64760, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5941 - acc: 0.7081 - val_loss: 0.6476 - val_acc: 0.6300\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.64760\n",
            "620/620 - 1s - loss: 0.5423 - acc: 0.7226 - val_loss: 0.6913 - val_acc: 0.5800\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.64760 to 0.63911, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5306 - acc: 0.7435 - val_loss: 0.6391 - val_acc: 0.6300\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.63911\n",
            "620/620 - 1s - loss: 0.5042 - acc: 0.7516 - val_loss: 0.6786 - val_acc: 0.6300\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.63911\n",
            "620/620 - 1s - loss: 0.5250 - acc: 0.7435 - val_loss: 0.6481 - val_acc: 0.6400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.63911\n",
            "620/620 - 1s - loss: 0.4925 - acc: 0.7500 - val_loss: 0.6428 - val_acc: 0.6800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.63911\n",
            "620/620 - 1s - loss: 0.4910 - acc: 0.7371 - val_loss: 0.7826 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.63911 to 0.61250, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4989 - acc: 0.7468 - val_loss: 0.6125 - val_acc: 0.6700\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.4458 - acc: 0.8000\n",
            "test loss, test acc: [0.4457741379737854, 0.8]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68618, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6792 - acc: 0.5726 - val_loss: 0.6862 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.68618\n",
            "620/620 - 1s - loss: 0.5588 - acc: 0.7161 - val_loss: 0.6879 - val_acc: 0.5600\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68618\n",
            "620/620 - 1s - loss: 0.5227 - acc: 0.7500 - val_loss: 0.7315 - val_acc: 0.5600\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68618\n",
            "620/620 - 1s - loss: 0.4951 - acc: 0.7516 - val_loss: 0.7947 - val_acc: 0.5700\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68618\n",
            "620/620 - 1s - loss: 0.4734 - acc: 0.7855 - val_loss: 0.7602 - val_acc: 0.5800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68618\n",
            "620/620 - 1s - loss: 0.4800 - acc: 0.7661 - val_loss: 0.6872 - val_acc: 0.6200\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.68618 to 0.65225, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4802 - acc: 0.7661 - val_loss: 0.6522 - val_acc: 0.6900\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.65225\n",
            "620/620 - 1s - loss: 0.4425 - acc: 0.7887 - val_loss: 0.6797 - val_acc: 0.7100\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.65225 to 0.61295, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4600 - acc: 0.7871 - val_loss: 0.6129 - val_acc: 0.7200\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.61295\n",
            "620/620 - 1s - loss: 0.4599 - acc: 0.7774 - val_loss: 0.6953 - val_acc: 0.7000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.4032 - acc: 0.8500\n",
            "test loss, test acc: [0.40322505626827476, 0.85]\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 2. 2. 2. 2. 1. 2. 1. 1. 2. 2. 1. 2. 1. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2.\n",
            " 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 2. 2. 1. 2. 1. 2. 2. 1. 1. 1. 2. 1. 1.\n",
            " 2. 1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 2.\n",
            " 1. 2. 2. 1. 1. 1. 1. 2. 2. 1. 2. 1. 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 2.\n",
            " 2. 1. 1. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69577, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6795 - acc: 0.6048 - val_loss: 0.6958 - val_acc: 0.4200\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.6011 - acc: 0.6984 - val_loss: 0.7286 - val_acc: 0.4200\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.5665 - acc: 0.7161 - val_loss: 0.7175 - val_acc: 0.4200\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.5385 - acc: 0.7468 - val_loss: 0.7321 - val_acc: 0.4200\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.5321 - acc: 0.7371 - val_loss: 0.7568 - val_acc: 0.4400\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.5286 - acc: 0.7452 - val_loss: 0.7510 - val_acc: 0.4300\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.69577\n",
            "620/620 - 1s - loss: 0.5065 - acc: 0.7565 - val_loss: 0.7979 - val_acc: 0.4400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.69577 to 0.68550, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4972 - acc: 0.7565 - val_loss: 0.6855 - val_acc: 0.5800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68550\n",
            "620/620 - 1s - loss: 0.4832 - acc: 0.7774 - val_loss: 0.7048 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.68550 to 0.67429, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4994 - acc: 0.7677 - val_loss: 0.6743 - val_acc: 0.5900\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6620 - acc: 0.6000\n",
            "test loss, test acc: [0.662031673383899, 0.6]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68769, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6934 - acc: 0.5258 - val_loss: 0.6877 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68769 to 0.68255, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6659 - acc: 0.6113 - val_loss: 0.6825 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68255 to 0.66277, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6378 - acc: 0.6452 - val_loss: 0.6628 - val_acc: 0.6300\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.66277 to 0.65405, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6217 - acc: 0.6855 - val_loss: 0.6541 - val_acc: 0.6300\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.65405 to 0.64827, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6047 - acc: 0.6871 - val_loss: 0.6483 - val_acc: 0.6300\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.64827 to 0.63368, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5962 - acc: 0.6935 - val_loss: 0.6337 - val_acc: 0.6700\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.63368 to 0.58555, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5728 - acc: 0.6919 - val_loss: 0.5856 - val_acc: 0.7200\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.58555 to 0.58157, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5383 - acc: 0.7468 - val_loss: 0.5816 - val_acc: 0.6900\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.58157\n",
            "620/620 - 1s - loss: 0.5151 - acc: 0.7581 - val_loss: 0.5944 - val_acc: 0.6500\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.58157\n",
            "620/620 - 1s - loss: 0.5038 - acc: 0.7516 - val_loss: 0.6126 - val_acc: 0.6000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5728 - acc: 0.7500\n",
            "test loss, test acc: [0.5727850540541113, 0.75]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68789, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6938 - acc: 0.5065 - val_loss: 0.6879 - val_acc: 0.5700\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68789 to 0.68364, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6451 - acc: 0.6710 - val_loss: 0.6836 - val_acc: 0.5200\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.6022 - acc: 0.7065 - val_loss: 0.6883 - val_acc: 0.4300\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.5258 - acc: 0.7677 - val_loss: 0.7209 - val_acc: 0.4500\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.4887 - acc: 0.7887 - val_loss: 0.7296 - val_acc: 0.4900\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.4813 - acc: 0.7903 - val_loss: 0.7088 - val_acc: 0.5800\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.4874 - acc: 0.7774 - val_loss: 0.7165 - val_acc: 0.5600\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.4790 - acc: 0.7790 - val_loss: 0.6925 - val_acc: 0.5900\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68364\n",
            "620/620 - 1s - loss: 0.4664 - acc: 0.7742 - val_loss: 0.6890 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.68364 to 0.68117, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4553 - acc: 0.7839 - val_loss: 0.6812 - val_acc: 0.6000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.7183 - acc: 0.6000\n",
            "test loss, test acc: [0.7182885111309588, 0.6]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 1. 2. 1. 2. 2. 1. 2. 1. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 2.\n",
            " 2. 2. 2. 1. 1. 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 1. 2.\n",
            " 1. 1. 1. 2. 1. 2. 1. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 1. 2. 2. 1.\n",
            " 1. 1. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 1. 2. 1. 2. 2.\n",
            " 1. 1. 2. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.66271, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6861 - acc: 0.5565 - val_loss: 0.6627 - val_acc: 0.5900\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.66271 to 0.64227, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6378 - acc: 0.6758 - val_loss: 0.6423 - val_acc: 0.5700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.64227 to 0.62850, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6060 - acc: 0.6919 - val_loss: 0.6285 - val_acc: 0.5700\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.62850\n",
            "620/620 - 1s - loss: 0.5772 - acc: 0.7194 - val_loss: 0.6293 - val_acc: 0.5800\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.62850 to 0.60479, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5537 - acc: 0.7323 - val_loss: 0.6048 - val_acc: 0.5800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.60479 to 0.60478, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5308 - acc: 0.7468 - val_loss: 0.6048 - val_acc: 0.6300\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.60478 to 0.58098, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5057 - acc: 0.7710 - val_loss: 0.5810 - val_acc: 0.6700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.58098 to 0.56621, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4974 - acc: 0.7532 - val_loss: 0.5662 - val_acc: 0.7100\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.56621\n",
            "620/620 - 1s - loss: 0.5111 - acc: 0.7403 - val_loss: 0.5670 - val_acc: 0.7100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.56621 to 0.55993, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4783 - acc: 0.7661 - val_loss: 0.5599 - val_acc: 0.7000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5974 - acc: 0.7250\n",
            "test loss, test acc: [0.5973545901477337, 0.725]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67980, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.7051 - acc: 0.4710 - val_loss: 0.6798 - val_acc: 0.5800\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67980 to 0.64822, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6438 - acc: 0.6726 - val_loss: 0.6482 - val_acc: 0.5700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.64822 to 0.63079, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6234 - acc: 0.6645 - val_loss: 0.6308 - val_acc: 0.6200\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63079 to 0.62314, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5698 - acc: 0.7194 - val_loss: 0.6231 - val_acc: 0.6200\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.62314 to 0.60217, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5400 - acc: 0.7387 - val_loss: 0.6022 - val_acc: 0.6800\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.60217 to 0.59050, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5191 - acc: 0.7516 - val_loss: 0.5905 - val_acc: 0.7000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.59050\n",
            "620/620 - 1s - loss: 0.5110 - acc: 0.7403 - val_loss: 0.5914 - val_acc: 0.6800\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.59050 to 0.58171, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4993 - acc: 0.7548 - val_loss: 0.5817 - val_acc: 0.6900\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.58171\n",
            "620/620 - 1s - loss: 0.5192 - acc: 0.7355 - val_loss: 0.5878 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.58171 to 0.56780, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5030 - acc: 0.7581 - val_loss: 0.5678 - val_acc: 0.7000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6404 - acc: 0.5750\n",
            "test loss, test acc: [0.6403709948062897, 0.575]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67375, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6849 - acc: 0.5565 - val_loss: 0.6738 - val_acc: 0.6400\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67375 to 0.64134, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6141 - acc: 0.6726 - val_loss: 0.6413 - val_acc: 0.5700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.64134 to 0.62865, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5723 - acc: 0.7097 - val_loss: 0.6286 - val_acc: 0.5700\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.62865 to 0.61845, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5236 - acc: 0.7306 - val_loss: 0.6184 - val_acc: 0.5700\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.61845 to 0.59661, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5211 - acc: 0.7387 - val_loss: 0.5966 - val_acc: 0.6600\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.59661 to 0.58588, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5071 - acc: 0.7581 - val_loss: 0.5859 - val_acc: 0.7200\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.58588 to 0.57709, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5039 - acc: 0.7532 - val_loss: 0.5771 - val_acc: 0.7300\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57709 to 0.56047, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5082 - acc: 0.7548 - val_loss: 0.5605 - val_acc: 0.7400\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.56047 to 0.54247, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5018 - acc: 0.7468 - val_loss: 0.5425 - val_acc: 0.7400\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.54247\n",
            "620/620 - 1s - loss: 0.4797 - acc: 0.7806 - val_loss: 0.5490 - val_acc: 0.7300\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5961 - acc: 0.6000\n",
            "test loss, test acc: [0.5961027950048446, 0.6]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 2. 2. 2. 2. 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 2. 1. 2.\n",
            " 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 1. 2. 1. 2. 1.\n",
            " 1. 2. 2. 1. 2. 2. 1. 1. 1. 2. 1. 2. 2. 1. 1. 2. 2. 2. 2. 2. 1. 2. 2. 2.\n",
            " 2. 2. 2. 1. 2. 2. 1. 2. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 2. 1. 1. 2.\n",
            " 1. 1. 2. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68541, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.7012 - acc: 0.5339 - val_loss: 0.6854 - val_acc: 0.5300\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68541 to 0.67648, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6592 - acc: 0.6177 - val_loss: 0.6765 - val_acc: 0.5300\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.67648 to 0.67060, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6072 - acc: 0.6952 - val_loss: 0.6706 - val_acc: 0.5300\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.67060\n",
            "620/620 - 1s - loss: 0.5658 - acc: 0.7226 - val_loss: 0.6886 - val_acc: 0.5200\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.67060\n",
            "620/620 - 1s - loss: 0.5375 - acc: 0.7210 - val_loss: 0.7253 - val_acc: 0.4900\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.67060\n",
            "620/620 - 1s - loss: 0.5168 - acc: 0.7371 - val_loss: 0.6911 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.67060 to 0.65013, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5182 - acc: 0.7484 - val_loss: 0.6501 - val_acc: 0.5600\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.65013 to 0.62510, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4960 - acc: 0.7710 - val_loss: 0.6251 - val_acc: 0.6000\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.62510 to 0.61378, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4986 - acc: 0.7565 - val_loss: 0.6138 - val_acc: 0.6400\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.61378 to 0.61181, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4899 - acc: 0.7452 - val_loss: 0.6118 - val_acc: 0.6100\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5572 - acc: 0.7750\n",
            "test loss, test acc: [0.5572160698473454, 0.775]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68535, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6947 - acc: 0.5177 - val_loss: 0.6854 - val_acc: 0.5100\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68535 to 0.67804, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6480 - acc: 0.6677 - val_loss: 0.6780 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.5987 - acc: 0.7097 - val_loss: 0.7055 - val_acc: 0.4900\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.5473 - acc: 0.7323 - val_loss: 0.7506 - val_acc: 0.4900\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.5220 - acc: 0.7500 - val_loss: 0.7412 - val_acc: 0.4900\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.5104 - acc: 0.7387 - val_loss: 0.7375 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.4971 - acc: 0.7677 - val_loss: 0.7228 - val_acc: 0.5200\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.4833 - acc: 0.7806 - val_loss: 0.6827 - val_acc: 0.5700\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.67804\n",
            "620/620 - 1s - loss: 0.4870 - acc: 0.7677 - val_loss: 0.6867 - val_acc: 0.6100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.67804 to 0.67143, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4820 - acc: 0.7548 - val_loss: 0.6714 - val_acc: 0.6000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6283 - acc: 0.6250\n",
            "test loss, test acc: [0.6283432107418776, 0.625]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67659, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6910 - acc: 0.5387 - val_loss: 0.6766 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67659 to 0.66618, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6432 - acc: 0.6516 - val_loss: 0.6662 - val_acc: 0.5200\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.66618\n",
            "620/620 - 1s - loss: 0.5802 - acc: 0.7274 - val_loss: 0.6751 - val_acc: 0.5100\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.66618\n",
            "620/620 - 1s - loss: 0.5437 - acc: 0.7129 - val_loss: 0.6815 - val_acc: 0.5200\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.66618\n",
            "620/620 - 1s - loss: 0.5152 - acc: 0.7468 - val_loss: 0.6694 - val_acc: 0.5400\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.66618 to 0.66529, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5151 - acc: 0.7516 - val_loss: 0.6653 - val_acc: 0.5600\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.66529\n",
            "620/620 - 1s - loss: 0.4806 - acc: 0.7758 - val_loss: 0.6780 - val_acc: 0.5700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.66529\n",
            "620/620 - 1s - loss: 0.4672 - acc: 0.7806 - val_loss: 0.7202 - val_acc: 0.5700\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.66529 to 0.64518, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4573 - acc: 0.7984 - val_loss: 0.6452 - val_acc: 0.6100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.64518\n",
            "620/620 - 1s - loss: 0.4769 - acc: 0.7823 - val_loss: 0.6761 - val_acc: 0.5900\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6308 - acc: 0.6250\n",
            "test loss, test acc: [0.6307980120182037, 0.625]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[1. 1. 1. 2. 2. 1. 2. 1. 2. 1. 2. 1. 1. 2. 2. 1. 1. 1. 2. 2. 1. 1. 2. 1.\n",
            " 2. 2. 1. 2. 1. 2. 2. 1. 1. 2. 2. 1. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 1.\n",
            " 2. 1. 2. 2. 1. 1. 1. 1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2.\n",
            " 2. 2. 1. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 2. 1. 2. 1. 2. 2. 1.\n",
            " 2. 1. 1. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68276, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6827 - acc: 0.5532 - val_loss: 0.6828 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.6293 - acc: 0.6726 - val_loss: 0.6836 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.5816 - acc: 0.7048 - val_loss: 0.7130 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.5525 - acc: 0.7306 - val_loss: 0.7924 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.5262 - acc: 0.7371 - val_loss: 0.8531 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.4999 - acc: 0.7597 - val_loss: 0.8984 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.4848 - acc: 0.7581 - val_loss: 0.8713 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.4816 - acc: 0.7919 - val_loss: 0.8232 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.4878 - acc: 0.7565 - val_loss: 0.8048 - val_acc: 0.5100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.68276\n",
            "620/620 - 1s - loss: 0.4694 - acc: 0.7726 - val_loss: 0.7271 - val_acc: 0.5500\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.7841 - acc: 0.5000\n",
            "test loss, test acc: [0.7841482850897592, 0.5]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67776, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6874 - acc: 0.5161 - val_loss: 0.6778 - val_acc: 0.5500\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67776 to 0.66129, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6430 - acc: 0.6726 - val_loss: 0.6613 - val_acc: 0.5500\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.66129 to 0.64859, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5794 - acc: 0.7306 - val_loss: 0.6486 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.64859\n",
            "620/620 - 1s - loss: 0.5312 - acc: 0.7468 - val_loss: 0.6802 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.64859\n",
            "620/620 - 1s - loss: 0.5218 - acc: 0.7645 - val_loss: 0.6891 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.64859\n",
            "620/620 - 1s - loss: 0.5042 - acc: 0.7613 - val_loss: 0.7060 - val_acc: 0.5100\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.64859\n",
            "620/620 - 1s - loss: 0.4840 - acc: 0.7645 - val_loss: 0.6843 - val_acc: 0.5400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.64859\n",
            "620/620 - 1s - loss: 0.4659 - acc: 0.7855 - val_loss: 0.6523 - val_acc: 0.5800\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.64859 to 0.58802, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4773 - acc: 0.7629 - val_loss: 0.5880 - val_acc: 0.6400\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.58802 to 0.58362, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4812 - acc: 0.7855 - val_loss: 0.5836 - val_acc: 0.6600\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6939 - acc: 0.5250\n",
            "test loss, test acc: [0.6939495196682401, 0.525]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68395, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6886 - acc: 0.5355 - val_loss: 0.6839 - val_acc: 0.5600\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68395 to 0.66901, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6385 - acc: 0.6661 - val_loss: 0.6690 - val_acc: 0.5100\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.66901 to 0.65278, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5952 - acc: 0.7242 - val_loss: 0.6528 - val_acc: 0.5300\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.65278\n",
            "620/620 - 1s - loss: 0.5532 - acc: 0.7306 - val_loss: 0.6591 - val_acc: 0.5500\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.65278 to 0.62957, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5253 - acc: 0.7532 - val_loss: 0.6296 - val_acc: 0.5900\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.62957 to 0.56462, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4847 - acc: 0.7903 - val_loss: 0.5646 - val_acc: 0.6700\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.56462 to 0.54097, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4822 - acc: 0.7661 - val_loss: 0.5410 - val_acc: 0.7000\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.54097\n",
            "620/620 - 1s - loss: 0.4793 - acc: 0.7855 - val_loss: 0.5423 - val_acc: 0.7100\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.54097\n",
            "620/620 - 1s - loss: 0.4688 - acc: 0.7935 - val_loss: 0.5533 - val_acc: 0.6700\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.54097 to 0.52273, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4658 - acc: 0.7726 - val_loss: 0.5227 - val_acc: 0.7100\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5086 - acc: 0.7000\n",
            "test loss, test acc: [0.5086281951749697, 0.7]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 2. 1. 1. 2.\n",
            " 1. 1. 2. 2. 2. 2. 1. 2. 2. 1. 2. 1. 2. 1. 1. 1. 1. 2. 1. 2. 2. 1. 1. 2.\n",
            " 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2. 2. 2. 1. 2. 1.\n",
            " 1. 1. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 1. 2. 2. 2. 2. 2.\n",
            " 1. 2. 1. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68181, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.7017 - acc: 0.5129 - val_loss: 0.6818 - val_acc: 0.5700\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68181 to 0.67167, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6525 - acc: 0.6581 - val_loss: 0.6717 - val_acc: 0.5600\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.67167 to 0.65641, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6096 - acc: 0.7065 - val_loss: 0.6564 - val_acc: 0.5600\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.65641\n",
            "620/620 - 1s - loss: 0.5538 - acc: 0.7274 - val_loss: 0.6591 - val_acc: 0.5600\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.65641\n",
            "620/620 - 1s - loss: 0.5178 - acc: 0.7500 - val_loss: 0.6680 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.65641 to 0.64102, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4851 - acc: 0.7855 - val_loss: 0.6410 - val_acc: 0.6000\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.64102 to 0.57735, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4754 - acc: 0.7839 - val_loss: 0.5773 - val_acc: 0.6700\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.57735 to 0.55494, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4845 - acc: 0.7677 - val_loss: 0.5549 - val_acc: 0.7000\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.55494 to 0.54119, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4523 - acc: 0.8081 - val_loss: 0.5412 - val_acc: 0.7200\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.54119 to 0.53333, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4591 - acc: 0.7758 - val_loss: 0.5333 - val_acc: 0.7400\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.6194 - acc: 0.6750\n",
            "test loss, test acc: [0.6194004945456981, 0.675]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67683, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6779 - acc: 0.5419 - val_loss: 0.6768 - val_acc: 0.5400\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67683 to 0.65340, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5969 - acc: 0.7048 - val_loss: 0.6534 - val_acc: 0.5600\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65340 to 0.63116, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5362 - acc: 0.7484 - val_loss: 0.6312 - val_acc: 0.5800\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63116 to 0.62902, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4724 - acc: 0.7742 - val_loss: 0.6290 - val_acc: 0.6100\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.62902 to 0.59124, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4884 - acc: 0.7613 - val_loss: 0.5912 - val_acc: 0.6500\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.59124 to 0.56807, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4563 - acc: 0.8000 - val_loss: 0.5681 - val_acc: 0.7100\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.56807\n",
            "620/620 - 1s - loss: 0.4675 - acc: 0.7710 - val_loss: 0.5855 - val_acc: 0.6800\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.56807 to 0.53914, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4716 - acc: 0.7548 - val_loss: 0.5391 - val_acc: 0.7300\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.53914\n",
            "620/620 - 1s - loss: 0.4232 - acc: 0.8032 - val_loss: 0.5449 - val_acc: 0.7300\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.53914 to 0.52632, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4369 - acc: 0.7952 - val_loss: 0.5263 - val_acc: 0.7500\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5541 - acc: 0.7500\n",
            "test loss, test acc: [0.554140730574727, 0.75]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68342, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6873 - acc: 0.5274 - val_loss: 0.6834 - val_acc: 0.5700\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68342 to 0.65944, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6381 - acc: 0.6839 - val_loss: 0.6594 - val_acc: 0.6000\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65944 to 0.63692, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5711 - acc: 0.7419 - val_loss: 0.6369 - val_acc: 0.6400\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63692 to 0.60137, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5259 - acc: 0.7581 - val_loss: 0.6014 - val_acc: 0.7100\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.60137 to 0.56939, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4835 - acc: 0.7790 - val_loss: 0.5694 - val_acc: 0.7200\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.56939 to 0.55634, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4703 - acc: 0.7645 - val_loss: 0.5563 - val_acc: 0.7400\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.55634 to 0.55480, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4647 - acc: 0.7839 - val_loss: 0.5548 - val_acc: 0.7300\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.55480 to 0.53173, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4604 - acc: 0.7903 - val_loss: 0.5317 - val_acc: 0.7100\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.53173\n",
            "620/620 - 1s - loss: 0.4528 - acc: 0.7806 - val_loss: 0.5571 - val_acc: 0.7100\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.53173\n",
            "620/620 - 1s - loss: 0.4433 - acc: 0.7968 - val_loss: 0.5399 - val_acc: 0.7300\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.5780 - acc: 0.6750\n",
            "test loss, test acc: [0.5779890529811382, 0.675]\n",
            "1\n",
            "EEG_Deep/Data2A/parsed_P01T.mat\n",
            "(0, 12, 4096)\n",
            "(80, 12, 4096)\n",
            "(80, 1)\n",
            "2\n",
            "EEG_Deep/Data2A/parsed_P02T.mat\n",
            "(80, 12, 4096)\n",
            "(160, 12, 4096)\n",
            "(160, 1)\n",
            "3\n",
            "EEG_Deep/Data2A/parsed_P03T.mat\n",
            "(160, 12, 4096)\n",
            "(240, 12, 4096)\n",
            "(240, 1)\n",
            "4\n",
            "EEG_Deep/Data2A/parsed_P04T.mat\n",
            "(240, 12, 4096)\n",
            "(320, 12, 4096)\n",
            "(320, 1)\n",
            "5\n",
            "EEG_Deep/Data2A/parsed_P05T.mat\n",
            "(320, 12, 4096)\n",
            "(400, 12, 4096)\n",
            "(400, 1)\n",
            "7\n",
            "EEG_Deep/Data2A/parsed_P07T.mat\n",
            "(400, 12, 4096)\n",
            "(480, 12, 4096)\n",
            "(480, 1)\n",
            "8\n",
            "EEG_Deep/Data2A/parsed_P08T.mat\n",
            "(480, 12, 4096)\n",
            "(560, 12, 4096)\n",
            "(560, 1)\n",
            "9\n",
            "EEG_Deep/Data2A/parsed_P09T.mat\n",
            "(560, 12, 4096)\n",
            "(640, 12, 4096)\n",
            "(640, 1)\n",
            "10\n",
            "EEG_Deep/Data2A/parsed_P010T.mat\n",
            "(640, 12, 4096)\n",
            "(720, 12, 4096)\n",
            "(720, 1)\n",
            "6\n",
            "EEG_Deep/Data2A/parsed_P06E.mat\n",
            "(0, 12, 4096)\n",
            "(40, 12, 4096)\n",
            "(40, 1)\n",
            "Filtering of training data in progress\n",
            "(720, 12, 4096)\n",
            "Filtering of test data in progress\n",
            "(40, 12, 4096)\n",
            "[1. 1. 1. 2. 2. 2. 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 2. 1.\n",
            " 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 2. 2. 2. 2. 1. 1. 2. 1. 2. 2. 1. 2. 1. 2.\n",
            " 1. 1. 2. 1. 2. 1. 2. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 2. 1. 2. 1. 1. 1. 1.\n",
            " 1. 2. 1. 1. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 1. 1. 1.\n",
            " 1. 2. 1. 2.]\n",
            "(620, 12, 1536)\n",
            "(620,)\n",
            "(100, 12, 1536)\n",
            "(100,)\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n",
            "X_train shape: (620, 1, 12, 1536)\n",
            "620 train samples\n",
            "100 val samples\n",
            "(40, 12, 1536)\n",
            "(40, 1)\n",
            "X_train shape: (40, 1, 12, 1536)\n",
            "40 train samples\n",
            "0 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69033, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6978 - acc: 0.4968 - val_loss: 0.6903 - val_acc: 0.5300\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69033 to 0.68740, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6694 - acc: 0.5774 - val_loss: 0.6874 - val_acc: 0.5400\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68740 to 0.68422, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6367 - acc: 0.6581 - val_loss: 0.6842 - val_acc: 0.5100\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68422\n",
            "620/620 - 1s - loss: 0.6009 - acc: 0.7032 - val_loss: 0.6892 - val_acc: 0.5100\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.68422 to 0.67982, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5547 - acc: 0.7306 - val_loss: 0.6798 - val_acc: 0.5500\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.67982 to 0.67786, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5336 - acc: 0.7355 - val_loss: 0.6779 - val_acc: 0.6100\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.67786 to 0.63438, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5051 - acc: 0.7403 - val_loss: 0.6344 - val_acc: 0.6400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.63438 to 0.62872, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5209 - acc: 0.7613 - val_loss: 0.6287 - val_acc: 0.6500\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.62872\n",
            "620/620 - 1s - loss: 0.5160 - acc: 0.7613 - val_loss: 0.6364 - val_acc: 0.6000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.62872\n",
            "620/620 - 1s - loss: 0.5072 - acc: 0.7613 - val_loss: 0.6337 - val_acc: 0.6700\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.8829 - acc: 0.4750\n",
            "test loss, test acc: [0.8829143933951855, 0.475]\n",
            "1 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69118, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6855 - acc: 0.5516 - val_loss: 0.6912 - val_acc: 0.4800\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.69118\n",
            "620/620 - 1s - loss: 0.6294 - acc: 0.6742 - val_loss: 0.6935 - val_acc: 0.4700\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.69118\n",
            "620/620 - 1s - loss: 0.5896 - acc: 0.7145 - val_loss: 0.7190 - val_acc: 0.4700\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.69118\n",
            "620/620 - 1s - loss: 0.5553 - acc: 0.7242 - val_loss: 0.7461 - val_acc: 0.4700\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.69118\n",
            "620/620 - 1s - loss: 0.5305 - acc: 0.7387 - val_loss: 0.7215 - val_acc: 0.5300\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.69118\n",
            "620/620 - 1s - loss: 0.5104 - acc: 0.7548 - val_loss: 0.7041 - val_acc: 0.5400\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.69118 to 0.65531, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.5135 - acc: 0.7581 - val_loss: 0.6553 - val_acc: 0.6400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.65531 to 0.63430, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4936 - acc: 0.7645 - val_loss: 0.6343 - val_acc: 0.7000\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.63430\n",
            "620/620 - 1s - loss: 0.4882 - acc: 0.7516 - val_loss: 0.6508 - val_acc: 0.7000\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.63430\n",
            "620/620 - 1s - loss: 0.4927 - acc: 0.7710 - val_loss: 0.6460 - val_acc: 0.7000\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.9600 - acc: 0.5250\n",
            "test loss, test acc: [0.9599569495767355, 0.525]\n",
            "2 0\n",
            "Train on 620 samples, validate on 100 samples\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69143, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6902 - acc: 0.5500 - val_loss: 0.6914 - val_acc: 0.5300\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69143 to 0.68836, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.6531 - acc: 0.6177 - val_loss: 0.6884 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.6086 - acc: 0.6887 - val_loss: 0.7031 - val_acc: 0.4800\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.5613 - acc: 0.7323 - val_loss: 0.7083 - val_acc: 0.5100\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.5288 - acc: 0.7355 - val_loss: 0.7238 - val_acc: 0.5300\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.4894 - acc: 0.7774 - val_loss: 0.7508 - val_acc: 0.5400\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.4954 - acc: 0.7645 - val_loss: 0.7851 - val_acc: 0.5400\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68836\n",
            "620/620 - 1s - loss: 0.4690 - acc: 0.8016 - val_loss: 0.7243 - val_acc: 0.5700\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.68836 to 0.67867, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4768 - acc: 0.7968 - val_loss: 0.6787 - val_acc: 0.6300\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.67867 to 0.62948, saving model to /tmp/checkpoint.h5\n",
            "620/620 - 1s - loss: 0.4676 - acc: 0.7790 - val_loss: 0.6295 - val_acc: 0.6600\n",
            "\n",
            "# Evaluate on test data\n",
            "40/40 [==============================] - 0s 3ms/sample - loss: 0.8647 - acc: 0.5500\n",
            "test loss, test acc: [0.8646977119147777, 0.55]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c1fc9320869a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outfname' is not defined"
          ]
        }
      ]
    }
  ]
}